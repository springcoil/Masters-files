\documentclass[12pt, oneside, a4paper]{article}

\usepackage[all]{xy}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{array, amsthm, amsmath, amssymb, amsfonts, color, hyperref, url, textcomp, bbm}
\usepackage{geometry, setspace, graphicx, enumerate, amssymb}
\onehalfspacing                 
\usepackage{fontspec,xltxtra,xunicode}

\newcommand{\bb}[1]{\textbf{#1}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{fact}[thm]{Fact}
%\newtheorem{clm}[thm]{Claim}
\def\Mtil{\widetilde{M}}
\def\ins{\operatorname{\without}}
\def\RePart{\Re e \,}
\def\ImPart{\Im m \,}
\def\Ind{\mathbbm{1}}
\def\supp{\operatorname{supp}}
\def\dist{\operatorname{dist}}
\def\grad{\operatorname{grad}}
\def\vol{\operatorname{vol}}
\def\divergence{\operatorname{div}}
\def\id{\operatorname{id}}
\def\pointtilde{\tilde{\,\cdot\,}}
\def\exptilde{\exp_\sim}
\def\nbf{\mathbf{n}}
\theoremstyle{dfn}
\newtheorem{dfn}[thm]{Definition}
\newtheorem{rem}[thm]{Remark}
\newtheorem{note}[thm]{Note}
%\newtheorem*{remu}{Remark}
\newtheorem{ex}[thm]{Example}
\newtheorem{exs}[thm]{Examples}
\newtheorem{exer}[thm]{Exercise}

\newtheorem{metaphor}{Metaphor}
\newtheorem{idea}{Idea}
\newtheorem{convention}{Convention}
\newtheorem{recall}{Recall}
\def \grad {\overrightarrow{\nabla}}
\def \curl {\overrightarrow{\nabla} \wedge \cdot}
\def \div {\overrightarrow{\nabla} \cdot}
\def \nab {\ensuremath{\nabla}}
\def \im {\text{im }}
\def \ker {\text{ker }}
\def \scal {\text{<\textperiodcentered,\textperiodcentered>}}
\newcommand{\scalprod}[2]{\langle #1,#2 \rangle}

\def\Cperinfty{C_{\operatorname{per}}^\infty}
 \def\Ccompct{C_{\operatorname{c}}^\infty}
\def\Cdist{C_{c}^{-\infty} (U)}
\providecommand{\Lper}[1]{L^{#1}([-\pi,\pi])}
\providecommand{\Lpern}[1]{L^{#1}([-\pi,\pi]^n)}

\def \C {\ensuremath{\mathcal{C}}} % for categories
\def \D {\ensuremath{\mathcal{D}}}
\def \S {\ensuremath{\mathcal{S}}}
\def \P {\ensuremath{\mathcal{P}}}
\def \U {\ensuremath{\mathcal{U}}}
\def \H {\ensuremath{\mathcal{H}}}
\def \S {\ensuremath{\mathcal{S}}}
\def \psiket {\ensuremath{|\psi \rangle}}
\def \phiket {\ensuremath{|\phi \rangle}}
\def \psibra {\ensuremath{\langle \psi |}}
\def \phibra {\ensuremath{\langle \phi |}}

\usepackage{textcomp}

\def\Kbb{\ensuremath{\mathbb{K}}}
\def\Nbb{\mathbb{N}}
\def\Pbb{\mathbb{P}}
\def\Qbb{\mathbb{Q}}
\def\Rbb{\ensuremath{\mathbb{R}}}
\def\Zbb{\ensuremath{\mathbb{Z}}}

\def \eps {\varepsilon}
\def \AA{\ensuremath{\mathcal{A}^{1}}}
\def  \AAA{\ensuremath{\mathcal{A}}}
\def \Fff{\mathfrak{F}}
%\def \commutes {\ar@{}[rd]|{\circlearrowleft}}
\def \commutes {\ar@{}[rd]|{\mbox{ \Large{$\circlearrowleft$} }}}
\def\dx{\,\mathrm dx}
\newcommand{\tensor}{\otimes}
\newcommand{\gt}{>}
\newcommand{\lt}{<}
\newcommand{\itexarray}[1]{\begin{matrix}#1\end{matrix}} %To draw commutative Diagrams
\newcommand{\Ob}{{\rm Ob}}
     \newcommand{\Cob}{{\rm Cob}}   
	\newcommand{\Vect}{{\mathrm{Vect}}}   
	\newcommand{\Hilb}{{\mathrm{Hilb}}}    
	\newcommand{\tr}{{\rm tr}}   
      \newcommand{\Hom}{{\rm hom}}
\newcommand{\cChVect}{\mathrm {cCh(Vect)}}
\newcommand{\gVect}{\mathrm {gVect}} 
\newcommand{\To}{\ensuremath{\rightarrow \;}}  
\newcommand{\newword}[1]{\textbf{\emph{#1}}}
\newcommand{\eee}{\ensuremath{e_{i_1}\wedge \cdots \wedge e_{i_p}}}
\def \hodge{*}
\def \iso {\cong}
\newcommand{\aut}[1]{\text{Aut}{(#1)}}

\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\normbig}[1]{\big\lVert#1\big\rVert}
\providecommand{\Norm}[1]{\left\lVert#1\right\rVert}

\newcommand{\tworow}[2]{\genfrac{}{}{0pt}{}{#1}{#2}}
\newcommand{\xdeg}[2]{[#1 : #2]}
\newcommand{\gal}[2]{\text{Gal}(#1/#2)}
\newcommand{\minpoly}[2]{m_{#1, #2}(x)}
\renewcommand{\Re}{\text{Re}}

\newcommand{\mapping}[5]{\begin{align*}
    #1 : \,     #2 &\rightarrow #3 \\
            #4  &\mapsto #5
\end{align*}    
}

\newcommand{\hilb}{(\Hil, \langle \cdot, \cdot, \rangle )}
\renewcommand{\phi}{\varphi}
       
\newcommand{\expc}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\var}[1]{\text{Var}\left(#1\right)}
\newcommand{\cov}[1]{\text{Cov}\left(#1\right)}
\newcommand{\prob}[1]{\mathbb{P}(#1)}
\newcommand{\given}{ \, | \,}
\newcommand{\us}{0 \leq u \leq s}
\newcommand{\ts}[1]{\{ #1 \}}

\newcommand{\dzz}{\, dz}
\newcommand{\bigo}[1]{\mathcal{O}(#1)}

% Maths Field Symbols
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Hil}{\mathcal{H}}
\newcommand{\Gcal}{\mathcal{G}}
\newcommand{\Fcal}{\mathcal{F}}


\newcommand{\Com}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Ga}{\mathbb{G}}

\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\absbig}[1]{\big\lvert#1\big\rvert}
\providecommand{\Abs}[1]{\left\lvert#1\right\rvert}

\newcommand{\gener}[1]{\langle #1 \rangle}
\newcommand{\charr}[1]{\text{char}(#1)}
\newcommand{\nth}{n\textsuperscript{th}}
        
\newcommand{\iprod}[1]{\left\langle #1 \right\rangle}
\newcommand{\sumkn}{\sum_{k=1}^n}
\newcommand{\sumin}{\sum_{i=1}^n}
\newcommand{\sumkinf}{\sum_{k=1}^\infty}
\newcommand{\sumiinf}{\sum_{i=1}^\infty}
\newcommand{\spans}{\text{span}\ }
\usepackage{hyperref}
%opening
\title{PDE Examples}
\author{Peadar Coyle}

\begin{document}

\maketitle
\tableofcontents
\section{Introduction}
\section{Preliminary Functional Analysis}

\begin{dfn}[Norm]
    Let $X$ be a vector space.  A norm on $X$ is a function $\| \cdot \| : X \mapsto \R$ satisfying 
    \begin{itemize}
        \item $\| x \| \geq 0$ with equality if and only if $x = 0$.  
        \item $\| \alpha x \| = | \alpha | \| x \|$.
        \item $\| x + y \| \leq \| x \| + \| y \|$ for all $x, y \in X$.  
    \end{itemize}
    
    We call the pair $(X, \| \cdot \|)$ a \textbf{normed vector space.}
\end{dfn}

\begin{thm}[Reverse triangle inequality]
    Let $X$ be a normed vector space.  For any $x, y \in X$, we have \[
        \left| \|x \| - \| y \| \right| \leq \| x - y \|  
    \]
\end{thm}

\begin{dfn}[Complete space]
    Let $X$ be a normed vector space.  Then $X$ is \textbf{complete} if every Cauchy sequence in $X$ converges to some $x \in X$.  
\end{dfn}

\begin{dfn}[Banach space]
    A \textbf{Banach space} is a complete normed vector space.
\end{dfn}


% section lecture_1_28_february (end)

\section{Lecture 2 - Wednesday 2 March} % (fold)
\label{sec:lecture_2_2_march}

\begin{prop}[Convergence] Let $(V, \| \cdot \| )$ be a normed vector space.  A sequence $(x_n)$ in $V$ converges to $x \in V$ if given $\epsilon > 0$, there exists $N$ such that $\| x - x_n \| < \epsilon$ whenever $n < N$. 
\end{prop}

\begin{lem}
    If $x_n \rightarrow x$, then $\| x_n \| \rightarrow \| x \| \in \R$.
    \begin{proof}
        $\left| \| x_n \| - \| x \| \right| \leq \| x - x_n \| \rightarrow 0$.
    \end{proof}
\end{lem}

\begin{prop}
    Every convergent sequence is Cauchy.
\end{prop}

\begin{dfn}[Banach space]
A complete, normed, vector space is called a \textbf{Banach space}
\end{dfn}

\begin{prop}
    $( \K, |\cdot |)$ is complete.
\end{prop}

\begin{prop}
    $(\ell^p, \| \cdot \|_p)$ is a Banach space for all $1 \leq p \leq \infty$
\end{prop}

\begin{proof}
    A general proof outline follows.
    \begin{itemize}
        \item Use completeness of $\R$ to find a candidate for the limit.
        \item Show this limit function is in $V$.
        \item Show that $x_n \rightarrow x$ in $V$.
    \end{itemize}
    Let $x^{(n)}$ be a Cauchy sequence in $\ell^p$.  Since $|x_j^{(n)} - x_{j}^{(n)}| \leq \|x^{(n)} - x^{(m)}\|$, we know that $x^{(n)}_j$ is a Cauchy sequence in $\K$.  Hence, $\lim_{n \rightarrow \infty} x^{(n)}_j := x_j$ exists, and is our limit candidate.
    
    We now show that $\sum_{j =1}^\infty |x_j|^p < \infty$.  We have 
\end{proof}

\begin{prop}
    ($\ell([a,b]), \|\cdot \|_\infty$) is a Banach space
\end{prop}

\begin{prop}
    If $1 \leq p < \infty$, then $(\ell([a,b]), \| \cdot \|_p)$ is \textbf{not} a Banach space.
\end{prop}
\begin{proof}
    Consider a sequence of functions that is equal to one on $[0, \frac{1}{2}]$, zero on $[\frac{1}{2}+ \frac{1}{n}, 1]$, and linear between.  This is a Cauchy sequence that does not converge to a continuous function. 
\end{proof}
% section lecture_2_2_march (end)

\section{Lecture 3 - Monday 7 March} % (fold)
\label{sec:lecture_3_monday_7_march}
We've seen that $(\ell([a,b]), \| \cdot \|_p)$ is not complete for $1 \leq p < \infty$.  

\begin{thm}[Completion] Let $(V, \| \cdot \| )$ be a normed vector space over $\K$.  There exists a Banach space ($V_1, \| \cdot \|_1$) such that $( V, \| \cdot \|)$ is isometrically isomorphic to a dense subspace of $(V_1, \| \cdot \|_1)$.  
    
    Furthermore, the space $( V_1, \| \cdot \|_1)$ is unique up to isometric isomorphisms.  
\end{thm}

\begin{proof}
    Rather straightforward - construct Cauchy sequences, append limits, quotient out (as different sequences may converge to the same limit).
\end{proof}

\begin{dfn}[] $(V_1, \| \cdot \|_1)$ is called \textbf{the completion} of $(V, \| \cdot \|)$. 
\end{dfn}

\begin{dfn}[Dense]
    If $X$ is a topological space and $Y \subseteq X$, then $Y$ is \textbf{dense} in $X$ if the closure of $Y$ in $X$ equals $X$, that is, $\overline{Y} = X$.

Alternatively, for each $x \in X$, there exists $(y_n)$ in $Y$ such that $y_n \rightarrow x$.
\end{dfn}

\begin{dfn}[Isomorphism of vector spaces]
    Two normed vector spaces $(X, \| \cdot \|X)$ and $(Y, \| \cdot \|Y)$ are \textbf{isometrically isomorphic} if there is a vector space isomorphism $\Psi: X \rightarrow Y$ such that \[
        \| \Psi(x) \|_Y = \| x \|_X \quad \forall x \in X
    \]
\end{dfn}

\begin{ex}
    Let $\ell_0 = \{ (x_i) \, | \, \# \{ i, x_i \neq 0 \} < \infty \}$.  The completion of $\ell_0, \| \cdot \|_p$ is $(\ell^p, \| \cdot \|_p )$, because,
    \begin{itemize}
        \item $\ell_0$ is a subspace of $\ell^p$,
        \item It is dense, since we can easily construct a sequence in $\ell_0$ converging to arbitrary $x \in \ell^p$.
    \end{itemize}
\end{ex}
% % 
\begin{ex}[ $L^p$ spaces]
    Let $\mu$ be the Lebesgue measure on $\R$.  Let \[
        \mathcal{L}^p([a,b]) = \{ \text{measurable } f: [a,b] \rightarrow \K \, | \, \int_a^b |f|^p \, d \mu < \infty \}
    \]
    
    Let $\| f \|_p = \left( \int_a^b |f|^p \, d \mu \right)^{1/p}$.  Since $\| f \|_p = 0 \iff f = 0 \, a.e$, we quotient out by the rule $f \equiv g \iff f - g = 0 \, a.e.$, and then our space of equivalence classes forms a normed vector space, denoted $L^p([a,b])$.
\end{ex}

\begin{thm}[Riesz-Fischer] $(L^p([a,b]), \| \cdot \|_p )$ is the completion of $(\mathcal{C}[a,b], \| \cdot \|_p )$, and is a Banach space.
\end{thm}
\begin{proof}
    Properties of the Lebesgue integral.
\end{proof}

\begin{rem}{\ }
    \begin{itemize}
        \item Let $X$ be any compact topological space, let $\mathcal{C}(X) = \{ f : X \rightarrow \K \, | \, \text{$f$ is continuous} \}$, and let $\|f \|_\infty = \sup_{x \in X} \|f(x)|$.  Then $\mathcal{C}(X, \| \cdot \|_\infty)$ is Banach.  
        \item Let $X$ be any topological space.  Then the set of all continuous and bounded functions with the supremum norm forms a Banach space.
        \item Let $(S, \mathcal{A}, \mu)$ be a measure space.  Then we can define the $\mathcal{L}^p$ and $L^p$ analogously, and they are also Banach.
    \end{itemize}
\end{rem}

\begin{dfn}[Linear operators on normed vector spaces]
    Let $X,Y$ be vector spaces over $\K$.  A linear operator is a function $T:X \rightarrow Y$ such that 
    \begin{align*}
        T(x+y) &= T(x) + T(y) \\
        T(\alpha x) &= \alpha T(x)
    \end{align*}
    for all $x,y,\alpha$.

    We write $\text{Hom}(X,Y) = \{ T: X \rightarrow Y \, | \, \text{$T$ is linear} \}$
\end{dfn}

\begin{dfn}[]
    $T: X \rightarrow Y$ is continuous at $x \in X$ if for all $\epsilon > 0$, there exists $\delta > 0$ such that \[
            \| x - y \|_X < \delta \Rightarrow \| Tx - Ty \|_y < \epsilon 
    \]
\end{dfn}

\begin{dfn}[]
    \[
    \mathcal{L}(X,Y) = \{ T:  X \rightarrow Y \, | \, \text{$T$ is linear and continuous} \}
    \]
\end{dfn}

\begin{rem}
    If $\text{dim}(X) < \infty$ then $\text{Hom}(X,Y) = \mathcal{L}(X,Y)$.  This is \textbf{not} true if $X$ has infinite dimension.
\end{rem}

\begin{dfn}[Bounded linear operator]
    Let $T: X \rightarrow Y$ be linear, then $T$ is \textbf{bounded} if $T$ maps bounded sets in $X$ to bounded sets in $Y$.  That is: for each $M > 0$ there exists $M' > 0$ such that \[
        \| x \|_X \leq M \Rightarrow \|Tx\|_Y \leq M'
    \]
\end{dfn}
% section lecture_3_monday_7_march (end)

\section{Lecture 4 - Wednesday 9 March } % (fold)
\label{sec:lecture_4_}
Consider the space $\mathcal{L}(X, Y)$, the set of all linear and continuous maps between two normed vector spaces $X$ and $Y$.  

\begin{thm}[Fundamental theorem of linear operators]
    Let $( X, \| \cdot \|_X)$ and $Y, \| \cdot \|_Y$ be normed vector spaces.  Let $ T \in \text{Hom}(X,Y)$, the set of all linear maps from $X$ to $Y$.  Then the following are all equivalent.
    \begin{enumerate}[1)]
        \item $T$ is uniformly continuous
        \item $T$ is continuous
        \item $T$ is continuous at 0
        \item $T$ is bounded
        \item There exists a constant $c > 0$ such that \[
            \| Tx \|_Y \leq c \| x \|_X \quad \forall x \in X
        \]
    \end{enumerate}
\end{thm}

\begin{proof}
    $1) \Rightarrow 2) \Rightarrow 3)$ is clear.
    
    $3) \Rightarrow 4)$.  Since $T$ is continuous at 0, given $\epsilon = 1 > 0$, there exists $\delta$ such that \[
        \| Tx - T0 \| \leq 1 \quad \text{whenever} \quad \| X - 0 \| \leq \delta,
    \] i.e. that $\| x \leq \delta \Rightarrow \| Tx \| \leq 1$.  Let $y \in X$.  The $\| \frac{\delta y}{\| y \|} \| \leq \delta$, and so $\| T\left( \frac{\delta y}{\| y \|} \right) \| < \leq 1$.  Hence, \[
        \frac{\delta}{\|y \|} \|T y \| \leq 1
    \] and so \[
        \|Ty \| \leq \frac{ \| y \|}{\delta}
    \] for all $y \in X$.  Thus, for all $\| y \| \leq M$, we have $\| Ty \| \leq M'$, where $M' = \frac{M}{\delta}$, and so $T$ is \textbf{bounded.} 
    
    $4) \Rightarrow 5)$.  If $T$ is bonded, given $M = 1 > 0$, there exists $c \geq 0$ such that $\| x \| \leq 1 \Rightarrow \|T x \| \leq c$.  Then \[
         \|T \left( \frac{x}{\|x \|} \right) \| \leq c  \] 
        Hence, $\|Tx \| \leq c \| x \|$.  
        
    $5) \Rightarrow 1)$.  If $5)$ holds, then  \[
        \| Tx - Ty \| = \| T(x-y) \| \leq c \| x - y \|.
    \]  So if $\epsilon$ is given, taking $\delta = \frac{\epsilon}{c}$, we have \[
        \|Tx - Ty \| \leq c \| x - y \| < c \frac{\epsilon}{c} = \epsilon. \qedhere
    \]
\end{proof}

\begin{cor}
    If $T \in \text{Hom}(X,Y)$, then $T$ continuous $\iff$ $T$ bounded $\iff$ $\|Tx \| \leq c \| x \|$ for all $x \in X$.
\end{cor}

\begin{dfn}[Operator norm]
    The \textbf{operator norm} of $T \in \mathcal{L}(x,y)$, $\| T\|$ is defined by any one of the following equivalent expressions.
    \begin{enumerate}[(a)]
        \item $\|T \| = \inf \{ c > 0 \, | \, \| Tx \| < c \| x \| \}$.
        \item $\| T\| = \sup_{x \neq 0} \frac{ \|Tx \|}{\| x \|}$.
        \item $\| T \| = \sup_{ \|x \| \leq 1} \| Tx \|$.
        \item $\| T \| = \sup_{\| x \| = 1} \|T x \|$.
    \end{enumerate}
\end{dfn}

\begin{prop}
    The operator norm is a norm on $\mathcal{L}(x,y)$.  
\end{prop}

\begin{proof}  The following are simple to verify.
    \begin{enumerate}[(a)]
        \item $\| T \| \geq 0$, with equality if and only if $ T = 0$. 
        \item $\| \alpha T \| = | \alpha | \|T \|$.
        \item $\| S + T \| \leq  \| S \| + \| T \|$.
    \end{enumerate}
\end{proof}

\begin{ex}[Calculating $\| T \|$]
    To calculate $\| T \|$, try the following. 
    \begin{enumerate}[1)]
        \item Make sensible calculations to find $c$ such that \[
            \| Tx \| \leq c \| x \|
        \] for all $x \in X$.
        \item Find $x \in X$ such that $\|Tx \| = c \| x \|$.
    \end{enumerate}
\end{ex}
% section lecture_4_ (end)

\section{Lecture 5 - Tuesday 15 March} % (fold)
\label{sec:lecture_5_tusday_15_march}
\begin{rem}
    Ignore !2, Q3(b), Q8 on the practice sheet, as we will be ignoring Hilbert space theory for the time being.
\end{rem}

\begin{dfn}[Algebraic dual]
    Let $(X, \| \cdot \|)$ be a normed vector space over $\K$.  The \textbf{algebraic dual} of $X$ is \[
        X^\star = \text{Hom}(X, \K) = \{ \phi: X \rightarrow \K \, | \, \text{$\phi$ is linear} \}.
    \]  Elements of $X^\star$ are called linear functionals.
\end{dfn}

\begin{dfn}[Continuous dual (just \textbf{dual})]
    The \textbf{continuous dual} (just dual) of $X$ is \[
        X' = \mathcal{L}(X, \K) = \{ \phi : X \rightarrow K \, | \, \text{$\phi$ is linear and continuous} \}.
    \]
\end{dfn}

\begin{rem}
    $X^\star \supsetneq X'$ if $\dim(X) = \infty$.
\end{rem}

\begin{ex}
    Let $(\wp([a,b]), \| \cdot \|_\infty)$ be the normed vector space of polynomials $p: [a,b] \rightarrow \K$.                 
    \begin{enumerate}[(a)]
        \item The functional $D : \wp([0,1]) \rightarrow \K$ given by $D(p) = p'(1)$ is linear, but \textbf{not} continuous.
        \item The functional $I: \wp([0,1]) \rightarrow \K$ given by $I(p) = \int_0^1 p(t) \, dt$ is linear \textbf{and} continuous.
    \end{enumerate}
\end{ex}

\begin{proof}
\begin{enumerate}[(a)]
        \item Linearity is clear.  The $p_n(t) = t^n$ for all $t \in [0,1]$.  Then $|D(p_n)| =   n \| p_n \|_\infty$.  So $D$ is not continuous, as continuity implies that there exists $c$ such that \[
            \| Tx \| \leq c \| x \|.
        \]
        \item Exercise: Show $\| I \| = 1$.
\end{enumerate}
\end{proof}

Describing the continuous dual space $X'$ is one of the first things to do when trying to understand a normed vector space.  It is generally pretty difficult to describe $X'$.

\begin{prop}[Dual of the $\ell^p$ space for $(1 < p < \infty)$]
    Let $1 < p < \infty$.  Let $q$ be the ``dual'' of $p$, defined by $\frac{1}{q} + \frac{1}{p} = 1$.  Then $(\ell^p)'$ is isometrically isomorphic to $\ell^q$.  
\end{prop}
\begin{rem}[Observation before proof]
    Let $1 \leq p < \infty$.  Let $e_i = (0,0,\dots, 1, 0, \dots)$ where $1$ is in the $i$-th place.  
\begin{enumerate}[1)]
        \item If $x = (x_i) \in \ell^p$, then \[
            x = \sum_{i=1}^\infty x_i e_i
        \] in the sense that the partial sums converge to $x$.
        \item If $\phi : \ell^p \rightarrow \K$ is linear and continuous, then \[
            \phi(x) = \sum_{i = 1}^\infty x_i \phi(e_i)
        \]
\end{enumerate}

\begin{proof}[Proof of observations.]
    Let $S_n = \sum_{i=1}^n x_i e_i$.  Then \begin{align*}
        \| x - S_n \|_p^p &= \| (0,0,\dots, x_{n+1}, x_{n+2}, \dots) \|_p^p \\
        &= \sum_{i=n+1}^\infty |x_i|^p \\
        &\rightarrow 0 \quad \text{as it is the tail of a convergent sum.}
    \end{align*}
    
    Write $\phi(x)$ as \begin{align*}
        \phi(x) &= \phi( \lim_{n \rightarrow \infty} S_n)  \quad \text{(continuity)}\\
                &= \lim_{n \rightarrow \infty} \left( \phi(S_n ) \right) \\
                &= \lim_{n \rightarrow \infty} \phi \left( \sum_{i=1}^n x_i e_i \right) \\
                &= \lim_{n \rightarrow \infty} \sum_{i=1}^n x_i \phi(e_i) \quad \text{(linearity)}  \\
                &= \sum_{i=1}^\infty x_i \phi(e_i) \qedhere
    \end{align*}
\end{proof}
\end{rem}

\begin{proof}
    Define a map $\theta$ by \mapping{\theta}{\ell^q}{(\ell^p)'}{y}{\phi_y} where $\phi_y(x) = \sum x_i y_i$ for all $x \in \ell^p$. 
    
    \begin{enumerate}[(1)]
        \item $\phi_y$ is linear, as $\phi_y( x + x') = \phi_y(x) + \phi_y(x')$ (valid as sums converge absolutely.)
        \item $\phi_y$ is continuous, as \[
            | \phi_y(x) | = | \sum x_i y_i | \leq \sum | x_i y_i | \leq  \| x \|_p \| y \|_q
        \] by H\"older's inequality.  From the fundamental theorem of linear operators, as $| \phi_y(x) | \leq \| x \|_p \| y \|_q$, we have that $\phi_y$ is continuous, and that 
        \begin{equation}
            \| \phi_y \| \leq \| y \|_q \tag{$\star$}
        \end{equation}  
        \item $\theta$ is linear. 
        \item $\theta$ is injective, as \[
            \theta(y) = \theta(y') \Rightarrow \phi_y = \phi_{y'} \Rightarrow \phi_y(x) = \phi_{y'}(x)\quad \forall x \in \ell^p
        \] \[
            \Rightarrow \phi_y(e_i) = \phi_{y'}(e_i) \quad\forall i \in \N \Rightarrow y_i = y_i' \quad\forall i \in \N \Rightarrow y = y'
        \]
        \item $\theta$ is surjective.  Let $\phi \in (\ell^p)$.  Let $y = ( \phi(e_1), \dots, \phi(e_n), \dots) = (y_1, \dots, y_n, \dots)$.  We now show $y \in \ell^q$.  
        
        Let $x^{(n)} \in \ell^q$  be defined by \[
            x_i^{(n)} = \begin{cases}
                \frac{|y_i|^q}{y_i} &\text{if $i \leq n$ and $y_i \neq 0$} \\
                0 &\text{otherwise}
            \end{cases}
        \]
        Then \begin{equation}
            \phi( x^{(n)}) = \sum_{i=1}^\infty x_i^{(n)} \phi(e_i) = \sum_{i=1}^n |y_i|^q
            \tag{$\dagger$}
        \end{equation} by Observation 2) above. 
        
        On the other hand, we know \begin{align*}
            \| \phi( x^{(n)}) &\leq \| \phi \| \| x^{(n)} \|_p \\
                            &= \| \phi \| \left( \sum_{i=1}^\infty |x_i^{(n)}|^p \right)^{1/p} \\
                            &= \| \phi \| \left( \sum_{i = 1}^n |y_i |^{(q-1)p} \right)^{1/p} \\
                            &= \| \phi \| \left( \sum_{i=1}^n |y_i |^q \right)^{1/p} \quad \text{as $1/p + 1/q = 1$.} \tag{$\star \star$}
        \end{align*}
        Now, using $(\dagger)$ and $(\star \star)$, we have \[
             \sum_{i=1}^n |y_i|^q  \leq \| \phi \| \left( \sum_{i=1}^n | y_i |^q \right)^{1/p} 
        \] and so we must have \[
            \| y \|_q \leq \| \phi \| \tag{$\star \star \star$}
        \]
        and so $y \in \ell^q$.
        
        We also have, by $(\star \star)$,\[
            \| y \|_q \leq \| \phi_y \|
        \] 
        \item Finally, we show that $\theta$ is an isometry.  By $(\star)$ and $(\star \star \star)$, we have \[
            \| \theta(y) \| = \| \phi_y \| = \| y \|_q 
        \] as required.\qedhere
         
    \end{enumerate} 
\end{proof} 
% section lecture_5_tusday_15_march (end)

\section{Lecture 6 - Wednesday 16 March} % (fold)
\label{sec:lecture_6_wednesday_16_march}
How big is $X'$?  When is $X' \neq \{ 0 \}$?  Examples suggest that $X'$ is big with a rich structure.  

\subsection{The Hahn-Banach theorem} % (fold)
\label{sub:the_hahn_banach_theorem}
The Hahn-Banach theorem is a cornerstone of functional analysis.  It is all about extending linear functionals defined on a subspace to linear functionals on the whole space, while preserving certain properties of the original functional.

\begin{dfn}[Seminorm]
A let $X$ be a vector space over $\K$.  A seminorm on $X$ is a function $p : X \rightarrow \R$ such that 
\begin{enumerate}[(1)]
    \item $p(x+y) \leq p(x) + p(y) \quad \forall x,y \in X$
    \item $p(\lambda x) = | \lambda | p(x) \quad \forall x \in X, \lambda \in \K$
\end{enumerate}
\end{dfn}

\begin{thm}[General Hahn-Banach]
    Let $X$ be a vector space over $\K$.  Let $p: X \rightarrow \R$ be a seminorm on $X$.  Let $Y \subseteq X$ be a subspace of $X$.  If $f : Y \rightarrow \K$ is a linear functional such that \[
        | f(y) | \leq p(y) \quad \forall y \in Y
    \] then there is an extension $\tilde{f} : X \rightarrow \K$ such that 
    \begin{itemize}
        \item $\tilde{f}$ is linear
        \item $\tilde f (y) = f(y) \quad \forall y \in Y$
        \item $|f(x)| \leq p(x) \quad \forall x \in X$
    \end{itemize}
\end{thm}

\begin{rem}
    This is great.
    \begin{itemize}
        \item $Y$ can be finite dimensional (and we know about linear functionals on finite dimensional spaces)
        \item If $p(x) = \| x \|$, then \[
            |\tilde f (x) | \leq \|x \| \quad \forall x \in X
        \] and so $\tilde f \in X'$
    \end{itemize}
\end{rem}

\begin{cor}
    Let $(X, \| \cdot \|)$ be a normed vector space over $\K$.  For each $y \in X$, with $y \neq 0$, there is $\phi \in X'$ such that \[
        \phi(y) = \| y \| \quad \text{and} \quad \| \phi \| = 1
    \]
\end{cor}
\begin{proof}
    Fix $y \neq 0$ in $X$.  Let $Y = \{ \K y \} = \{ \lambda y | \lambda \in \K \}$, a one-dimensional subspace.  
    
    Define $f : Y \rightarrow \K$, $f( \lambda y) = \lambda \| y \|$.  This is linear.  Set $p(x) = \| x \|$.  Then \[
        | f(\lambda y ) = p(\lambda y)
    \] and so by Hahn-Banach, there exists $\tilde f : X \rightarrow \K$ such that
    \begin{itemize}
        \item $\tilde f$ is linear
        \item $\tilde f(\lambda y) = f( \lambda y) \quad \forall \lambda \in \K$
        \item $| \tilde f (x) | \leq \| x \| \quad \forall x \in X$
    \end{itemize}
    Then we  have $\tilde f \in X'$ and $\| f \| = 1$ as required.
\end{proof}

% subsection the_hahn_banach_theorem (end)

\subsection{Zorn's Lemma} % (fold)
\label{sub:zorn_s_lemma}

\begin{thm}[Axiom of Choice is equivalent to Zorn's Lemma]
    See handout for proof that \[
        A.C. \Rightarrow Z.L.
    \]
\end{thm}

\begin{dfn}[Partially ordered set]
    A \textbf{partially ordered set} (poset) is a set $A$ with a relation $\leq$ such that 
    \begin{enumerate}[(1)]
        \item $ a \leq a$ for all $a \in A$,
        \item If $a \leq b$ and $b \leq a$then $a = b$,
        \item If $a \leq b$ and $b \leq c$, then $a \leq c$
    \end{enumerate}
\end{dfn}

\begin{dfn}[Totally ordered set]
    A \textbf{totally ordered set} is a poset $(A, \leq)$ such that if $a, b \in A$ then either $a \leq b$ or $b \leq a$.
\end{dfn}

\begin{dfn}[Chain]
    A \textbf{chain} in a poset $(A, \leq)$ is a totally ordered subset of $A$.
\end{dfn}

\begin{dfn}[Upper bound]
    Let $(A, \leq)$ be a poset.  An \textbf{upper bound} for $B \subseteq A$ is an element $u \in A$ such that $b \leq u$ for all $ b \in B$.  
\end{dfn}

\begin{dfn}[Maximal element]
    A \textbf{maximal element} of a poset $(A, \leq)$ is an element $m \in A$ such that $m \leq x$ implies $x = m$, that is, \[
        m \leq x \Rightarrow x = m
    \]
\end{dfn}

\begin{ex}
    Let $S$ be any set.  Let $\mathcal{P}(S)$ be the power set of $S$ (the set of all subsets of $S$).  Define $a \leq b \iff a \subseteq b$.  Maximal element is $S$
\end{ex}

\begin{thm}[Zorn's Lemma]
    Let $(A, \leq)$ be a poset.  Suppose that every chain in $A$ has an upper bound.  Then $A$ has (at least one) maximal element.  
\end{thm}

\begin{ex}[Application - all vector spaces have a basis]
    \begin{dfn}[Linearly independent]
        Let $X$ be a vector space over $\F$.  We call $B \subseteq X$ \textbf{linearly independent} if \[
            \lambda_1 x_1 + \dots + \lambda_n x_n = 0 \Rightarrow \lambda_1 = \dots = \lambda_n = 0
        \] for all finite $\{ x_1, \dots, x_n \} \subseteq B$. 
    \end{dfn}
    
    \begin{dfn}[Span]
        We say $B \subseteq X$ \textbf{spans} $X$ if each $x \in X$ can be written as \[
            x = \lambda_1 x_1 + \dots + \lambda_n x_n
        \] for some $\lambda_1, \dots, \lambda_n \in \F$ and $\{ x_1, \dots, x_n \} \subseteq B$. 
    \end{dfn}
    
    \begin{dfn}[Hamel basis]
        A Hamel basis is a linearly independent spanning set. Equivalently, $B \subseteq X$ is a Hamel basis if and only if each $x \in X$ can be written in exactly one way as a finite linear combination of elements of $B$.
    \end{dfn}
    
    \begin{thm}
        Every vector space has a Hamel basis
    \end{thm}
    
    \begin{proof}
        Let $L = \{ \text{linearly independent subsets} \}$, with subset ordering.  Let $C$ be a chain in $L$.  Let $u = \bigcup_{a \in C} a$.  Then 
        \begin{enumerate}[(1)]
            \item $u \in L$,
            \item $u$ is an upper bound for $C$.
        \end{enumerate}  
        So Zorn's Lemma says that $L$ has a maximal element $\mathbf{b}$.  
        
        Then $\mathbf{b}$ is a Hamel basis. 
        \begin{itemize}
            \item $\mathbf{b}$ is linearly independent.  
            \item If $\text{Span}(\mathbf{b}) \neq X$, there exists $X \in X \backslash \text{Span}(\mathbf{b})$, and $\mathbf{b'} = \mathbf{b} \bigcup \{ x \} \in L$ is linearly independent, contradicting maximality of $\mathbf{b}$.
        \end{itemize}  
    \end{proof}
    
    \begin{rem}
        If $ X, \| \cdot \| )$ is Banach, every Hamel basis is uncountable.
    \end{rem}
\end{ex}
% subsection zorn_s_lemma (end)

% section lecture_6_wednesday_16_march (end)

\section{Lecture 7 - Monday 21 March} % (fold)
\label{sec:lecture_7_monday_21_march}
Proof of Hahn-Banach Theorem
Discussion of Dual operators

\begin{thm}[Hahn-Banach theorem over $\R$]
    Let $X$ be a real linear space and let $p(x)$ be a seminorm on $X$.  Let $M$ be a real linear subspace of $X$ and $f_0$ a real-valued linear functional defined on $M$.  Let $f_0$ satisfy $f_0(x) \leq p(x)$ on $M$.  Then there exists a real valued linear functional $F$ defined on $X$ such that 
    \begin{enumerate}[(i)]
        \item $F$ is an extension of $f_0$, that is, $F(x) = f_0(x)$ for all $x \in M$, and 
        \item $F(x) \leq p(x)$ on $X$.  
    \end{enumerate}
\end{thm}

\begin{proof}
    We first show that $f_0$ can be extended if $M$ has codimension one.  Let $x_0 \in X \backslash M$ and assume that $\text{span}(M \cup \{ x_0 \}) = X$. As $x_0 \notin M$ be can write $x \in X$ uniquely in the form \[
        x = m + \alpha x_0
    \] for $\alpha \in \R$.  Then for every $c \in \R$, the map $f_c \in \text{Hom}(X, \R)$ given by $f_c(m + \alpha x) = f_0(m) + c \alpha$ is well defined, and $f_c(m) = f_0(m)$ for all $m \in M$. We now show that we can choose $c \in \R$ such that $f_c(x) \leq p(x)$ for all $ x \in X$.  Equivalently, we must show 
    \[
        f_0(m) + c \alpha \leq p(m + \alpha x_0)
    \] for all $m \in M$ and $\alpha \in \R$.  By positive homogeneity of $p$ and linearity of $f$ we have \begin{align*}
        f_0(m / \alpha) + c &\leq p(x_0 + m/\alpha) \quad \alpha > 0 \\
        f_0(-m/\alpha) - c &\leq p(-x_0 -m/\alpha) \quad \alpha < 0
    \end{align*}  Hence we need to choose $c$ such that \begin{align*}
        c &\leq p(x_0 + m) - f_0(m) \\
        c &\geq -p(-x_0 + m) + f_0(m).
    \end{align*}  This is possible if \[
        -p(-x_0 + m_1) + f_0(m_1) \leq p(x_0 + m_2) - f_0(m_2) 
    \] for all $m_1, m_2 \in M$.  By subadditivity of $p$ we can verify this condition since \[
        f_0(m_1 + m_2) \leq p(m_1 m_2) = p(m_1 - x_0 + m_2 - x_0) \leq p(m_1 - x_0) + p(m_2 + x_0)
    \] for all $m_1, m_2 \in M$.  Hence $c$ can be chosen as required.
    
    
    Hence $D(F) = X$, and the theorem is proven.
\end{proof}


\begin{thm}[Hahn-Banach over $\Com$]
    Suppose that $c$ is a seminorm on a complex vector space $X$ and let $M$ sub a subspace of $X$.  If $f_0 \in \text{Hom}(M, \Com)$ is such that $|f_0(x) | \leq p(x)$ for all $x \in M$, then there exists an extension $f \in \text{Hom}(X, \Com)$ such that $f|_M = f_0$ and $|f(x)| \leq p(x)$ for all $x \in X$.  
\end{thm} 

\begin{proof}
    Split $f_0$ into real and imaginary parts \[
        f_0(x) = g_0(x) + ih_0(x).
    \]  By linearity of $f_0$ we have \begin{align*}
        0   &= if_0(x) - f_0(ix) = ig_0(x) - h_0(x) - g_0(ix) - ih_0(ix) \\
            &= -(g_0(ix) + h_0(x) ) + i(g_0(x) - h_0(ix))
    \end{align*} and so $h_0(x) = -g_0(ix)$.  Therefore, \[
        f_0(x) = g_0(x) - ig_0(ix)
    \] 
    for all $x \in M$.  We now consider $X$ as a vector space over $\R$, $X_\R$.  Now considering $M_\R$ as a subspace of $X_\R$.  GSince $g_0 \in \text{Hom}(M_\R, \R)$ and $g_0(x) \leq |f_0(x)| \leq p(x)$ and so by the real Hahn-Banach, there exists $g \in \text{Hom}(X_\R, \R)$ such that $g|_{M_\R} = g_0$ and $g(x) \leq p(x)$ for all $x \in X_\R$.  Now set $F(x) = g(x) - ig(ix)$ for all $x \in X_\R$.  Then by showing $f(ix) = if(x)$, we have that $f$ is linear.  
    
    We now show $|f(x)| \leq p(x)$.  For a fixed $x \in X$ choose $\lambda \in \Com$ such that $\lambda f(x) = |f(x)|$.  Then since $|f(x)| \in \R$ and by definition of $f$, we have \[
        |f(x)| = \lambda f(x) | = f(\lambda x) = g(\lambda x) \leq p(\lambda x) = |\lambda p(x) = p(x)
    \] as required.  
 \end{proof}
% section hahn_banac (end)
% section lecture_7_monday_21_march (end)

\section{Lecture 8 - Wednesday 23 March} % (fold)
\label{sec:lecture_8_wednesday_23_march}
\begin{dfn}[Inner product]
    Let $X$ be a vector space over $\K$.  
    An \textbf{inner product} is a function \[
    \langle \cdot, \cdot \rangle : X \times X \rightarrow \K 
    \] such that 
    \begin{enumerate}[(1)]
        \item $\langle x + y, z \rangle = \langle x, z \rangle + \langle y, z \rangle$
        \item $\langle \alpha x, z \rangle = \alpha \langle x, z \rangle$
        \item $\langle x, y \rangle = \overline{ \langle y, x \rangle}$
        \item $\langle x, x \rangle \geq 0$ with equality if and only if $x = 0$
    \end{enumerate}
    We then have \[
        \langle x, y + z \rangle = \langle x, y \rangle + \langle x, z \rangle
    \] and \[
        \langle x, \alpha z \rangle = \overline \alpha \langle x, z \rangle
    \]
\end{dfn}

\begin{dfn}[Inner product space]
    Let $(X, \langle \cdot, \cdot \rangle)$ be an \textbf{inner product space}.  Defining $\| x \| = \sqrt{ \langle x, x \rangle}$ turns $X$ into a normed vector space.  To prove the triangle inequality, we use the Cauchy-Swartz theorem.
\end{dfn}

\begin{thm}[Cauchy-Schwarz]
    In an inner product space $(X, \langle \cdot, \cdot \rangle)$, we have \[
        | \langle x, y \rangle | \leq \|x \| \| y \| \quad \forall x, y  \in X
    \] 
\end{thm}
\begin{proof}
    \begin{align*}
        0   &\leq \langle x - \lambda y, x - \lambda y \rangle \\
            &= \langle x, x \rangle - \langle x, \lambda y \rangle - \langle \lambda y, x \rangle +\langle \lambda y, \lambda y \rangle  \\
            &= \| x \|^2 - \bar \lambda \langle x, y \rangle - \lambda \langle y, x \rangle + |\lambda|^2 \| y \|^2 \\
            &= \| x \|^2 - 2 \Re ( \lambda \langle y, x \rangle ) + |\lambda|^2 \| y \|^2 \\
    \end{align*}  Set $\lambda = \frac{\langle x, y \rangle}{\| y \|^2}$.  Then
    \begin{align*}
        0 &\leq \| x \|^2 - 2 \Re ( \frac{|\langle x, y \rangle|^2}{\| y \|^2} ) + \frac{|\langle x, y \rangle|^2}{\| y \|^2} \\
            &= \| x \|^2 - \frac{|\langle x, y \rangle|^2}{\| y \|^2}
    \end{align*} as required.
\end{proof}

\begin{cor}
    \[
        \| x + y \| \leq \| x \| + \| y \|
    \]
\end{cor}

\begin{dfn}[Hilbert space]
    If $(X, \langle \cdot, \cdot \rangle)$ is complete with respect to $\| \cdot \|$ then it is called a \textbf{Hilbert space.} 
\end{dfn}

\begin{ex}
    \begin{enumerate}[(a)]
        \item $\ell^2$, where $\langle x, y \rangle = \sum_{i=1}^\infty x_i \overline{y_i}$.  
        
        Cauchy-Schwarz then says \[
            | \sum_{i=1}^\infty x_i \overline{y_i} | \leq \sqrt{ \sum_{i=1}^\infty |x_i|^2} \sqrt{\sum_{i=1}^\infty |y_i|^2}
        \]
        \item $L^2([a,b])$, where $\langle f, g \rangle = \int_a^b f(x) \overline{g(x)} \, dx$. 
        
        Cauchy-Swartz then says \[
            | \int_a^b f(x) \overline{ g(x)} \, dx \leq .....
        \]
    \end{enumerate}
\end{ex}

\begin{dfn}[Orthogonality]
    Let $(X, \langle \cdot , \cdot \rangle )$ be inner product spaces.  Then $x, y \in X $ are orthogonal if $\langle x, y \rangle = 0$ where $x, y \neq 0$.  
\end{dfn}

\begin{thm}
    Let $x_i, \dots, x_n$ be pairwise orthogonal elements in $(X, \langle \cdot , \cdot \rangle)$.  Then \[
        \| \sum_{i=1}^n x_i \|^2 = \sum_{i=1}^n \|x_i\|^2
    \]
\end{thm}

\begin{thm}[Parallelogram identity]
    In $(X, \langle \cdot, \cdot \rangle)$ we have \[
         \| x+ y \|^2 + \| x-y \|^2 = 2( \| x \|^2 + \|y \|^2) \tag{$\star$}
    \] for all $x, y \in X$.
\end{thm}

\begin{rem}
    If $(X, \| \cdot \|)$ is a normed vector space which satisfies parallelogram identity then $X$ is an inner product space with inner products defined by the polarisation equation \[
    \langle x, y \rangle =  \begin{cases} 
            \frac{1}{4} \left( \| x + y \|^2 - \| x - y \|^2 \right)    & \K = \R \\
            \frac{1}{4}\left( \| x + y\|^2 - \| x - y \|^2 + i\| x + iy \|^2 - i\|x - iy\|^2 \right)                                                & \K = \Com
        \end{cases}
    \]
\end{rem}

\begin{dfn}[Projection]
    Let $X$ be a vector space over $\K$.  A subset $M$ of $X$ is convex if for any $x, y \in M$, then \[
        tx + (1-t) y \in M \quad \forall t \in [0,1]
    \]
\end{dfn}

\begin{thm}[Projection]
    Let $(\Hil, \langle \cdot, \cdot, \rangle )$ be a Hilbert space.  Let $M \subseteq \Hil$ be closed and convex.  Let $x \in \Hil$.  THen there exists a unique point $m_x \in M$ which is closest to $x$, i.e. \[
        \| x - m_x \| = \inf_{m \in M} \| x - m \| = d
    \]  
\end{thm}

\begin{proof}
    For each $k \geq 1$ choose $m_k \in M$ such that \[
        d^2 \leq \| x - m_k \|^2 \leq d^2 + \frac{1}{k} 
    \] Each $m_k$ exists as $d$ is defined as the infimum over all $m$. 
    
    Then \begin{align*}
        \| m_k - m_l \|^2   &= \| (m_k - x) - (m_k - x) \|^2 \\
                            &= 2 \| m_k - x \|^2 + 2 \| m_l - x \|^2 - \| m_k + m_l - 2x \|^2 \\
                            &\leq 2d^2 + \frac{2}{l} + 2d^2 + \frac{2}{k} - 4 \| \frac{ m_k + m_l}{2} - x \|^2 \\
    \end{align*} and as $m_k/2 + m_l/2 \in M$, we have $\| \frac{ m_k + m_l}{2} - x \|^2  \geq d^2$.  Then 
    \begin{align*}
            \| m_k - m_l \|^2 \leq 2 ( \frac{1}{k} + \frac{1}{l})
    \end{align*} Thus $(m_k)$ is Cauchy.  So $m_k \rightarrow m_x \in M$ as $\Hil$ is complete and $M$ is closed.  We then have \[
        \| x - m_x \| = d 
    \] and so now we show that $m_x$ is unique.  
    
    Suppose that there exists $m'_x \in M$ with $\| x - m'_x \| = d$.  Then by the above inequality, we have \[
        \| m_x - m'_x \|^2 = 2 \| m_x - x \|^2 + 2 \| m'_x - x \|^2 - 4 \| \frac{m_x - m'_x}{2} - x \|^2 \leq 0 
    \] from above. 
\end{proof}

\begin{dfn}[Projection operator]
Let $\hilb$ be a Hilbert space.  Let $M \subseteq \Hil$ be closed and convex.  Define \[
    P_M : \Hil \rightarrow \Hil
\] by $P_M(x) = m_x$ from above. This is the projection of $\Hil$ onto $M$.
\end{dfn}

\begin{dfn}[Orthogonal decomposition]  
    If $S \subseteq \Hil$, let \[
        S^\perp = \{ x \in \Hil
 \, | \langle x, y \rangle = 0 \quad \forall y \in S. 
\] We call $S^\perp$ the orthogonal component.
\end{dfn}

% section lecture_8_wednesday_23_march (end)

\section{Lecture 9 - Monday 28 March} % (fold)
\label{sec:lecture_9_monday_28_march}

\begin{thm}[From previous lecture]
    If $M \subseteq \Hil$, then the projection of $\Hil$ onto $M$ is \mapping{P_m}{\Hil}{\Hil}{x}{m_x} where $m_x \in M$ is the unique element with $\| x - m_x \| = \inf_{m \in M} \| x - m \|$.  
\end{thm}

\begin{lem}
    Let $M \subseteq \Hil$ be closed subspace.  Then $x - P_M x \in M^{\perp}$ for all $x \in \Hil$.
\end{lem}

\begin{proof}
    Let $m \in M$.  We need to show $\langle x - P_M x , m \rangle = 0$.  This is clear if $m = 0$.  Without loss of generality, assuming $ m \neq 0$, we can assume $ \| m \| = 1$.  Then write \[
        x - P_M x = x - \left( P_M x + \langle x - P_M x, m \rangle m \right) + \langle x - P_M x, m \rangle m.
    \]   Let the bracketed term be $m'$.  Then $ x- m' \perp \langle x - P_M x, m \rangle m$ because 
    \begin{align*}
        \langle x - m', \langle x - P_M x, m \rangle m \rangle &= \overline{\langle x - P_M x, m \rangle} \langle x - m', m \rangle \\
        &= C \langle x - P_M x - \langle x - P_M x, m \rangle m, m \rangle \\
        &= C( \langle x - P_M x, m \rangle - \langle x - P_M x, m \rangle \| m \|) \\
        &= 0.
    \end{align*}
    
    So $\| x - P_M x \|^2 = \| x - m' \|^2 + | \langle x - P_M x, m \rangle |^2$.  So $\| x - P_M x \|^2 \geq \| x - P_M x\|^2 + | \langle x - P_M x, m \rangle |^2$ by definition of $P_M x$.  Thus, \[
        \langle x - P_M x, m \rangle = 0 
    \] and thus $x - P_M x \in M^\perp$.
\end{proof}

\begin{thm}
    The following theorem is the key fundamental result.  
    Let $\hilb$ be a Hilbert space.  Let $M$ be a closed subspace of $\Hil$.  Then \[
         \Hil = M \oplus M^\perp.
    \]  That is, each $x \in \Hil$ can be written in exactly one way as $x = m + m^\perp$ with $m \in M$, $m^\perp \in M^\perp$. 
\end{thm}

\begin{proof}
    \textbf{Existence} - Let $x = P_m x + ( x - P_M x)$. 
    
    \textbf{Uniqueness} - Let $x = x_1 + x_1^\perp$, $x = x_2 + x_2^\perp$ with $x_1, x_2 \in M, x_1^\perp, x_2^\perp \in M^\perp$
.  Then \[
    x_1 -x_2 = x^\perp_2 - x_1^\perp \in M^\perp
\] Then \[
    \langle x_1 - x_2, x_1 - x_n \rangle = 0 \Rightarrow x_1 = x_2 .  
\] Thus $x_1^\perp = x_2^\perp$.
\end{proof} 

\begin{cor}
    Let $M \subseteq \Hil$ be a closed subspace.  Then we have
    \begin{enumerate}[(a)]
        \item $P_M \in \mathcal{L}(\Hil, \Hil)$.
        \item $\| P_M \| \leq 1$.
        \item $\text{Im}P_m = M, \ker P_M = M^\perp$.
        \item $P^2_M = P_M$.
        \item $P_{M^\perp} = I - P_M$.
    \end{enumerate} 
\end{cor}
\begin{proof}
    (c), (d), (e) exercises.  
    
    (a).  Let $x,y \in H$.  Write $x = x_1 + x^\perp_1$ and $y = y_1 + y_1^\perp$ with $x_1, y_1 \in M$ and $x_1^\perp, y_1^\perp \in M^\perp$.  Then \[
        x = y = (x_1 + y_1) + (x^\perp_1 + y^\perp_1)
    \] and so \[
        P_M(x+y) = x_1 + y_1
    \] and similarly $P_M(\alpha x) = \alpha P_M x$.  We also have 
    \begin{align*}
        \| x \|^2   &= \|P_M x + (x - P_M x) \|^2 \\
                    &= \| P_M x \|^2 + \| x - P_M x \|^2 \\
                    \geq  \| P_M x \|^2 
    \end{align*} and so $\| P_M \| \leq 1$.  
\end{proof}

\subsection{The dual of a Hilbert space} % (fold)
\label{sub:the_dual_of_a_hilbert_space}

If $y \in \Hil$ is fixed, then the map \mapping{\phi_y}{\Hil}{\K}{x}{\langle x, y \rangle} is in $\Hil'$.  Linearity is clear, and continuity is proven by Cauchy-Swartz, \[
    | \phi_y(x) | = | \langle x, y \rangle | \leq \| y \| \| x \|.
\] So $\| \phi_y \| \leq \| y \|$. Since $|\phi_y(y)| = \| y \|^2$, we then have \[
    \| \phi_y \| = \| y \|.
\]

\begin{thm}[Riesz Representation Theorem]
    Let $\Hil$ be a Hilbert space. The map \mapping{\theta}{\Hil}{\Hil'}{y}{\phi_y} is a conjugate linear bijection, and $\| \phi_y \| = \| y \|$.  
\end{thm}
\begin{proof}
    Conjugate linearity is clear.
    
    \textbf{Injectivity} 
    \begin{align*}
        \phi_y = \phi_{y'} \Rightarrow \phi_y(x) = \phi_{y'}(x) \quad \forall x
    \end{align*} so \[
        \langle x, y = \langle x, y' \rangle  = 0 \quad \Rightarrow \langle y - y', y - y' \rangle = 0
    \] and so $y = y'$.
    
    \textbf{Surjectivity}
    Let $\phi \in H'$.  We now find $y \in \Hil$ with $\phi = \phi_y$.  If $\phi = 0$, take $y = 0$.  Suppose $\phi \neq 0$.  Then $\ker \phi \neq \Hil$.  But $\ker \phi$ is a closed subspace of $\Hil$.  So \[
        H = (\ker \phi) \oplus (\ker \phi)^\perp.
    \] Hence $(\ker \phi)^\perp \neq \{ 0 \}$. Pick $z \in (\ker \phi)^\perp, z \neq 0$.  For each $x \in \Hil$, the element \[
        x - \frac{\phi(x)}{\phi(z)} z \in \ker \phi
    \] Note that $\phi(z) \neq 0$ since $z \notin \ker \phi$.  Then \begin{align*}
        0   &=  \langle x - \frac{\phi(x)}{\phi(z)}z, z \rangle \\
            &= \langle x, z - \frac{\phi(x}{\phi(z)} \| z \|^2
    \end{align*}
    and so \[
    \phi(x) = \langle x, \frac{\overline{\phi(z)}}{\| z \|^2} z \rangle \quad \forall x \in \Hil,\]
    and so letting $y = \frac{\overline{\phi(z)}}{\| z \|^2} z$, we have $\phi = \phi_y$.  
\end{proof}

\begin{ex}
    From Hahn-Banach given $y \in \Hil$ there exists $\phi \in \Hil'$ such that \[
        \| \phi \| = 1
    \] and $\phi(y) = \| y \|$. We can be very constructive in the Hilbert case, and let \[
        \phi(x) = \langle x, \frac{y}{\| y \|} \rangle
    \] 
\end{ex}
\begin{ex}
    All continuous linear functionals on $L^2([a,b])$ are of the form \[
        \phi(f) = \int_a^b f(x) \overline{g(x)} \, dx 
    \] for some $g \in L^2([a,b])$.
\end{ex}

\begin{ex}[Adjoint operators]
    Let $\Hil_1, \Hil_2$ be Hilbert spaces.  Let $ T \in \mathcal{L}(\Hil_1, \Hil_2)$.  The \textbf{adjoint} of $T$ is $T^\star \in \mathcal{L}(\Hil_2, \Hil_1)$ given by \[
        \langle T x, y \rangle_2 = \langle x, T^\star y \rangle_1
    \] for all $x \in \Hil_1, y \in \Hil_2$
\end{ex}

\begin{exer}
    Check all of the above.
\end{exer}

\begin{exer}
    Prove $T^\star = \overline{T^t}$ where $T^t$ is the transpose.   
\end{exer}
% subsection the_dual_of_a_hilbert_space (end)
% section lecture_9_monday_28_march (end)

\section{Lecture 10 - Wednesday 30 March} % (fold)
\label{sec:lecture_10_wednesday_30_march}

\begin{dfn}[Orthonormal system]
    As subset $S \subseteq \Hil$ is an \textbf{orthonormal system} (orthonormal) if \[
        \langle e, e' \rangle = \delta_{e, e'} \quad \forall e, e' \in S
    \]
\end{dfn}

\begin{dfn}[Complete orthonormal system or Hilbert basis]
    An orthonormal system $S$ is \textbf{complete} or a \textbf{Hilbert basis} if \[
        \overline{\spans S} = \Hil
    \]
\end{dfn}

\begin{rem}
    By Gram-Schmidt and Zorn's Lemma, every Hilbert space has a complete orthonormal system.   
\end{rem}

\begin{ex}
    \begin{enumerate}
        \item $\ell^2$.  Then \[
            S = \{ e_i \, | \, i \geq 1 \}
        \] is orthonormal and is complete.  
        \item $L^2_\Com([0, 2 \pi])$.  Then \[
            S = \{ \frac{1}{2\pi} e^{i n t} \, | \, n \in \Z \}
        \] is orthonormal and is complete.  Completeness follows from Stone-Weierstrass theorem.
        \item $L^2_\R([0, 2 \pi])$.  Then \[
            S= \{ \frac{1}{\sqrt{2\pi}}, \frac{1}{\sqrt{\pi}} \cos nt, \frac{1}{\sqrt{\pi}} \sin nt \, | \, n \geq 1 \}
        \] is orthonormal and is complete, again by Stone-Weierstrass.  
    \end{enumerate}
\end{ex}

    We want to look at series $\sum_{e \in S} ...$, which is tricky if $S$ is not countable.

\begin{lem}\label{lem:tod}
    If $\{ e_k \, | \, k \geq 0 \}$ is orthonormal, then \[
        \sum_{k=0}^\infty a_l e_k
    \] converges in $\Hil$ if and only if \[
        \sum_{k=0}^\infty |a_k |^2
    \] converges in $\K$.  
    
    If either series converges, then \[
        \left\| \sum_{k=0}^\infty a_k e_k \right\|^2 = \sum_{k=0}^\infty | a_k |^2
    \]
\end{lem}

\begin{note}
    If $x_n \rightarrow x,y_n \rightarrow y$, then \[
        \langle x_n, y_n \rangle \rightarrow \langle x, y \rangle
    \]
\end{note}


\begin{proof}
    If $\sum_{k=0}^\infty a_k e_k$ converges to $x$, then \begin{align*}
        \langle x, x \rangle &= \lim_{n \rightarrow \infty} \langle \sum_{k=0}^n a_k e_k, \sum_{k=0}^n a_k e_k \rangle \\
        &= \lim_{n \rightarrow \infty} \sum_{k=0}^n | a_k |^2
    \end{align*}
    
    Conversely, if $\sum_{k=0}^\infty |a_k |^2$ converges, then writing $x_n = \sum_{k=0}^n a_k e_k$, we have \begin{align*}
        \| x_m - x_n \|^2 &= \| \sum_{k=n+1}^m a_k e_k \|^2 \\
                        &= \sum_{k=n+1}^m \| a_k e_k \|^2 \, \text{by Pythagoras} \\
                        &= \sum_{k=n+1}^m |a_k |^2 \rightarrow 0
    \end{align*} and so $(x_n)$ is Cauchy, and hence converges by completeness of $\Hil$.  
\end{proof}

\begin{lem}
    Let $\{ e_1, \dots, e_n \}$ be orthonormal. Then \[
        \sumkn | \iprod{x, e_k} |^2 \leq \|x\|^2 
    \] for each $x \in \Hil$.  
\end{lem}
\begin{proof}
    Let $y = \sumkn \iprod{x, e_k} e_k$.  Let $z = x-y$.  We claim that $z \perp y$.  We have 
    \begin{align*}
        \iprod{x,y} &= \iprod{x-y, y} \\
                    &= \iprod{x,y} - \| y \|^2 \\
                    &= \sumkn \overline{\iprod{x,e_k}} \iprod{x, e_k} - \sumkn | \iprod {x, e_k} |^2 \\
                    &= 0.
    \end{align*}
    So \begin{align*}
        \| x \|^2   &= \|y + z \|^2 \\
                    &= \| y \|^2 + \| z \|^2 \, \text{Pythagoras} \\
                    &\geq \|y \|^2 = \sumkn | \iprod{x, e_k} |^2
    \end{align*} 
\end{proof}

We want to write expressions like $\sum_{e \in S} \iprod{x, e} e$.
\begin{cor}
    Let $x \in \Hil$ and $S$ orthonormal.  Then \[
        \{ e \in S \, | \, \iprod{x, e} \neq 0 \}
    \] is countable.  
\end{cor}

\begin{proof}
    \[
        \{ e \in S \, | \, \iprod{x, e} \neq 0 \} = \bigcup_{k \geq 1} \{ e \in S \, | \, |\iprod{x, e} | > \frac{1}{k}
    \] From the lemma, \[
        \# \{ e \in S \, | \, | \iprod{x,e} | > \frac{1}{k} \} \leq k^2 \| x ^2 \|
    \] For if this number were greater than $k^2 \| x \|^2$, then the LHS in Lemma is greater than $\frac{1}{k^2}k^2 \| x \|^2$.  
\end{proof} 


















\section{PDE}
\label{PDENotes}
Recall the notion of an ordinary differential equation.

We are given an open interval $I = (a,b) \subset \Rbb$ in the real numbers, $k \in \Nbb = \{1,2,3,\ldots\}$.\footnote{Notation: $\Nbb = \{1,2,3,4,\ldots\}$, $\Nbb_0 = \{0\} \cup \Nbb$.} We look for functions $f: I \to J \subset \Rbb$ (where $J$ is an open interval) that satisfy a given relation between the values and the derivatives:
\begin{equation}
F\big(x, f(x), f'(x), f''(x), f^{(3)}(x), \ldots, f^{(k)}(x)\big) = 0
\label{DefODE}
\end{equation}
where $F: I \times J \times \Omega \to \Rbb$ (with $\Omega \subset \Rbb^k$ open) is a certain given function. \eqref{DefODE} is an \textcolor{blue}{ordinary differential equation} (ODE) in \textcolor{blue}{``implicit form''}.

To be more general, we can consider systems of ODE: we replace $f$ by a vector valued function $f: I \to U \subset \Rbb^m$ and $F$ by $F: I \times U \times \Omega \to \Rbb^m$, where $\Omega$ is an open subset of $\underbrace{\Rbb^m \times \dots \times \Rbb^m}_{\text{$k$ times}} = \Rbb^{km}$. Then \eqref{DefODE} still makes sense and defines a general system of ODE.

If possible, we write \eqref{DefODE} in \textcolor{blue}{explicit form}
\begin{equation}
f^{(k)}(x) = G\big(x, f(x), \ldots, f^{(k-1)}(x)\big)
\label{ExplicitODE}
\end{equation}
and one requires \textcolor{blue}{initial conditions}
\begin{equation}
f^{(\ell)}(x_0) = y_\ell \quad (\ell = 0, \ldots, k-1)
\label{InitCondODE}
\end{equation}
for some $x_0 \in I$ and $y_\ell \in \Rbb^m$.

If $G$ is ``nice'' (e.g. satisfies a Lipschitz condition or the even stronger condition of being differentiable) one has a good solution theory of \eqref{ExplicitODE} and \eqref{InitCondODE}. For functions satisfying a Lipschitz condition, existence and uniqueness of solutions is guaranteed by the Picard-Lindelöf theorem.

The situation is easier if \eqref{DefODE} or \eqref{ExplicitODE} depends linearly on $f, f', \ldots, f^{(k)}$. For $n=1$, \eqref{DefODE} becomes
\[
\sum_{\ell=0}^k a_\ell(x) f^{(k - \ell)} (x) + b(x) = 0
\]
where $a_\ell(x)$ and $b(x)$ are coefficients. In the easiest case, these coefficients do not depend on $x$.

\subsection*{Partial differential equations}

Consider similar relations that depend on partial derivatives (in different directions) up to a certain order of functions of several variables.

A simple but important example is the following: for $U \subset \Rbb^n$ open, we look for \textcolor{blue}{``harmonic functions''}, that means functions $f: U \to \Rbb$ or $\Com$ that satisfy the \textcolor{blue}{``Laplace equation''}
\begin{equation}
\sum_{i=1}^{n} \frac{\partial^2 f}{\partial x_i^2} (x) = 0.
\label{LaplaceEq}
\end{equation}
We introduce
\[
\Delta: C^2(U) \to C(U)
\]
(where $C^2(U)$ stands for twice continuously differentiable functions on $U$ and $C(U)$ for continuous functions on $U$) by
\[
\Delta f(x) = \sum_{i=1}^n \frac{\partial^2 f}{\partial x_i^2} (x).
\]
$\Delta$ is called the \textcolor{blue}{Laplace operator}\footnote{We have $\Delta = \nabla \cdot \nabla$ where $\nabla = \operatorname{grad}$ denotes the gradient of a function.}. We can write \eqref{LaplaceEq} as $\Delta f = 0$.

For given $g \in C(U)$ one can also consider the \textcolor{blue}{``nonhomogeneous Laplace equation''} or \textcolor{blue}{``Poisson equation''}
\begin{equation}
\Delta f(x) = g(x)
\label{PoissonEq}
\end{equation}
or shortly $\Delta f = g$.

In general, we consider
\begin{equation}
F\left(x, f(x), \frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n}, \ldots, \frac{\partial^2 f}{\partial x_i x_j}, \ldots, \frac{\partial^k f}{\partial x_{i_1} \ldots \partial x_{i_k}}\right) = 0.
\label{GeneralPDE}
\end{equation}

The equation is called linear, if $F$ depends linearly on $f$ and all its partial derivatives.
For example, \eqref{LaplaceEq} and \eqref{PoissonEq} are linear. Examples of non-linear equations (with $f : \Rbb^2 \to \Com$):
\begin{itemize}
	\item $\frac{\partial f}{\partial x_1} \frac{\partial f}{\partial x_2} = 0$,
	\item $\det \left( \frac{\partial^2 f}{\partial x_i \partial x_j} \right)_{i,j} = 0$,
	\item $\Delta f = f^k$ with $k \neq 1$. (Here $f^k$ denotes the $k$\textsuperscript{th} power of $f$ rather than the $k$\textsuperscript{th} derivative.)
\end{itemize}

Instead of initial conditions one often considers a kind of \textcolor{blue}{boundary conditions}. We fix the value of $f$ (and some derivatives of $f$) on $N$ where $N \subset U$ is a submanifold of codimension 1 (i.e. parametrized by $n-1$ variables).

We can also consider systems of equations like \eqref{GeneralPDE}.

\subsection*{Differences to the theory of ODE}

\begin{itemize}
	\item There exists no general solution theory.
	\item Non-linear equations are especially difficult. Usually one compares them with linear equations. They will not appear in this course.
	\item There is no easy way to reduce higher order equations to first order ones. Most interesting PDE have second order.
\end{itemize}

\subsection*{Tools}

\begin{enumerate}
	\item For specific PDE one has a number of computational tricks.
	\item In some situations, one can use separation of variables and reduction to ODE.
	\item For linear equations there is a more conceptual approach.
Consider differential operators $D$, e.g. $D = \Delta = \sum_{i=1}^n \frac{\partial^2 f}{\partial x^2_i}$, as linear operators between infinite dimensional vector spaces of functions
\[
D: H_1 \to H_2
\]
where $H_1$ and $H_2$ are both contained in a bigger space $H$ (for instance a Hilbert space). Use tools of functional analysis to understand properties of $D$. In particular:
\begin{itemize}
	\item theory of Fourier series and Fourier transform (Fourier integral);
	\item spectral theory of operators on Hilbert spaces.
\end{itemize}
\end{enumerate}

\subsection*{Rough program of the course}

\begin{enumerate}
	\item The Fourier transform on $\Rbb^n$.
	\item The classical second order equations (Laplace/Poisson, Heat equation, Wave equation).
	\item Spectral theory of linear operators on Hilbert spaces.
\end{enumerate}

\section{The Fourier transform on $\Rbb^n$}
\subsection{Reminder and motivation: Fourier series}\label{sec:FourierSeries}

For $p \in [1,\infty)$, we consider the space
\[
L^p([-\pi,\pi]) = \left\{ f \colon [-\pi,\pi] \to \Com \;\left|\; \text{$f$ measurable, } \int_{-\pi}^\pi \abs{f(x)}^p \dx < \infty \right\} \right/ \sim
\]
of all measurable functions from $[-\pi,\pi]$ to $\Com$ that are integrable to power $p$ with respect to the Lebesgue measure, modulo the equivalence relation $\sim$ defined by
\[
f_1 \sim f_2 \iff f_1(x) = f_2(x) \text{ for almost all $x \in [-\pi,\pi]$.}
\]
Equivalent functions are identical in $\Lper{p}$.

For any $p\in [1,\infty)$, the space $\Lper{p}$ is a Banach space for the norm defined by
\[
\norm{f}_p = \left( \int_{-\pi}^\pi \abs{f}^p \dx \right)^{1/p}
\]
This norm is called the $L^p$-norm.

When $p = 2$, $\Lper{2}$ is a Hilbert space with scalar product
\[
\scalprod{f}{g} = \int_{-\pi}^\pi f(x) \overline{g(x)} \dx.
\]

We consider the space of all square-summable complex sequences
\[
L^2(\Zbb) := \bigg\{ \{c_n\}_{n \in \Zbb} \in \Com^\Zbb \;\bigg|\; \sum_{n=-\infty}^\infty \abs{c_n}^2 < \infty \bigg\}.
\]

For an integrable function $f \in \Lper{1}$ and an integer $n \in \Zbb$, we define the $n$\textsuperscript{th} Fourier coefficient of $f$ by
\[
c_n(f) = \frac{1}{2\pi} \int_{-\pi}^\pi f(x) e^{-inx} \dx \in \Com.
\]

Since $[-\pi,\pi]$ has finite measure, we have $\Lper{2} \subset \Lper{1}$, and therefore the above definition of Fourier coefficients has a sense for all $f \in \Lper{2}$.
By Riesz-Fischer theorem, the spaces $\Lper{2}$ and $L^2(\Zbb)$ are related in the following way:

\begin{fact}
If $f \in \Lper{2}$, then the Fourier series
\[
\sum_{n=-\infty}^\infty c_n(f) e^{inx}
\]
converges to $f$ with respect to the $L^2$-norm.
Conversely, for any sequence $\{c_n\}_{n \in \Zbb} \in L^2(\Zbb)$, there is a function $f \in \Lper{2}$ with $c_n(f) = c_n$ for all $n \in \Zbb$.
\end{fact}

%\begin{itemize}
%	\item If $f \in \Lper{2}$, then the Fourier series
%	\[
%	\sum_{n=-\infty}^\infty c_n(f) e^{inx}
%	\]
%	converges to $f$ with respect to the $L^2$-norm.
%	\item Conversely, for any sequence $(c_n) \in L^2(\Zbb)$, there is a %function $f \in \Lper{2}$ with $c_n(f) = c_n$ for all $n \in \Zbb$.
%\end{itemize}
%If $f \in \Lper{2}$, then the Fourier series
%\[
%\sum_{n=-\infty}^\infty c_n(f) e^{inx}
%\]
%converges to $f$ with respect to the $L^2$-norm and for any sequence $(c_n) \in L^2(\Zbb)$ (where $L^2(\Zbb) := \{(c_n) \mid n \in \Zbb, \sum_{n=-\infty}^\infty \abs{c_n}^2 < \infty\}$), there is a function $f \in \Lper{2}$ with $c_n(f) = c_n$ for all $n \in \Zbb$.

It is a consequence of the fact that the family of functions
\[
\left\{ \frac{1}{\sqrt{2\pi}} e^{inx} =: f_n \;\bigg|\; n \in \Zbb \right\}
\]
is a \textcolor{blue}{complete orthonormal system} in the Hilbert space $\Lper{2}$, i.e.
\begin{itemize}
	\item
		$\scalprod{f_n}{f_m} = \delta_{nm} =
		\begin{cases}
		1 & n=m \\
		0 & n \neq m
		\end{cases}$,
		and
	\item $\spans_\Com \{ f_n \mid n \in \Zbb \}$ is dense in $\Lper{2}$.
\end{itemize}

For several variables we may look at the cube $[-\pi,\pi]^n \subset \Rbb^n$. We can consider $\Lpern{p}$, $p \in \{1,2\}$, with respect to the Lebesgue measure. Functions in $\Lpern{p}$ may be viewed as functions on $\Rbb^n$ that are $2\pi$-periodic in each variable.

\begin{fact} If we define for $\nbf \in \Zbb^n$
\[
f_\nbf(x) := \frac{1}{(2\pi)^{n/2}} e^{i \scalprod{\nbf}{x}}
\]
then $\{ f_\nbf \mid \nbf \in \Zbb^n \}$ is a complete orthonormal system of the Hilbert space $\Lpern{2}$.
\end{fact}

It follows that the Fourier series $\sum_{\nbf \in \Zbb^n} c_\nbf(f) e^{i \scalprod{\nbf}{x}}$ converges to $f$, where $f \in \Lpern{2}$ and
\[
c_\nbf(f) = \frac{1}{(2\pi)^{n/2}} \scalprod{f}{f_\nbf}_{\Lpern{2}} = \frac{1}{(2\pi)^n} \int_{[-\pi,\pi]^n} f(x) e^{-i \scalprod{\nbf}{x}} \dx.
\]
Conversely, for all $(c_\nbf)_{\nbf \in \Zbb^n} \in L^2(\Zbb^n)$ (with respect to counting measure) there is a function $f \in \Lpern{2}$ with $c_\nbf(f) = c_\nbf$.

Another way to express the result is

\begin{thm}
The assignment
\[
\Lpern{2} \ni f \mapsto \widehat{f} \in L^2(\Zbb^n),
\]
where
\[
\widehat{f}(\nbf) = \scalprod{f}{f_\nbf} = (2\pi)^{n/2} c_\nbf(f) = \frac{1}{(2\pi)^{n/2}} \int_{[-\pi,\pi]^n} f(x) e^{-i \scalprod{\nbf}{x}} \dx,
\]
is a unitary\footnote{Unitary means that it preserves the scalar product.} bijection of Hilbert spaces.
\end{thm}

The importance of this result from the point of view of differential equations consists in the following observations:

%(i) \textcolor{red}{$f_\nbf$ are eigenfunctions of constant coefficient differential operators.}
(i) \textsl{$f_\nbf$ are eigenfunctions of constant coefficient differential operators.}

Indeed, we have
\[
\frac{\partial}{\partial x_j} f_\nbf = i \nbf_j f_\nbf.
\]
This means that $f_\nbf$ is an eigenvector of the operator $\frac{\partial}{\partial x_j}$ with eigenvalue $i \nbf_j \in \Com$.

(ii) \textsl{The map $f \mapsto \widehat{f}$ can be seen as a diagonalization of these operators.}


%\begin{itemize}
%	\item $f_\nbf$ are eigenfunctions of constant coefficient differential operators.
%	\item The map $f \mapsto \widehat{f}$ can be seen as a diagonalization of these operators.
%\end{itemize}

Let $\alpha = (\alpha_1, \ldots, \alpha_n) \in \Nbb_0^n$ be a multi-index.\footnote{We use the standard multi-index notation. For $\alpha = (\alpha_1, \ldots, \alpha_n) \in \Nbb_0^n$ and $x = (x_1, \ldots, x_n) \in \Com^n$, we denote $\abs{\alpha} = \alpha_1 + \alpha_2 + \dots + \alpha_n$, $D^\alpha = \frac{\partial^{\abs{\alpha}}}{\partial x_1^{\alpha_1} \dots \partial x_n^{\alpha_n}}$ and $x^\alpha = x_1^{\alpha_1} x_2^{\alpha_2} \dots x_n^{\alpha_n}$.} Then
	\[
	D^\alpha f_\nbf = (i\nbf)^\alpha f_\nbf.
	\]
Now let $f \in \Cperinfty(\Rbb^n) \subset \Lpern{2}$ be a smooth function that is $2\pi$-periodic in each variable. Then
	\begin{align}
	\widehat{D^\alpha f}(\nbf)
	&= \frac{1}{(2\pi)^{n/2}} \int_{[-\pi,\pi]^n} (D^\alpha f)(x) e^{-i \scalprod{\nbf}{x}} \dx \nonumber \\
	&= (-1)^{\abs{\alpha}} \frac{1}{(2\pi)^{n/2}} \int_{[-\pi,\pi]^n} f(x) D^\alpha e^{-i \scalprod{\nbf}{x}} \dx \label{eqPartialIntegration} \\
	%&\quad \uparrow \text{(by partial integration, boundary terms cancel by pariodicity)} \\
	%\intertext{(by partial integration; boundary terms cancel by periodicity)}
	&= (-1)^{\abs{\alpha}} (-i\nbf)^\alpha \widehat{f}(\nbf)
	= (i\nbf)^\alpha \widehat{f}(\nbf) \nonumber
	\end{align}
	where the passage to line \eqref{eqPartialIntegration} follows from partial integration (boundary terms cancel by periodicity).
	We have thus proved that
	\[
	\widehat{D^\alpha f}(\nbf) = (i\nbf)^\alpha \widehat{f}(\nbf).
	\]
If $P$ is a polynomial (of degree $k$) on $\Rbb^n$ then $P$ can be written as
	\[
	P(x) = \sum_{\substack{\alpha \in \Nbb_0^n \\ \abs{\alpha} \leqslant k}} a_\alpha x^\alpha
	\]
	for some coefficients $a_\alpha \in \Com$. We denote $P(D)$ the corresponding constant coefficient differential operator:
	\[
	P(D) = \sum_{\substack{\alpha \in \Nbb_0^n \\ \abs{\alpha} \leqslant k}} a_\alpha D^\alpha.
	\]
	Then we get
	\[
	\widehat{P(D)f} = P(i\nbf) \widehat{f}.
	\]

The general inhomogeneous linear PDE with constant coefficients has the form
\[
P(D)f = g,
\]
where $g$ is given and we want to find $f$. We assume that $g$ is $2\pi$-periodic. We look for $2\pi$-periodic solutions $f$. We obtain
\[
\widehat{g} = \underbrace{P(i\nbf)}_{=:Q(\nbf)} \widehat{f} = Q \widehat{f}
\]
and then
\[
\text{``} \widehat{f} = \frac{1}{Q} \widehat{g} \text{''}
\]
if this makes sense as an $L^2$-function on $\Zbb^n$, otherwise the equation will have no solution.
In periodic functions, let us denote the inverse transform to $f \mapsto \widehat{f}$ by $h \mapsto \check{h}$. Then we get
	\[
	f = \check{\frac{1}{Q} \widehat{g}}.
	%f = \check{\frac{1}{Q} \widehat{g}}.
	\]

\section{Definition of the Fourier transform and Schwartz functions}

We have seen that Fourier coefficients of $2\pi$-periodic functions in $n$ variables are integrals against joint periodic eigenfunctions of $\frac{\partial}{\partial x_1}, \frac{\partial}{\partial x_2}, \ldots, \frac{\partial}{\partial x_n}$. If we drop the periodicity condition, all such eigenfunctions are given by $f_\lambda$, $\lambda \in \Com^n$, where \[
f_\lambda(x) = e^{i \scalprod{\lambda}{x}}.
\]
Indeed: $\frac{\partial}{\partial x_k} f_\lambda = i\lambda_k f_\lambda$. The function $f_\lambda$ is bounded if and only if $\lambda \in \Rbb^n$.

\begin{dfn}\label{def:FourierTransform}
For a function $f \in L^1(\Rbb^n)$ and $\xi \in  \Rbb^n$ we define
\[
\widehat{f} (\xi) = \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} f(x) e^{-i \scalprod{\xi}{x}} \dx \in \Com.
\]
The function $\widehat{f} \colon \Rbb^n \to \Com$ is called the \textcolor{blue}{Fourier transform of $f$}.
\end{dfn}

\begin{rem}
(a) Since $\abs{f(x) e^{-i\scalprod{\xi}{x}}} = \abs{f(x)}$, the function $x \mapsto f(x) e^{-i\scalprod{\xi}{x}}$ is integrable in the sense of Lebesgue.
%This means that the above definition of $\widehat{f}(\xi)$ has a sense.
This means that the Fourier transform $\widehat{f}(\xi)$ is well-defined.

(b) For all $\xi \in \Rbb^n$, we have
	\[
	\abs{\widehat{f}(\xi)} \leqslant \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \abs{f(x) e^{-i\scalprod{\xi}{x}}} \dx = \frac{1}{(2\pi)^{n/2}} \norm{f}_{L^1}.
	\]
	It follows that $\widehat{f}$ is bounded on $\Rbb^n$ (provided $f \in L^1(\Rbb^n))$.

(c) For all $f \in L^1(\Rbb^n)$, the Fourier transform $\widehat{f}$ is continuous.
\end{rem}

Our goal is to define $\widehat{f}$ for any function in the Hilbert space $L^2(\Rbb^n)$. The problem is that $L^2(\Rbb^n) \not\subset L^1(\Rbb^n)$. The way out will be to look at a smaller space $\S(\Rbb^n)$ which is dense both in $L^1(\Rbb^n)$ and $L^2(\Rbb^n)$ and to extend the Fourier transform from $\S(\Rbb^n)$ to $L^2(\Rbb^n)$ by continuity. For this purpose, we will define the Schwartz space\footnote{Laurent Schwartz, 1915--2002.} of rapidly decreasing functions:

\begin{dfn}
A function $f \colon \Rbb^n \to \Com$ is called a \textcolor{blue}{Schwartz function} or \textcolor{blue}{rapidly decreasing function} if and only if the two following properties are satisfied:
%\begin{enumerate}
%	\item $f$ is smooth and
%	\item for all $N \in \Nbb_0$ and for all multi-indeces $\alpha = (\alpha_1, \ldots, \alpha_n)$, there exists a constant $C = C_{N,\alpha}$ such that

(a) $f$ is smooth,

(b) for all $N \in \Nbb_0$ and for all multi-indices $\alpha = (\alpha_1, \ldots, \alpha_n) \in \Nbb_0^n$, there exists a constant $C = C_{N,\alpha}$ such that
	\[
	(1 + \abs{x}^2)^N \abs{D^\alpha f(x)} \leqslant C
	\]
	for all $x \in \Rbb^n$.
%\end{enumerate}

The space of all such functions is called the \textcolor{blue}{Schwartz space on $\Rbb^n$} and denoted by $\S(\Rbb^n)$.
\end{dfn}

In other words, a smooth function $f$ is a Schwartz function if $f$ and all its partial derivatives of any order approach zero at infinity faster than the inverse of any polynomial function.

The condition (b) of the preceding definition can be also expressed in the following way: for any multi-indices $\alpha, \beta \in \Nbb_0^n$, we have
\[
\sup_{x \in \Rbb^n} \abs{x^\alpha D^\beta f(x)} < \infty.
\]

%It is easy to show that $\S(\Rbb^n)$ is a vector space.
\begin{rem}
The following properties are immediate consequences of the definition.

(a) The Schwartz space $\S(\Rbb^n)$ is a vector space.

(b) For any multi-indices $\alpha, \beta \in \Nbb_0^n$, the map $f \mapsto \sup_{x \in \Rbb^n} \abs{x^\alpha D^\beta f(x)}$ is a semi-norm on $\S(\Rbb^n)$.

(c) If $f$ is a Schwartz function, then all partial derivatives of $f$ of any order are Schwartz functions as well.

%(d) The product of a Schwartz function by any polynomial function is again a Schwartz function.
(d) Let $f,g \in \S(\Rbb^n)$ be two Schwartz functions and let $P$ be a polynomial function. Then the pointwise products $fg$ and $Pf$ are also Schwartz functions.

(e) If $f \in \S(\Rbb^n)$ then $f$ is uniformly continuous on $\Rbb^n$. It is a consequence of the boundedness of all its partial derivatives.
\end{rem}

\begin{recall}
(a) The \textcolor{blue}{support} $\supp f$ of a continuous function $f \colon X \to \Com$ on a metric space $X$ is defined as the closure of the set $\{ x \in X \mid f(x) \neq 0 \}$. Alternatively, we can define $X \smallsetminus \supp f$ as the union of all open subsets $U \subset X$ such that $f|_U = 0$.

(b) We denote by $C_c(X)$ the set of all continuous functions on $X$ with compact support. If $X \subset \Rbb^n$ is open, we set $C_c^\infty(X) := C_c(X) \cap C^\infty(X)$.
\end{recall}

\begin{lem}\label{SchSubsetLP}
(a) $C_c^\infty(\Rbb^n) \subset \S(\Rbb^n)$.

(b) $\S(\Rbb^n) \subset L^p(\Rbb^n)$ for all $p \in [1,\infty)$.
\end{lem}

\begin{proof}
(a) Checked directly.

%(b) Using polar coordinates it is not difficult to show that $\frac{1}{(1 + \abs{x}^2)^N} \in L^1(\Rbb^n)$ if $N > n/2$. It follows that $\frac{1}{(1 + \abs{x}^2)^N} \in L^p(\Rbb^n)$ if $N^p > n/2$.
(b) Using polar coordinates it is not difficult to show that $1/(1 + \abs{x}^2)^N \in L^1(\Rbb^n)$ if $N > n/2$. This is equivalent to say that $1/(1 + \abs{x}^2)^N \in L^p(\Rbb^n)$ if $Np > n/2$. It follows that if $N > n/2$, then $1/(1 + \abs{x}^2)^N \in L^p(\Rbb^n)$ for all $p \in [1,p)$.

Now let $f \in \S(\Rbb^n)$. Choose $N > n/2$. Since $f$ is a Schwartz function, there exists a constant $C$ such that $(1 + \abs{x}^2)^N \abs{f(x)} \leqslant C$ for all $x \in \Rbb^n$. We have
\[
\abs{f(x)} = \frac{1}{(1 + \abs{x}^2)^N} (1 + \abs{x}^2)^N \abs{f(x)} \leqslant C \frac{1}{(1 + \abs{x}^2)^N} \in L^p(\Rbb^n)
\]
and therefore $f \in L^p(\Rbb^n)$.
\end{proof}

Our goal is to show that $\S(\Rbb^n)$ is dense in $L^p(\Rbb^n)$ with respect to the $L^p$-norm. We will use the fact that $C_c(\Rbb^n)$ is dense in $L^p(\Rbb^n)$. More generally, if $U$ is an open subset of $\Rbb^n$ then $C_c(U)$ is dense in $L^p(U)$.

\begin{thm}\label{SCSdenseLP} %SCS - smooth compact support
Let $U$ be an open subset of $\Rbb^n$ and $p \in [1,\infty)$.
Then $C_c^\infty(U)$ is dense in $L^p(U)$.
\end{thm}

\begin{cor}
$\S(\Rbb^n)$ is dense in $L^p(\Rbb^n)$, $p \in [1,\infty)$.
\end{cor}

\begin{proof}
Combine Lemma~\ref{SchSubsetLP}(a) and Theorem~\ref{SCSdenseLP}.
\end{proof}

\begin{lem}\label{ExistsABumpFunction}
There exists a function $\psi \in C_c^\infty(\Rbb^n)$ that satisfies the following properties:

(a) $\supp \psi \subset \overline{B}(0,1) \subset \Rbb^n$,

%(b) $\psi(x) \in [0,1]$ for all $x \in \Rbb^n$,

(b) $\int_{\Rbb^n} \psi(x) \dx = 1$.

\end{lem}

\begin{proof}
The function $f \colon \Rbb \to [0,1]$ defined by
$
%f(t) =
%\begin{cases}
%e^{-1/t} & t > 0 \\
%0 & t \leqslant 0
%\end{cases}
f(t) = e^{-1/t} \Ind_{\{t>0\}}(t)
$
is smooth. We define $\varphi \colon \Rbb^n \to [0,1]$ by
$
\varphi(x) := f(1 - \abs{x}^2)
$, see Figure~\ref{fig:BumpFunction}.
Then $\varphi$ satisfies (a). Let $\alpha := \int_{\Rbb^n} \varphi(x) \dx \in (0,\infty)$. We set
$
\psi(x) := \frac{1}{\alpha} \varphi(x).
$
\end{proof}

We can now prove Theorem~\ref{SCSdenseLP}. To do this, we will use the technique of smoothing by convolution.

\begin{proof}[Proof of Theorem~\ref{SCSdenseLP}]
Since $C_c(U)$ is dense in $L^p(U)$, and since densiness is transitive, it suffices to show that $C_c^\infty(U)$ is dense in $C_c(U)$.

Let $f \in C_c(U)$. We want to construct a family of functions $h_\varepsilon \in C_c^\infty(U)$, $\varepsilon > 0$, such that
\[
\lim_{\varepsilon \to 0} \norm{f - h_\varepsilon}_p = 0.
\]
Let $0 < \delta \leqslant \dist(\supp f, \Rbb^n \smallsetminus U)$. The inequality $0 < \dist(\supp f, \Rbb^n \smallsetminus U)$ is indeed satisfied because $\supp f$ is compact, $\Rbb^n \smallsetminus U$ is closed and $\supp f \subset U$. Let $\psi$ be as in Lemma~\ref{ExistsABumpFunction}. For $\varepsilon < \delta/2$, we define
\[
h_\varepsilon(x) = \int_{\Rbb^n} f(x - \varepsilon z) \psi(z) \d{}z.
\]
We have to check that $h_\varepsilon \in C_c^\infty(U)$, i.e. that (i) $h_\varepsilon$ has compact support contained in $U$ and (ii) $h_\varepsilon$ is smooth.

(i) We have
$
\supp h_\varepsilon \subset \{ x \mid \dist(x, \supp f) \leqslant \varepsilon\} \subset U
$.\footnote{%
The second inclusion is an immediate consequence of the fact that $\varepsilon < \delta/2$. Let us prove the first inclusion. Set $A:=  \{ x \mid \dist(x, \supp f) \leqslant \varepsilon\}$. Let $a \in \Rbb^n \smallsetminus A$ be arbitrary. Then $\dist(a,\supp f) > \varepsilon$. Therefore $f(a - \varepsilon z) = 0$ if $\abs{z} \leqslant 1$. Since $\psi(z) = 0$ if $\abs{z} > 1$, it follows that $f(a - \varepsilon z) \psi(z) = 0$ for all $z \in \Rbb^n$ and therefore $h_\varepsilon(a) = \int_{\Rbb^n} f(a - \varepsilon z) \psi(z) \d{}z = 0$. Thus $a \in \{x \mid h_\varepsilon(x) =0\}$. We have thus proved that $\Rbb^n \smallsetminus A \subset \{x \mid h_\varepsilon(x) =0\}$, which is equivalent to say that $\{x \mid h_\varepsilon(x) \neq 0\} \subset A$. Since $A$ is closed, it follows that $\supp h_\varepsilon = \overline{\{x \mid h_\varepsilon(x) \neq 0\}} \subset A$.
}
This shows that $\supp h_\varepsilon$ is contained in $U$ and bounded (because $\supp f$ is bounded). It follows that $\supp h_\varepsilon$ is compact.%This shows that $\supp h_\varepsilon \subset U$ is bounded (because $\supp f$ is bounded). It follows that $\supp h_\varepsilon$ is compact.%Since $\supp h_\varepsilon$ is also closed by definition of support, it follows that $\supp h_\varepsilon$ is compact.

(ii) As for the smoothness, let us start by writing the integral defining $h_\varepsilon(x)$ with the change of variables $y = x - \varepsilon z$, $\d{}z = \frac{1}{\varepsilon^n} \d{}y$:
\[
h_\varepsilon(x)
%= \frac{1}{\varepsilon^n} \int_{\Rbb^n} f(y) \psi(\{x-y\}/\varepsilon) \d{}y.
= \frac{1}{\varepsilon^n} \int_{\Rbb^n} f(y) \psi\left(\frac{x-y}{\varepsilon}\right) \d{}y.
\]
That way, the parameter $x$ appears only in the function $\psi$ that we know to be smooth. We are therefore allowed to use the theorem on the differentiation of parameter-dependent integrals which ensures that all (higher) partial derivatives of $h_\varepsilon$ exist and are given by
\[
D^\alpha h_\varepsilon(x)
= \frac{1}{\varepsilon^n} \int_{\Rbb^n} f(y) D^\alpha_x \psi\left(\frac{x-y}{\varepsilon}\right) \d{}y.
\]
It follows that $h_\varepsilon$ is smooth.

It remains to show that $\lim_{\varepsilon \to 0} \norm{h_\varepsilon - f}_p = 0$. Since $f$ is continuous with compact support, $f$ is uniformly continuous, that is,
\[
\forall \eta > 0 \; \exists \varepsilon > 0: \; \abs{x-y} < \varepsilon \Rightarrow \abs{f(x) - f(y)} < \eta.
\]
Let $\eta > 0$, then there exists $\varepsilon > 0$ such that for all $x \in \Rbb^n$, we have
\begin{align*}
	\absbig{h_\varepsilon(x) - f(x)}
	&= \Abs{\int_{\Rbb^n} \{f(x - \varepsilon z) - f(x)\} \psi(z) \d{}z} \\
	&\leqslant \int_{\Rbb^n} \absbig{f(x - \varepsilon z) - f(x)} \psi(z) \d{}z
	\leqslant \eta \int_{\Rbb^n} \psi(z) \d{}z = \eta 
\end{align*}
and therefore
\begin{align*}
	\norm{h_\varepsilon - f}_p^p
	= \int_{\Rbb^n} \absbig{h_\varepsilon(x) - f(x)}^p \dx
	\leqslant \int_{\tilde{K}} \eta^p \dx \leqslant \eta^p \operatorname{vol}(\tilde{K}) = C\eta^p
\end{align*}
where $\tilde{K} := \{x \in \Rbb^n \mid d(x, \supp f) \leqslant \delta/2\}$ is a compact and $C:= \operatorname{vol}(\tilde{K}) < \infty$. Since $\eta$ can be chosen arbitrarily small, this proves that $\lim_{\varepsilon \to 0} \norm{h_\varepsilon - f}_p = 0$.
\end{proof}

\begin{prop}\label{Prop:DifferentiationOfFourierTransform}
Let $f \in \S(\Rbb^n)$ be a Schwartz function. Then the following conditions are satisfied:

(a) $\widehat{D^\alpha f} = (i\xi)^\alpha \widehat{f}(\xi)$,

(b) $\widehat{f} \in \S(\Rbb^n)$,

(c) $D^\alpha_\xi \widehat{f} = \widehat{(-ix)^\alpha f}$.
\end{prop}

\begin{proof}
The formula (a) can be obtained by partial integration as in~\eqref{eqPartialIntegration}, Section~\ref{sec:FourierSeries}. Boundary terms vanish since $f$ and all its partial derivatives go to zero for $\abs{x} \to \infty$.

To prove the remaining two assertions, we first show that $\widehat{f} \in C^\infty(\Rbb^n)$ and that (c) holds. For all $\xi \in \Rbb^n$, we have
\[
\Abs{D^\alpha_\xi e^{-i\scalprod{\xi}{x}} f(x)} = \Abs{(-ix)^\alpha f(x) e^{-i\scalprod{\xi}{x}}} = \absbig{(-ix)^\alpha f(x)} \in L^1(\Rbb^n)
\]
because $(-ix)^\alpha f(x) \in \S(\Rbb^n) \subset L^1(\Rbb^n)$. We can therefore use the theorem on the differentiation of parameter-dependent integrals, which gives
\[
D^\alpha_\xi \widehat{f}(\xi)
= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} D^\alpha_\xi e^{-i \scalprod{x}{\xi}} f(x) \dx
= \widehat{(-ix)^\alpha f}(\xi).
\]
This shows that $\widehat{f} \in C^\infty(\Rbb^n)$ and gives the formula (c).

It remains to show (b). Using successively (c) and (a), we obtain
\[
\xi^\alpha D^\beta_\xi \widehat{f}(\xi)
= \xi^\alpha \widehat{(-ix)^\beta f}(\xi)
= (-i)^{\abs{\alpha}} \widehat{D^\alpha_x ((-ix)^\beta f) } (\xi).
\]
Since $D^\alpha_x((-ix)^\beta f) \in \S(\Rbb^n) \subset L^1(\Rbb^n)$, it follows from the remark~(b) after Definition~\ref{def:FourierTransform} that $\widehat{D^\alpha_x ((-ix)^\beta f) }$ is bounded. Hence, in view of the preceding equality, $\xi^\alpha D^\beta_\xi \widehat{f}$ is bounded as well, i.e. $\sup_{\xi \in \Rbb^n} \absbig{\xi^\alpha D^\beta_\xi \widehat{f}(\xi)} < \infty$. It follows that $\widehat{f} \in \S(\Rbb^n)$.
\end{proof}

\begin{thm}[Fourier inversion]\label{Theo:FourierInversion}
The Fourier transform $\widehat{\phantom{g}}$ restricted to $\S(\Rbb^n)$ is a linear bijection from the space $\S(\Rbb^n)$ to itself. The inverse of $\widehat{\phantom{w}}$ is called the \emph{inverse Fourier transform} and is given by the relation
\begin{equation}\label{eq:FourierInversion1}
f(x) = \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} e^{i\scalprod{x}{\xi}} \widehat{f} (\xi) \d{}\xi
\end{equation}
which is valid for all $f,\widehat{f} \in \S(\Rbb^n)$ such that $\widehat{f}$ is the Fourier transform of $f$.

Moreover, $\widehat{\phantom{g}}$ preserves the scalar product on $L^2(\Rbb^n)$, i.e. for any $f,g \in \S(\Rbb^n)$, we have
\begin{equation}\label{eq:FourierInversion2}
\scalprod{f}{g}_{L^2(\Rbb^n)} = \scalprod{\widehat{f}}{\widehat{g}}_{L^2(\Rbb^n)}.
\end{equation}
\end{thm}

\begin{rem}
The last equality is known as \textcolor{blue}{Parseval's equality}. In particular, we have $\norm{f}_2 = \norm{\widehat{f}}_2$ for all $f \in \S(\Rbb^n)$ and therefore the Fourier transform $\S(\Rbb^n) \ni f \to \widehat{f} \in \S(\Rbb^n)$ is continuous with respect to the $L^2$ norm on both sides.
\end{rem}

In the proof of Theorem~\ref{Theo:FourierInversion}, we will use the following result:

\begin{lem}\label{lemma:GaussianInvariant}
Let $g \colon \Rbb^n \to \Rbb$ be defined by
\[
g(x) = e^{-\frac{\abs{x}^2}{2}}.
\]
Then $g$ is a Schwartz function and is invariant under the Fourier transform, i.e. for all $\xi \in \Rbb^n$, we have
\[
g(\xi) = \widehat{g}(\xi).
\]
\end{lem}

\begin{rem}
(a) In other words, the Lemma sais that $g$ is an eigenfunction of the Fourier transform with eigenvalue 1.

(b) Let $g$ be as in the preceding Lemma. By computing $\widehat{g}(0)$, one finds
\begin{equation}\label{remark:GaussianInvariant}
\int_{\Rbb^n } \widehat{g}(y) \d{}y
= \int_{\Rbb^n } g(x) \d{}x
= (2\pi)^{n/2}.
\end{equation}
\end{rem}

\begin{proof}
It is clear that $g \in \S(\Rbb^n)$. Let us prove that $\widehat{g}(\xi) = g(\xi)$ for all $\xi \in \Rbb^n$.

We have
\begin{align}
	\widehat{g}(\xi)
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} e^{\abs{x}^2/2} \; e^{-i\scalprod{x}{\xi}} \dx \nonumber \\
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \prod_{i = 1}^n \left( e^{-x^2_i / 2 - ix_i \xi_i} \right) \dx \nonumber \\
	&= \frac{1}{(2\pi)^{n/2}} \prod_{i = 1}^n \int_{\Rbb} e^{-x^2_i / 2 - ix_i \xi_i} \dx_i \label{proof:lemma:Gaussian:1}
\end{align}
where the passage to line~\eqref{proof:lemma:Gaussian:1} follows from Fubini's theorem. We have thus expressed $\widehat{g}(\xi)$ as a product of one-dimensional integrals. Therefore it remains to compute
$
\int_\Rbb e^{-t^2 / 2 - its} \d{}t
$
for $s \in \Rbb$.

By completing the square, we obtain $\frac{t^2}{2} + its = \frac{(t+is)^2}{2} + \frac{s^2}{2}$. Therefore
\begin{equation}\label{proof:lemma:Gaussian:2}
\int_{\Rbb} e^{-t^2/2 - its} \d{}t = e^{-s^2/2} \int_{\Rbb} e^{-(t+is)^2/2} \d{}t.
\end{equation}
Furthermore, it is clear that
\[
\int_{\Rbb} e^{-(t+is)^2/2} \d{}t
= \lim_{n \to \infty} \int_{-n}^n e^{-(t+is)^2/2} \d{}t.
\]
By a change of variables, we obtain
\begin{equation}\label{proof:lemma:Gaussian:3}
\int_{-n}^n e^{-(t+is)^2/2} \d{}t
= \int_{-n+is}^{n+is} e^{-z^2/2} \d{}z.
\end{equation}
Let us define the segments $\gamma_1(n) := [n,n+is]$ and $\gamma_2(n) := [-n+is,-n]$ (see Figure~\ref{fig:proof:Gaussian}).
\begin{figure}[b]
\begin{center}
%\includegraphics[angle=90,width=0.5\textwidth]{test}
%\includegraphics[width=0.5\textwidth]{Mollifier_illustration}
\setlength{\unitlength}{1cm}
\begin{picture}(0,2.5)
\put(-4,0){\vector(1,0){8}}% realna osa
\put(0,-0.5){\vector(0,1){3}}% imaginarni osa
\put(2,0){\line(0,1){1.6}}% \gamma_1
\put(-2,0){\line(0,1){1.6}}% \gamma_2
\put(2,0){\vector(0,1){0.8}}% \gamma_1 - sipka
\put(-2,1.6){\vector(0,-1){0.8}}% \gamma_2 - sipka
\put(-2,1.6){\line(1,0){4}}% spojnice [-n+is,n+is]
\put(-2.4,-0.4){$-n$}
\put(2,-0.4){$n$}
\put(0.2,-0.4){$0$}
\put(3.9,-0.4){$\Rbb$}
\put(0.15,2.3){$i\Rbb$}
\put(2.15,0.7){$\gamma_1(n)$}
\put(-3,0.7){$\gamma_2(n)$}
%\put(-3.5,1.8){$-n+is$}
\put(0.2,1.7){$is$}
\end{picture}
\end{center}
\caption{Curves $\gamma_1(n)$ and $\gamma_2(n)$ from the proof of Lemma~\ref{lemma:GaussianInvariant}.}
\label{fig:proof:Gaussian}
\end{figure}
Since the curve $[-n,n] + \gamma_1(n) + [n+is,-n+is] + \gamma_2(n)$ is a closed path in the complex plane and since $z \mapsto e^{\abs{z}^2/2}$ is a holomorphic function, it follows from Cauchy's integral theorem that the integral of $e^{\abs{z}^2/2}$ over this curve is zero, i.e.
\begin{equation}\label{proof:lemma:Gaussian:4}
\int_{-n+is}^{n+is} e^{-z^2/2} \d{}z
= \int_{\gamma_1(n)} e^{-z^2/2} \d{}z
+ \int_{\gamma_2(n)} e^{-z^2/2} \d{}z
+ \int_{-n}^{n} e^{-z^2/2} \d{}z.
\end{equation}
It is easy to show that $\lim_{n \to \infty} \int_{\gamma_i(n)} e^{-z^2/2} \d{}z = 0$ for $i \in \{1,2\}$.\footnote{
Let us show the result for $\gamma_1(n)$ (for $\gamma_2(n)$, the computation is analogous). One can parametrize $\gamma_1(n)$ by $\gamma_1(n)(\tau) = n + i\tau s$, $\tau \in [0,1]$. Then
$
\absbig{\int_{\gamma_1(n)} e^{-z^2/2} \d{}z}
= \absbig{\int_0^1 e^{-(n + i\tau s)^2/2} \abs{s} \d{}\tau}
= \absbig{\int_0^1 e^{-(n^2 + 2in\tau s - \tau^2 s^2)/2} \abs{s} \d{}\tau}
= \absbig{\int_0^1 e^{-n^2/2} e^{-in\tau s} e^{\tau^2 s^2/2} \abs{s} \d{}\tau}
\leqslant \abs{s} e^{-n^2/2} \int_0^1 e^{\tau^2 s^2/2} \d{}\tau \to 0
$
as $n \to \infty$.
}
Taking $n$ to infinity in~\eqref{proof:lemma:Gaussian:3} and~\eqref{proof:lemma:Gaussian:4} therefore gives
\[
\int_\Rbb e^{-(t+is)^2/2} \d{}t = \int_{-\infty}^\infty e^{-z^2/2} \d{}z = 2 \int_0^\infty e^{-z^2/2} \d{}z = \sqrt{2\pi},
\]
and hence \eqref{proof:lemma:Gaussian:2} becomes
\[
\int_\Rbb e^{-t^2 / 2 - its} \d{}t = e^{-s^2/2} \sqrt{2\pi}.
\]
By inserting into~\eqref{proof:lemma:Gaussian:1}, one finds
\[
\widehat{g}(\xi)
= \frac{1}{(2\pi)^{n/2}} \prod_{i=1}^n \sqrt{2\pi} \; e^{-\xi^2_i/2} = e^{-\abs{\xi}^2/2} = g(\xi). \qedhere
\]
\end{proof}

\begin{proof}[Proof of Theorem~\ref{Theo:FourierInversion}]
The main assertion is the formula~\eqref{eq:FourierInversion1}. A na\"{\i}ve approach does not work. Indeed one would like to apply Fubini for the computation of
\begin{align*}
\frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} e^{i\scalprod{x}{\xi}} \int_{\Rbb^n} e^{-i\scalprod{\xi}{y}} f(y) \d{}y \d{}\xi
&\overset{?}{=} \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n \times \Rbb^n} e^{i\scalprod{\xi}{x-y}} f(y) \d{}y \d{}\xi \\
&\overset{?}{=} \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} f(y) \int_{\Rbb^n} e^{i\scalprod{\xi}{x-y}} \d{}\xi \d{}y.
\end{align*}
However, $e^{i\scalprod{\xi}{x-y}} f(y) \notin L^1(\Rbb^n \times \Rbb^n)$ and $e^{i\scalprod{\xi}{x-y}} \notin L^1(\Rbb^n)$ since there is no decay in the variable $\xi$, and therefore the integrals on the right-hand side are not well-defined. One needs some trick.

We choose an auxiliary second function $\varphi \in \S(\Rbb^n)$ and consider
\begin{align}
	\int_{\Rbb^n} \varphi(\xi) \widehat{f} (\xi) e^{i\scalprod{x}{\xi}} \d{}\xi
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \varphi(\xi) e^{i\scalprod{x}{\xi}} \int_{\Rbb^n} e^{-i\scalprod{\xi}{y}} f(y) \d{}y \d{}\xi \nonumber \\
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \varphi(\xi) \int_{\Rbb^n} e^{i\scalprod{x-y}{\xi}} f(y) \d{}y \d{}\xi \nonumber \\
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \int_{\Rbb^n} \varphi(\xi) e^{i\scalprod{x-y}{\xi}} f(y) \d{}\xi \d{}y \label{proof:FourierInversion:1} \\
	&= \int_{\Rbb^n} \widehat{\varphi}(y-x) f(y) \d{}y \nonumber \\
	&= \int_{\Rbb^n} \widehat{\varphi}(z) f(z+x) \d{}z, \nonumber
\end{align}
where the passage to line \eqref{proof:FourierInversion:1} follows from Fubini's theorem. We have thus shown that
\begin{equation}\label{proof:FourierInversion:2}
\int_{\Rbb^n} \varphi(\xi) \widehat{f} (\xi) e^{i\scalprod{x}{\xi}} \d{}\xi
= \int_{\Rbb^n} \widehat{\varphi}(z) f(z+x) \d{}z.
\end{equation}

Now let $g \in \S(\Rbb^n)$ be a Schwartz function. For $\varepsilon > 0$, we set $\varphi_\varepsilon(\xi) := g (\varepsilon\xi)$. By continuity of $g$, we have $\lim_{\varepsilon \to 0} \varphi_\varepsilon \equiv g(0)$. Moreover, since $g \in \S(\Rbb^n)$, there exists a constant $C < \infty$ such that
\[
\sup_{\xi \in \Rbb^n} \varphi_\varepsilon(\xi) = \sup_{\xi \in \Rbb^n} g(\xi) \leqslant C
\]
and therefore
\[
\Abs{\varphi_\varepsilon(\xi) \widehat{f}(\xi) e^{i\scalprod{\xi}{x}}}
\leqslant C \Abs{\widehat{f}(\xi)}
\]
for all $\xi \in \Rbb^n$. Since $\widehat{f} \in \S(\Rbb^n) \subset L^1(\Rbb^n)$, this allows us to use Lebesgue's theorem on dominated convergence, which gives
\begin{align}
	\lim_{\varepsilon \to 0} \int_{\Rbb^n} \varphi_\varepsilon(\xi) \widehat{f}(\xi) e^{i\scalprod{x}{\xi}} \d{}\xi
	= \int_{\Rbb^n} \lim_{\varepsilon \to 0} \varphi_\varepsilon(\xi) \widehat{f}(\xi) e^{i\scalprod{x}{\xi}} \d{}\xi
	= g(0) \int_{\Rbb^n} \widehat{f}(\xi) e^{i\scalprod{x}{\xi}} \d{}\xi.
\label{proof:FourierInversion:3}
\end{align}
On the other hand, we have
\begin{align*}
	\widehat{\varphi}_\varepsilon(z)
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} e^{-i \scalprod{x}{z}} g(\varepsilon x) \dx \\
	&= \frac{1}{(2\pi)^{n/2}} \frac{1}{\varepsilon^n} \int_{\Rbb^n} e^{-i \scalprod{y}{z}/\varepsilon} g(y) \d{}y
	= \frac{1}{\varepsilon^n} \widehat{g}\left(\frac{z}{\varepsilon}\right)
\end{align*}
and therefore
\begin{align*}
	\int_{\Rbb^n} \widehat{\varphi}_\varepsilon(z) f(z+x) \d{}z
	= \frac{1}{\varepsilon^n} \int_{\Rbb^n} \widehat{g}\left(\frac{z}{\varepsilon}\right) f(z+x) \d{}z
	= \int_{\Rbb^n} \widehat{g}(y) f(\varepsilon y + x) \d{}y.
\end{align*}
By applying the theorem on dominated convergence on the preceding equality, we obtain
\begin{equation}
\lim_{\varepsilon \to 0} \int_{\Rbb^n} \widehat{\varphi}_\varepsilon(z) f(z+x) \d{}z
= \int_{\Rbb^n} \widehat{g}(y) f(x) \d{}y
= f(x) \int_{\Rbb^n} \widehat{g}(y) \d{}y.
\label{proof:FourierInversion:4}
\end{equation}
Now observe that the left-hand sides of the equalities~\eqref{proof:FourierInversion:3} and~\eqref{proof:FourierInversion:4} are equal by~\eqref{proof:FourierInversion:2}. It follows that
\begin{equation}
f(x) \int_{\Rbb^n} \widehat{g}(y) \d{}y = g(0) \int_{\Rbb^n} \widehat{f}(\xi) e^{i\scalprod{x}{\xi}} \d{}\xi.
\label{proof:FourierInversion:5}
\end{equation}
Now let $g(x) = e^{-\abs{x^2}/2}$ be defined as in Lemma~\ref{lemma:GaussianInvariant}. By inserting into~\eqref{proof:FourierInversion:5} and using~\eqref{remark:GaussianInvariant}, we obtain
\[
f(x) = \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} e^{i\scalprod{x}{\xi}} \widehat{f}(\xi) \d{}\xi,
\]
which is the formula~\eqref{eq:FourierInversion1}.

The next assertion to show is that $\;\widehat{}\;$ is a linear bijection from $\S(\Rbb^n)$ to itself.
It is easy to see that~$\;\widehat{}\;$ is linear.
The injectivity follows directly from~\eqref{eq:FourierInversion1}. Indeed, let us denote the inverse Fourier transform by $\;\check{}\;$, i.e. for any $f \in \S(\Rbb^n)$, define $\check{f}$ by
\[
\check{f}(x) = \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} e^{i\scalprod{x}{\xi}} f(\xi) \d{}\xi.
\]
Then by~\eqref{eq:FourierInversion1}, we have $\check{\widehat{f}} = f$ for all $f \in \S(\Rbb^n)$ and therefore $\;\widehat{}\;$ is injective.
To show the surjectivity, we start by introducing the following notation: for a function $h \colon \Rbb^n \to \Com$, we define $\widetilde{h} \colon \Rbb^n \to \Com$ by setting $\widetilde{h}(x) := h(-x)$ for all $x \in \Rbb^n$. Now let $g \in \S(\Rbb^n)$ be an arbitrary Schwartz function. We want to find $f \in \S(\Rbb^n)$ such that $\widehat{f} = g$. The function $f := \widetilde{\widehat{g}}$ satisfies this property. Indeed, we have $f \in \S(\Rbb^n)$ and it is easy to check that
\[
\widehat{f} = \widehat{\widetilde{\widehat{g}}} = \check{\widehat{g}} = g.
\]

It remains to show the equality~\eqref{eq:FourierInversion2}, which states that $\;\widehat{}\;$ preserves the scalar product on $L^2(\Rbb^n)$. Inserting $\varphi = \overline{\widehat{g}}$ into~\eqref{proof:FourierInversion:2} and setting $x = 0$ yields
\[
\int_{\Rbb^n} \widehat{f}(\xi) \overline{\widehat{g}(\xi)} \d{}\xi
= \int_{\Rbb^n} \widehat{\overline{\widehat{g}}}(z) f(z) \d{}z.
\]
Using~\eqref{eq:FourierInversion1} one finds $\widehat{\overline{\widehat{g}}} = \overline{g}$. This finishes the proof.
\end{proof}

\section{The Fourier transform on $L^2(\Rbb^n)$}

\begin{recall}
Let $(V,\norm{.}_1)$ and $(W,\norm{.}_2)$ be two (possibly infinite-dimensional) normed vector spaces and let $A \colon V \to W$ be a linear operator. We define the operator norm of $A$ as
\[
\norm{A} := \sup_{v \in V \smallsetminus \{0\}} \frac{\norm{Av}_2}{\norm{v}_1}.
\]
It is a well-known fact that $\norm{A} < \infty$ if and only if $A$ is continuous. Furthermore, every continuous linear map is uniformly continuous.
%The following conditions are equivalent:

%(a) $\norm{A} < \infty$,

%(b) $A$ is uniformly continuous on $V$,

%(c) $A$ is continuous,

%(c) $A$ is continuous at the origin.
\end{recall}

\begin{lem}\label{lemma:ContinuousExtension}
Let $(V,\norm{.}_1)$ and $(W,\norm{.}_2)$ be two normed vector spaces and assume that $W$ is a Banach space. Let $V_0 \subset V$ be a dense vector subspace of $V$ considered as a normed vector space via $\norm{.}_1|_{V_0}$. Let $A \colon V_0 \to W$ be a continuous linear map. Then there exists a unique continuous linear map $\widetilde{A} \colon V \to W$ such that $\widetilde{A}|_{V_0} = A$. Moreover, we have $\norm{\widetilde{A}} = \norm{A}$.
\end{lem}

\begin{proof}
Let $v \in V$. Choose a sequence $\{v_n\}_n \in V_0^\Nbb$ such that $\lim_{n \to \infty} v_n = v$. We define $\widetilde{A} v := \lim_{n \to \infty} Av_n$. This limit exists; indeed, $\{v_n\}_n$ is a Cauchy sequence in $V_0$, so by the uniform continuity of $A$, $\{Av_n\}_n$ is a Cauchy sequence in $W$ and since $W$ is complete, it follows that $\{Av_n\}_n$ converges in $W$. Next, we have to check that the definition of $\widetilde{A} v$ does not depend on the choice of the sequence $\{v_n\}_n$. Let $\{y_n\}_n \in V_0^\Nbb$ be a second sequence such that $\lim_{n \to \infty} y_n = v$. Then $\widetilde{A} v - \widetilde{A} y = \lim_{n\to\infty} A(v_n) - \lim_{n\to\infty} A(y_n) = \lim_{n \to \infty}A(v_n - y_n) = 0$ by continuity of $A$, so $\widetilde{A}$ is well-defined. It is easy to show that $\widetilde{A}$ is linear and that its restriction on $V_0$ coincides with $A$. Furthermore, we have
\[
\norm{\widetilde{A}}
= \sup_{v \in V \smallsetminus \{0\}} \frac{\norm{\widetilde{A}v}_2}{\norm{v}_1}
= \sup_{v \in V_0 \smallsetminus \{0\}} \frac{\norm{Av}_2}{\norm{v}_1}
= \norm{A}
\]
because for any $v \in V$, there exists a sequence $\{v_n\}_n \in V_0^\Nbb$ such that $\lim_{n \to \infty} v_n = v$ and $\lim_{n \to \infty} Av_n = \widetilde{A}v$. This completes the existence part of the proof.

To prove unicity, assume that there exist two continuous linear maps $\widetilde{A}$ and $\widetilde{A}' \colon V \to W$ that satisfy the assertions of the lemma. Set $E := \{v \in V \mid \widetilde{A}(v) = \widetilde{A}'(v)\}$. Since $\widetilde{A}|_{V_0} = A = \widetilde{A}'|_{V_0}$, we have $V_0 \subset E$. On the other hand, $E = (\widetilde{A} - \widetilde{A}')^{-1}(\{0\})$ is closed in $V$ because the map $\widetilde{A} - \widetilde{A}'$ is continuous. Since $\overline{V_0} = V$, it follows that $E = V$.
\end{proof}

\begin{dfn}
A map $A \colon H_1 \to H_2$ between two Hilbert spaces is called \textcolor{blue}{unitary} if and only if $\scalprod{Av}{Aw}_{H_2} = \scalprod{v}{w}_{H_1}$ for all $v, w \in H_1$.
\end{dfn}

\begin{rem}
If $A$ is unitary, then $\norm{A} = 1$.

Indeed, $\norm{Av} = \sqrt{\scalprod{Av}{Av}} = \sqrt{\scalprod{v}{v}} = \norm{v}$ for all $v \in H_1$.
\end{rem}

\begin{thm}\label{Theo:ExtensionOfFourierTransform}
The Fourier transform $\S(\Rbb^n) \ni f \mapsto \widehat{f} \in \S(\Rbb^n)$ extends uniquely to a unitary and bijective map
\[
\Fcal \colon L^2(\Rbb^n) \to L^2(\Rbb^n).
\]
\end{thm}

\begin{proof}
We know that $L^2(\Rbb^n)$ is a Banach space, $\S(\Rbb^n)$ is dense in $L^2(\Rbb^n)$, and by the remark after Theorem~\ref{Theo:FourierInversion}, $\;\widehat{}\; \colon \S(\Rbb^n) \to \S(\Rbb^n)$ is continuous with respect to the $L^2$ norm. It therefore follows from Lemma~\ref{lemma:ContinuousExtension} that we can extend $\;\widehat{}\; \colon \S(\Rbb^n) \to \S(\Rbb^n) \hookrightarrow L^2(\Rbb^n)$ uniquely to a continuous linear map $\Fcal \colon L^2(\Rbb^n) \to L^2(\Rbb^n)$. We have to show that $\Fcal$ is (i) bijective and (ii) unitary.

(i) We extend Fourier inversion $\;\check{}\; \colon \S(\Rbb^n) \to L^2(\Rbb^n)$ to a unique continuous linear map $\Gcal \colon L^2(\Rbb^n) \to L^2(\Rbb^n)$. For $f \in \S(\Rbb^n)$, we have
\[
\Gcal \circ \Fcal(f) = \check{\widehat{f}} = f
\quad\text{and} \quad
\Fcal \circ \Gcal(f) = \widehat{\check{f}} = f.
\]
$\Fcal \circ \Gcal$ and $\Gcal \circ \Fcal$ are therefore continuous extensions of the embedding $\S(\Rbb^n) \hookrightarrow L^2(\Rbb^n)$, hence $\Fcal \circ \Gcal = \Gcal \circ \Fcal = \id_{L^2(\Rbb^n)}$. In other words, $\Fcal$ is invertible with $\Fcal^{-1} = \Gcal$.

(ii) For $f,g \in L^2(\Rbb^n)$, choose sequences $\{f_n\}_n$, $\{g_n\}_n \in \S(\Rbb^n)^\Nbb$ with $f_n \to f$ in $L^2(\Rbb^n)$ and $g_n \to g$ in $L^2(\Rbb^n)$. Then
\[
\scalprod{\Fcal f}{\Fcal g}
= \scalprod{\lim_{n \to \infty} \widehat{f}_n}{\lim_{n \to \infty} \widehat{g}_n}
= \lim_{n \to \infty} \scalprod{\widehat{f}_n}{ \widehat{g}_n}
= \lim_{n \to \infty} \scalprod{f_n}{g_n}
= \scalprod{f}{g},
\]
where the second and fourth equalities follow from the continuity of the scalar product $\scalprod{}{}$ on $L^2(\Rbb^n) \times L^2(\Rbb^n)$ (which can be proved using the Cauchy-Schwartz inequality) and the third equality is due to Theorem~\ref{Theo:FourierInversion}.
\end{proof}

For functions $f$ in $L^1(\Rbb^n) \cap L^2(\Rbb^n)$ we have defined the Fourier transform in two different ways, on the one hand as $\widehat{f}$ in the sense of Definition~\ref{def:FourierTransform}, and on the other hand as $\Fcal(f)$ from the previous theorem. A natural question is whether $\widehat{f}$ and $\Fcal(f)$ actually coincide. One may also ask whether there exists a formula for the Fourier transform of an $L^2$ function that is not necessarily in $L^1(\Rbb^n)$. The following corollary gives positive answers to both of these questions.

\begin{cor}
(a) Let $f \in L^1(\Rbb^n) \cap L^2(\Rbb^n)$. Then $\Fcal(f) = \widehat{f}$.

(b) Let $f \in L^2(\Rbb^n)$. Then
\[
\Fcal(f) = \lim_{R \to \infty} \frac{1}{(2\pi)^{n/2}} \int_{B(0;R)} f(x) e^{-i\scalprod{x}{\xi}} \dx
\]
where the limit is taken in $L^2(\Rbb^n)$.
\end{cor}

The last formula is similar to the concept of improper integrals.
Let us consider the following example in dimension $n = 1$. Let $f \colon \Rbb \to \Rbb$ be defined by
\[
f(x) =
\begin{cases}
0 & \text{if } x < 1, \\
1/x & \text{if } x \geqslant 1.
\end{cases}
\]
We have $f \in L^2(\Rbb^n) \smallsetminus L^1(\Rbb^n)$. In this case,
\[
\int_\Rbb f(x) e^{-ix\xi} \dx = \int_1^\infty \frac{1}{x} e^{-ix\xi} \dx
\]
does not exist in the sense of Lebesgue integrals. But we can compute
\begin{align*}
	\Fcal(f)(\xi)
	&= \lim_{R \to \infty} \frac{1}{\sqrt{2\pi}} \int_1^R \frac{1}{x} e^{-i\scalprod{x}{\xi}} \dx \\
	&= \lim_{R \to \infty} \frac{1}{\sqrt{2\pi}} \int_1^R \left( \frac{\cos(\xi x)}{x} -i \frac{\sin(\xi x)}{x} \right) \dx \\
	&= \lim_{R \to \infty} \frac{1}{\sqrt{2\pi}} \left( \int_{\abs{\xi}}^R \frac{\cos y}{y} \d{}y \pm i \int_{\abs{\xi}}^R \frac{\sin y}{y} \d{}y \right)
\end{align*}
where the change of variables $y = \xi x$ can be performed if $\xi \neq 0$.

\begin{proof}
(a) Let $f \in L^1(\Rbb^n) \cap L^2(\Rbb^n)$. We consider $\chi_{B(0;R)} f$ and choose $f_{n,R} \in C_c^\infty\big(B(0;R)\big)$ with
\[
\lim_{n \to \infty} \norm{\chi_{B(0;R)} f - f_{n,R}}_2 = 0.
\]
Such $f_{n,R}$ exists since $C_c^\infty\big(B(0;R)\big)$ is dense in $L^2\big(B(0;R)\big)$. By the Cauchy-Schwartz inequality, we have
\[
\norm{\chi_{B(0;R)} f - f_{n,R}}_1
= \scalprod{1}{\abs{\chi_{B(0;R)} f - f_{n,R}}}_{L^2(B(0;R))}
\leqslant \norm{1}_{L^2(B(0;R))} \norm{\chi_{B(0;R)} f - f_{n,R}}_2
\]
and therefore
\[
\lim_{n \to \infty} \norm{\chi_{B(0;R)} f - f_{n,R}}_1 = 0.
\]
So $\lim_{n\to\infty} f_{n,R} = \chi_{B(0;R)} f$ in $L^1(\Rbb^n)$ and $L^2(\Rbb^n)$. In addition, we have $\lim_{R \to \infty} \chi_{B(0;R)} f = f$ in $L^1(\Rbb^n)$ and $L^2(\Rbb^n)$. It follows that
\[
\lim_{n\to\infty} f_{n,n} = f
\]
in $L^1(\Rbb^n)$ and $L^2(\Rbb^n)$. Using the linearity of $\;\widehat{}\;$ and remark~(b) after Definition~\ref{def:FourierTransform}, one finds
\[
\Abs{\widehat{f}(\xi) - \widehat{f}_{n,n}(\xi)}
= \Abs{\widehat{f - f_{n,n}}(\xi)} \leqslant \norm{f - f_{n,n}}_1
\]
for all $\xi \in \Rbb^n$. It follows that
\[
\widehat{f}(\xi) = \lim_{n \to \infty} \widehat{f}_{n,n}(\xi) \quad (\forall \xi \in \Rbb^n)
\]
and the convergence is uniform.

On the other hand, we have
\[
\Fcal(f) = \lim_{n \to \infty} \widehat{f}_{n,n}
\]
in the $L^2$-sense. This follows from Theorem~\ref{Theo:ExtensionOfFourierTransform} because $f_{n,n} \in \S(\Rbb^n)$ and $\lim_{n \to \infty} f_{n,n} = f$ in $L^2(\Rbb^n)$. We have therefore
\[
\chi_{B(0;R)} \Fcal(f) = \lim_{n \to \infty} \chi_{B(0;R)} \widehat{f}_{n,n}
\]
in $L^2(\Rbb^n)$. It follows that
\begin{align}
	\int_{B(0;R)} \absbig{\Fcal(f) - \widehat{f} \,}^2 \d\xi
	&= \int_{B(0;R)} \absbig{ \lim_{n \to \infty} \widehat{f}_{n,n} - \widehat{f} \,}^2 \d\xi \label{proof:Theo:ExtensionOfFT:1} \\
	&= \normbig{\lim_{n \to \infty} \widehat{f}_{n,n} - \widehat{f} \,}^2_{L^2(B(0;R))} \label{proof:Theo:ExtensionOfFT:2} \\
	&= \lim_{n \to \infty} \int_{B(0;R)} \absbig{\widehat{f}_{n,n}(\xi) - \widehat{f}(\xi) }^2 \d\xi \nonumber \\
	&= \int_{B(0;R)} \absbig{\lim_{n \to \infty} \widehat{f}_{n,n}(\xi) - \widehat{f}(\xi) }^2 \d\xi = 0 \label{proof:Theo:ExtensionOfFT:3}
\end{align}
where the limits in \eqref{proof:Theo:ExtensionOfFT:1} and \eqref{proof:Theo:ExtensionOfFT:2} are considered with respect to the $L^2$ norm, whereas the limit in \eqref{proof:Theo:ExtensionOfFT:3} is pointwise. This shows that $\chi_{B(0;R)} \Fcal(f) = \chi_{B(0;R)} \widehat{f}$ for all $R$. By taking $R$ to infinity, we obtain finally $\Fcal(f) = \widehat{f}$.

(b) Let $f \in L^2(\Rbb^n)$. Then $\chi_{B(0;R)} f \in L^1(\Rbb^n)$: indeed, since $B(0;R)$ has finite measure, we have $\chi_{B(0;R)} f \in L^2\big(B(0;R)\big) \subset L^1\big(B(0;R)\big) \subset L^1(\Rbb^n)$. In addition, $\lim_{R \to \infty} \chi_{B(0;R)} f = f$ in $L^2(\Rbb^n)$. Since $\Fcal$ is continuous, we have
\[
\Fcal(f) = \lim_{R\to\infty} \Fcal(\chi_{B(0;R)} f)
=\lim_{R\to\infty} \widehat{\chi_{B(0;R)} f}
= \lim_{R\to\infty} \frac{1}{(2\pi)^{n/2}} \int_{B(0;R)} f(x) e^{-i\scalprod{x}{\xi}} \dx
\]
where the second equality is obtained by applying (a) on $\chi_{B(0;R)} f \in L^1(\Rbb^n) \cap L^2(\Rbb^n)$.
\end{proof}

\section{Properties and first applications of the Fourier transform}\label{Subsection:PropertiesFT}

\subsection{(a) Partial differential equations with constant coefficients}

\paragraph{The heat equation.} Let $U$ be an open subset of $\Rbb^n$ and let $I \subset \Rbb$ be an open interval. Let $f\colon I \times U \to \Com$ be a sufficiently often differentiable function of $t \in I$ and $x \in U$, where $t$ represents time and $x$ position.

The \textcolor{blue}{heat equation} is
\begin{equation}\label{HeatEquation}
\frac{\partial f}{\partial t} (t,x) = \Delta_x f(t,x) = \sum_{i=1}^n \frac{\partial^2 f}{\partial x_i^2} (t,x).
\end{equation}
A function $f$ that satisfies~\eqref{HeatEquation} describes the distribution of heat in space depending on time~$t$ and an initial distribution $f(t_0,.)$.

Let us consider the case $I = (0,+\infty)$, $U = \Rbb^n$. We want to find a ``nice'' solution of~\eqref{HeatEquation} with $f(t,.) \in \S(\Rbb^n)$ for $t \in (0,+\infty)$. Then also $\widehat{f}(t,.) \in \S(\Rbb^n)$ (where $\widehat{f}(t,.)$ denotes the Fourier transform of $f$ with respect to $x$).

We start by computing the Fourier transform of both sides of the heat equation. Using the theorem on differentiation of parameter-dependent integrals, one finds
\begin{equation*}%\label{HeatEquation:1}
	\frac{\widehat{\partial f}}{\partial t} (t,\xi)
	= \frac{\partial \widehat{f}}{\partial t} (t,\xi)
\end{equation*}
and by Proposition~\ref{Prop:DifferentiationOfFourierTransform},
\begin{equation*}%\label{HeatEquation:1}
	\widehat{\Delta_x f}(t,\xi)
	= -\norm{\xi}^2 \widehat{f}(t,\xi)
\end{equation*}
where $-\norm{\xi}^2 = -\sum_{i=1}^n \xi^2_i$. Therefore~\eqref{HeatEquation} is equivalent to
\[
\frac{\partial \widehat{f}}{\partial t} (t,\xi)
= -\norm{\xi}^2 \widehat{f}(t,\xi).
\]
For fixed $\xi \in \Rbb^n$ this is just an ordinary differential equation with general solution
\[
\widehat{f}(t,\xi) = C(\xi) e^{-t\norm{\xi}^2}.
\]
We can choose an arbitrary smooth function such that $\xi \mapsto C(\xi) e^{-t\norm{\xi}^2} \in \S(\Rbb^n)$. In particular taking $C(\xi) = C$ independent of $\xi$ gives a ``nice'' solution. It is convenient to work with $C = 1/(2\pi)^{n/2}$. Fourier inversion now gives
\begin{align*}
	f(t,x)
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \widehat{f}(t,\xi) e^{i\scalprod{x}{\xi}} \d\xi \\
	&= \frac{1}{(2\pi)^n} \int_{\Rbb^n} e^{-t\norm{\xi}^2} e^{i\scalprod{x}{\xi}} \d\xi \\
	&= \frac{1}{(2\pi)^n} \frac{1}{(2t)^{n/2}} \int_{\Rbb^n} e^{-\frac{\norm{y}^2}{2}} e^{i\scalprod{x}{\frac{y}{\sqrt{2t}}}} \d{}y \\ %\quad\text{(we take } \xi = \tfrac{y}{\sqrt{2t}}\text{)} \\ %\text{we take $\xi = \frac{y}{\sqrt{2t}}} \\
	&= \frac{1}{(4\pi t)^{n/2}} \;\widehat{e^{-\frac{\norm{y}^2}{2}}} \left(-\frac{x}{\sqrt{2t}} \right) \\
	&= \frac{1}{(4\pi t)^{n/2}} \; e^{-\frac{\norm{x}^2}{4t}}
\end{align*}
where we used the change of variables $\xi = \frac{y}{\sqrt{2t}}$ and Lemma~\ref{lemma:GaussianInvariant}. We have found a special solution of~\eqref{HeatEquation}, namely
\begin{equation}\label{FundSolHeatEq}
f(t,x) = \frac{1}{(4\pi t)^{n/2}} \; e^{-\frac{\norm{x}^2}{4t}},
\end{equation}
which is called the ``Fundamental solution of the heat equation on $\Rbb^n$.''

Among all solutions of~\eqref{HeatEquation} this ``fundamental solution'' is distinguished by the fact that $f(t,.) \in \S(\Rbb^n)$ and that for all $\varphi \in \S(\Rbb^n)$, we have
\begin{equation}\label{FundSolHeatEqConsequence}
\lim_{t \to 0} \int_{\Rbb^n} f(t,x) \varphi(x) \dx = \varphi(0).
\end{equation}

\begin{proof}[Proof that \eqref{FundSolHeatEqConsequence} really holds:]
Set $f_t(x) := f(t,x)$. By unitariness of the Furier transform, we have
\[
\int_{\Rbb^n} f(t,x) \varphi(x) \dx
= \scalprod{\varphi}{f_t}_{L^2(\Rbb^n)}
= \scalprod{\widehat{\varphi}}{\widehat{f}_t}_{L^2(\Rbb^n)}
= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} e^{-t\norm{\xi}^2} \widehat{\varphi}(\xi) \d\xi.
\]
By using dominated convergence, we find that the limit of the above integral as $t$ goes to zero is
\[
\frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \widehat{\varphi} (\xi) \d\xi = \varphi(0),
\]
where the last equality follows by the Fourier inversion formula.
\end{proof}

\subsection*{(b) Fourier transforms of compactly supported functions never have compact support.}

\begin{dfn}
Let $U \subset \Rbb^n$ be an open subset and let $f \colon U \to \Com$ be a measurable function. The support of $f$ is the closed subset $\supp f$ of $U$ whose compliment is defined by%We define the closed support of $f$ $\supp f \subset U$ by defining its compliment
\[
U \smallsetminus \supp f := \bigcup_{\substack{\text{$V \subset U$ open} \\ \text{$f|_V = 0$ a.e.}}} V.
\]
The function $f$ is said to be compactly supported if $\supp f$ is compact.
\end{dfn}

\begin{rem}
If $f$ is continuous, this notion coincides with the previously defined one.
\end{rem}

\begin{prop}\label{Prop:FourierLaplaceTransform}
Let $f \in L^1(\Rbb^n)$ be a function with compact support. Then $\widehat{f}\colon \Rbb^n \to \Com$ extends (uniquely) to a function $\widetilde{f} \colon \Com^n \to \Com$ such that $\widetilde{f}$ is holomorphic in all variables.\footnote{A function $\widetilde{f}$ is called holomorphic in all variables if for all $i \in \{1,\dots,n\}$ and all $(z_1,\dots,z_{i-1},z_{i+1},\dots,z_n) \in \Com^{n-1}$, the function $\Com \ni z \mapsto \widetilde{f}(z_1,\dots,z_{i-1},z,z_{i+1},\dots,z_n)$ is holomorphic in $\Com$ (``entire function'').}
\end{prop}

The proof of this proposition is based on the use of the theorem on holomorphy of parameter-dependent integrals:

\begin{lem}\label{Lemma:HolomorphyParDepIntegrals}
Let $\bigo \subset \Com$ be open and let $f\colon \bigo \times \Rbb^n \to \Com$ be a function that satisfies the following properties:

(a) for all $z \in \bigo$, $f(z,.) \in L^1(\Rbb^n)$,

(b) for almost all $x \in \Rbb^n$, $f(.,x)$ is holomorphic on $\bigo$,

(c) there exists $g \in L^1(\Rbb^n)$ such that $\absbig{\frac{\partial f}{\partial z} (z,x)} \leqslant g(x)$ almost everywhere.

\noindent Then
\[
h(z) := \int_{\Rbb^n} f(z,x) \dx
\]
is holomorphic on $\bigo$ and
\[
\frac{\partial h}{\partial z}(z) = \int_{\Rbb^n} \frac{\partial f}{\partial z} (z,x) \dx.
\]
\end{lem}

\begin{proof}
As in the real case.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{Prop:FourierLaplaceTransform}]
For $w \in \Com^n$, we define the ``Fourier-Laplace'' transform by
\[
\widetilde{f}(w) := \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} f(x) e^{-i\scalprod{w}{x}} \dx
\]
where for $w = \xi + i \eta$ ($\xi, \eta \in \Rbb^n$), we set $\scalprod{w}{x} = \scalprod{\xi}{x} + i\scalprod{\eta}{x} \in \Com$. The integral exists since $f$ is integrable and since the function $x \mapsto e^{-i\scalprod{w}{x}}$ is continuous and therefore bounded on the compact support of~$f$.

Let $\bigo \subset \Com$ be an arbitrary bounded open subset. Then $\widetilde{f}$ is holomorphic on $\bigo$ by Lemma~\ref{Lemma:HolomorphyParDepIntegrals} applied to the function
\[
f_1 (z,x) := f(x) e^{-i\scalprod{w(z)}{x}}
\]
where $w(z) = (z_1,\dots,z_{i-1},z,z_{i+1},\dots,z_n)$ with $z_1,\dots,z_{i-1},z_{i+1},\dots,z_n \in \Com$ fixed.
%Let $\bigo \subset \Com$ be an arbitrary bounded open subset. By Lemma~\ref{Lemma:HolomorphyParDepIntegrals} applied to $f_1$, the function $\widetilde{f}$ is holomorphic on $\bigo$.
Since $\bigo$ can be chosen arbitrarily large, it follows that $\widetilde{f}$ is holomorphic everywhere.
\end{proof}

\begin{rem}
Let $f \in L^2(\Rbb^n)$ be a compactly supported function. Then $f \in L^1(\Rbb^n)$ since $\supp f$ has finite measure. It follows that Proposition~\ref{Prop:FourierLaplaceTransform} holds also for $L^2$ functions.
\end{rem}

\begin{cor}\label{Cor:FourierTransformSupport}
Let $f \in L^2(\Rbb^n)$ be a compactly supported function. If $\supp \Fcal(f) \neq \Rbb^n$, then $f = 0$.
In particular, Fourier transforms of compactly supported functions never have compact support.
\end{cor}

\begin{proof}
If $\supp \Fcal(f) \neq \Rbb^n$, there is a non empty open subset $U \subset \Rbb^n$ such that $\Fcal(f)|_U = 0$. We consider the holomorphic function
\[
h(z) := \widetilde{f}(z,w_2,\dots,w_n)
\]
with $w_2,\dots,w_n$ fixed such that $(z,w_2,\dots,w_n) \in U$ for some $z \in \Rbb$. Then
\[
\{z \in \Rbb \mid (z,w_2,\dots,w_n) \in U\}
\]
is a non empty open subset of $\Rbb$. The set of zeroes of $h$ has therefore an accumulation point (it contains an open interval in $\Rbb$). Since $h$ is holomorphic on $\Com$ by Proposition~\ref{Prop:FourierLaplaceTransform}, it follows from the identity theorem in complex analysis that $h(z) = 0$ for all $z \in \Com$. By putting $z$ successively to all the remaining variables, we show that $\widetilde{f} = 0$, and hence $\Fcal(f) = 0$. Since $\Fcal$ is injective, this implies $f = 0$.
\end{proof}

\begin{rem}
Corollary~\ref{Cor:FourierTransformSupport} also holds for $f \in L^p(\Rbb^n)$ with compact support.
\end{rem}

\subsection*{(c) Translation and convolution}

\begin{dfn}
For $y \in \Rbb^n$ and $p \geqslant 1$, we define the translation operator $\tau_y \colon L^p(\Rbb^n) \to L^p(\Rbb^n)$ by
\[
(\tau_y f)(x) = f(x-y).
\]
\end{dfn}

The translation operator has the following simple properties:

(a) For all $f \in L^p(\Rbb^n)$, $\norm{\tau_y f}_p = \norm{f}_p$. In particular, $\norm{\tau_y} = 1$. If $p=2$, $\tau_y$ is unitary.

(b) We have $\tau_{y_1 + y_2} = \tau_{y_1} \circ \tau_{y_2}$ and $\tau_y^{-1} = \tau_{-y}$. Let $GL(L^p(\Rbb^n))$ be the group of linear invertible bounded operators on $L^p(\Rbb^n)$. Then $\Rbb^n \ni y \mapsto \tau_y \in GL(L^p(\Rbb^n))$ is a group homomorphism. Such a homomorphism is often called a representation of the group $(\Rbb^n,+)$.

(c) For $f \in L^1(\Rbb^n)$, we have
\[
\widehat{\tau_y f} (\xi) = e^{-i\scalprod{\xi}{y}} \widehat{f}(\xi).
\]
In other words, the Fourier transform converts translation to multiplication with an exponential function.

(d) The property (c) holds also for $f \in L^2(\Rbb^n)$.
%This is a consequence of the fact that $\tau_y e^{-i\scalprod{\xi}{x}} = e^{-i\scalprod{\xi}{y}} e^{-i\scalprod{\xi}{x}}$.

\begin{convention}
In the following, we will often denote $\Fcal: L^2(\Rbb^n) \to L^2(\Rbb^n)$ by $f \mapsto \widehat{f}$ as for $f \in L^1(\Rbb^n)$.
\end{convention}

\begin{proof}[Proof of \emph{(d)}]
We choose $f_n \in \S(\Rbb^n) \subset L^1(\Rbb^n)$ such that $f_n \to f$ in $L^2(\Rbb^n)$. Then $\tau_y f_n \to \tau_y f$ in $L^2(\Rbb^n)$ and $\widehat{\tau_y f_n} \to \widehat{\tau_y f}$ in $L^2(\Rbb^n)$. Hence
\[
\widehat{\tau_y f}
= {\lim_{n\to\infty}}^{\!\!L^2} \widehat{\tau_y f_n}
\overset{\text{(c)}}{=} {\lim_{n\to\infty}}^{\!\!L^2} e^{-i\scalprod{y}{.}} \widehat{f}_n
= e^{-i\scalprod{y}{.}} {\lim_{n\to\infty}}^{\!\!L^2} \widehat{f}_n
= e^{-i\scalprod{y}{.}} \widehat{f}.
\qedhere
\]
\end{proof}

One may ask whether there are closed subspaces $V \subset L^2(\Rbb^n)$ that are invariant with respect to all translation operators $\tau_y$, $y \in \Rbb^n$ (i.e. such that $\tau_y(V) \subset V$). Such closed invariant subspaces define subrepresentations of the representation $y \mapsto \tau_y \in GL(L^2(\Rbb^n))$.

It is not easy to write down such spaces directly. If you take $f \in L^2(\Rbb^n)$ (not especially clever choice) then the closure of $\spans_\Com\{\tau_y f \mid y \in \Rbb^n \}$ will be typically the Hilbert space $L^2(\Rbb^n)$. But the task becomes much easier if we look at Fourier transforms and use~(d).

\begin{prop}\label{Prop:TranslationInvariantSubspaces}
Let $A \subset \Rbb^n$ be a Borel subset (e.g. $A$ open or closed). We define
\[
V_A := \{f \in L^2(\Rbb^n) \mid \chi_A \widehat{f} = \widehat{f} \,\}.
\]
Then $V_A$ is a closed translation invariant subspace (as required above).
\end{prop}

\begin{rem}
If $A$ is closed then the condition $\chi_A \widehat{f} = \widehat{f}$ is equivalent to $\supp \widehat{f} \subset A$.
\end{rem}

\begin{proof}
We have to show that (i) $V_A$ is closed and (ii) $V_A$ is translation invariant.

(i) For a bounded measurable function $h$, let $m_h \colon L^2(\Rbb^n) \to L^2(\Rbb^n)$ be the multiplication operator $m_h(f) = hf$. Then $m_h$ is linear and continuous. We have
\[
V_A = \{ f \in L^2(\Rbb^n) \mid m_{1-\chi_A}\widehat{f} = 0 \},
\]
in other words $V_A = \ker(m_{1-\chi_A} \circ \Fcal)$. The claim now follows from the fact that the kernel of a continuous linear operator is always a closed linear subspace.

(ii) We have to show that for all $y \in \Rbb^n$ and for all $f \in V_A$, we have $\tau_y f \in V_A$.

Take $y \in \Rbb^n$, $f \in V_A$. We have
\[
\chi_A \widehat{\tau_y f}
	=%\overset{\text{(d)}}{=}
\chi_A e^{-i\scalprod{y}{.}} \widehat{f}
	=
e^{-i\scalprod{y}{.}} \chi_A \widehat{f}
	=%\overset{f \in V_A}{=}
e^{-i\scalprod{y}{.}} \widehat{f}
	=%\overset{\text{(d)}}{=}
\widehat{\tau_y f}
\]
(where the first and the fourth equalities follow from the property (d) of the translation operator and the third equality holds because $f \in V_A$). This shows that $\tau_y f \in V_A$.
\end{proof}

\begin{rem}
(a) The converse of Proposition~\ref{Prop:TranslationInvariantSubspaces} is also true, i.e. if $V \subset L^2(\Rbb^n)$ is a closed translation invariant subspace, then there exists a Borel set $A \subset \Rbb^n$ such that $V = V_A$.

(b) There are no minimal translation invariant subspaces other than $\{0\}$. Indeed, $\chi_A \neq 0$ if, and only if, $\lambda(A) > 0$ (where $\lambda$ denotes the Lebesgue measure). In this case there always exists $A' \subset A$ such that $\lambda(A') = \frac{1}{2} \lambda(A)$.
\end{rem}

\paragraph{Convolution.} Let $\varphi \in C_c(\Rbb^n)$ and $f \in L^p(\Rbb^n)$. We define the convolution of $\varphi$ with $f$ by
\begin{align*}
	\varphi * f(x)
	&:= \int_{\Rbb^n} \varphi(y) \tau_y f(x) \d{}y \\
	&\phantom{:}= \int_{\Rbb^n} \varphi(y) f(x-y) \d{}y.
\end{align*}
The notions of translation and convolution are related by the fact that $\varphi * f$ can be interpreted as a weighted average of translations of $f$ with respect to $\varphi$.

The integral defining $\varphi * f(x)$ really exists. Indeed, the function $y \mapsto \varphi(y)f(x-y)$ is integrable since by Hölder's inequality,
\[
\norm{\varphi f(x-.)}_1 \leqslant \norm{\varphi}_q \norm{f(x-.)}_p = \norm{\varphi}_q \norm{f}_p
\]
where $q$ is such that $\frac{1}{p} + \frac{1}{q} = 1$. Of course, $\norm{\varphi}_q < \infty$ since $C_c(\Rbb^n) \subset L^q(\Rbb^n)$ for all $q$.

Alternatively, the existence of the integral follows from the fact that
\[
\varphi * f(x) = \int_{\supp \varphi} \varphi(y) f(x-y) \d{}y
\]
and $y \mapsto \varphi(y) f(x-y) \in L^p(\supp \varphi) \subset L^1(\supp \varphi)$. Here we used the fact that the support of $\varphi$ is compact and has therefore finite measure.

Our goal is to extend the definition of convolution to $\varphi \in L^1(\Rbb^n)$ and to show that in this case, for all $f \in L^p(\Rbb^n)$, $p \in [1,\infty)$, we have $\varphi * f \in L^p(\Rbb^n)$. We start by proving this result for $p = 1$:

\begin{prop}\label{Prop:ConvolutionL1}
Let $\varphi, f \in L^1(\Rbb^n)$. Then the integral
\[
\varphi * f(x)
:= \int_{\Rbb^n} \varphi(y) f(x-y) \d{}y
\]
exists for almost all $x \in \Rbb^n$, $\varphi * f \in L^1(\Rbb^n)$ and $\norm{\varphi * f}_1 \leqslant \norm{\varphi}_1 \norm{f}_1$.
\end{prop}

\begin{proof}
Consider the function $F\colon \Rbb^n \times \Rbb^n \to \Com$ defined by $F(x,y) := \varphi(y) f(x-y)$. Then
\begin{align*}
	F \in L^1(\Rbb^n \times \Rbb^n)
	&\iff \int_{\Rbb^n \times \Rbb^n} \absbig{\varphi(y) f(x-y)} \dx \d{}y < \infty \\
	&\iff \int_{\Rbb^n} \absbig{\varphi(y)} \left( \int_{\Rbb^n} \absbig{f(x-y)} \dx \right) \d{}y < \infty \\
	&\iff \norm{\varphi}_1\norm{f}_1 < \infty
\end{align*}
where the second equivalence holds by Fubini's theorem for non negative measurable functions. Since $\varphi, f \in L^1(\Rbb^n)$ by assumption, we have thus shown that $F \in L^1(\Rbb^n \times \Rbb^n)$. By Fubini's theorem for integrable functions, it follows that $\int_{\Rbb^n} \varphi(y) f(x-y) \d{}y$ exists for almost all $x \in \Rbb^n$ (and $\int_{\Rbb^n} \{ \int_{\Rbb^n} \varphi(y) f(x-y) \d{}y \} \dx = \int_{\Rbb^n \times \Rbb^n} F(x,y) \dx \d{}y$). Thus $\varphi * f(x)$ exists for almost all $x \in \Rbb^n$.

It remains to show that $\norm{\varphi * f}_1 \leqslant \norm{\varphi}_1 \norm{f}_1$. We have
\begin{align*}
	\norm{\varphi * f}_1
	&= \int_{\Rbb^n} \abs{\varphi * f(x)} \dx \\
	&= \int_{\Rbb^n} \Abs{\int_{\Rbb^n} \varphi(y) f(x-y) \d{}y} \dx \\
	&\leqslant \int_{\Rbb^n} \int_{\Rbb^n} \absbig{\varphi(y) f(x-y)} \d{}y \dx \\
	&= \norm{F}_{L^1(\Rbb^n \times \Rbb^n)} = \norm{\varphi}_1 \norm{f}_1
\end{align*}
where the passage to the last line follows again from Fubini's theorem.
\end{proof}

\begin{prop}\label{Prop:ConvolutionLp}
Let $\varphi \in L^1(\Rbb^n)$ and $f \in L^p(\Rbb^n)$, $p \in [1,\infty)$. Then the integral
\begin{equation}\label{Eq:Prop:ConvolutionLp}
\varphi * f(x)
:= \int_{\Rbb^n} \varphi(y) f(x-y) \d{}y
\end{equation}
exists for almost all $x \in \Rbb^n$, $\varphi * f \in L^1(\Rbb^n)$ and $\norm{\varphi * f}_p \leqslant \norm{\varphi}_1 \norm{f}_p$.
\end{prop}

\begin{proof}
Similar to the proof of Proposition~\ref{Prop:ConvolutionL1}, but with an additional trick. For $p > 1$ we consider the dual exponent $q \in (1,\infty)$ such that $\frac{1}{p} + \frac{1}{q} = 1$, i.e. $q = \frac{p}{p-1}$. (For $p=1$ the proposition is just Proposition~\ref{Prop:ConvolutionL1}.)

We define $F(x,y):=\varphi(y)f(x-y)h(x)$ where $h \in L^q(\Rbb^n)$ is an auxiliary function. Using successively Fubini's theorem and Hölder's inequality, we obtain
\begin{align*}
	\norm{F}_{L^1(\Rbb^n \times \Rbb^n)}
	&= \int_{\Rbb^n} \absbig{\varphi(y)} \int_{\Rbb^n} \absbig{f(x-y) h(x)} \dx \d{}y \\
	&\leqslant \int_{\Rbb^n} \abs{\varphi(y)} \; \norm{\tau_y f}_p \; \norm{h}_q \d{}y
	= \norm{\varphi}_1 \norm{f}_p \norm{h}_q < \infty.
\end{align*}
Again by Fubini, we see that
\[
G_h(x) := h(x) \int_{\Rbb^n} \varphi(y) f(x-y) \d{}y
\]
is defined for almost all $x\in\Rbb^n$. If we apply this result to the function
\[
h(x) = \chi_{B(0;R)} (x),
\]
(we have indeed $h \in L^q(\Rbb^n)$ for all $q$), it follows that for almost all $x \in B(0;R)$ the integral~\eqref{Eq:Prop:ConvolutionLp} is defined. Since $R$ is arbitrary, we eventually get that~\eqref{Eq:Prop:ConvolutionLp} is defined for almost all $x \in \Rbb^n$.

It remains to show that $\varphi * f \in L^1(\Rbb^n)$ and $\norm{\varphi * f}_p \leqslant \norm{\varphi}_1 \norm{f}_p$. For $R \in (0,\infty)$, we define
\[
A(R) := \big\{x \in \Rbb^n \;\big|\; \norm{x} \leqslant R, \; \abs{\varphi * f(x)} \leqslant R \big\}
\]
and
\[
h_R(x) := \chi_{A(R)} \abs{\varphi * f(x)}^{p-1}.
\]
The function $h_R$ is in $L^q(\Rbb^n)$ because it is bounded by $R^{p-1}$ and its support is contained in $B(0;R)$.
We have therefore
\begin{equation}\label{Eq:Proof:Prop:ConvolutionLp:1}
\int_{A(R)} \abs{\varphi * f(x)}^p \dx
= \norm{G_{h_R}}_1
\leqslant \norm{\varphi}_1 \norm{f}_p \norm{h_R}_q.
\end{equation}
On the other hand, since $(p-1)q = p$, we have
\[
\norm{h_R}_q
= \left( \int_{A(R)} \abs{\varphi * f(x)}^{(p-1)q} \dx \right)^{1/q}
= \left( \int_{A(R)} \abs{\varphi * f(x)}^{p} \dx \right)^{1/q}.
\]
By dividing both sides of~\eqref{Eq:Proof:Prop:ConvolutionLp:1} by $\norm{h_R}_q$, we obtain therefore
\[
\left( \int_{A(R)} \abs{\varphi * f(x)}^{p} \dx \right)^{1 - 1/q}
\leqslant \norm{\varphi}_1 \norm{f}_p.
\]
Now, taking $R$ to infinity, we find finally
\[
\norm{\varphi * f}_p
= \lim_{R\to\infty} \left( \int_{A(R)} \abs{\varphi * f(x)}^p \right)^{1/p} \leqslant \norm{\varphi}_1 \norm{f}_p < \infty.
\qedhere
\]
\end{proof}

One of the basic properties of the Fourier transform is that it turns convolution into multiplication:

\begin{prop}
Let $\varphi \in L^1(\Rbb^n)$ and $f \in L^p(\Rbb^n)$ with $p=1$ or $2$. Then
\[
\widehat{\varphi * f} = (2\pi)^{n/2} \widehat{\varphi} \widehat{f}.
\]
\end{prop}

\begin{proof}
At first, assume that $p = 1$. Let $\varphi, f \in L^1(\Rbb^n)$. Then
\begin{align}
	\widehat{\varphi * f}(\xi)
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \varphi * f(x) e^{-i\scalprod{x}{\xi}} \dx \nonumber \\
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \int_{\Rbb^n} \varphi(y) f(x-y) \d{}y \; e^{-i\scalprod{x}{\xi}} \dx \label{eq:FourierTransformConvolution:1} \\
	&= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} \int_{\Rbb^n} f(x-y) e^{-i\scalprod{x}{\xi}} \dx \; \varphi(y) \d{}y \label{eq:FourierTransformConvolution:2} \\
	&= \int_{\Rbb^n} \widehat{\tau_y f}(\xi) \varphi(y) \d{}y \nonumber \\
	&= \int_{\Rbb^n} \widehat{f}(\xi) e^{-i\scalprod{y}{\xi}} \varphi(y) \d{}y \nonumber \\
	&= \widehat{f}(\xi) (2\pi)^{n/2} \widehat{\varphi}(\xi). \nonumber
\end{align}
Note that the function $(x,y) \mapsto \varphi(y) f(x-y) e^{-i\scalprod{x}{\xi}}$ is in $L^1(\Rbb^n \times \Rbb^n)$ by Proposition~\ref{Prop:ConvolutionL1}, which makes it possible to use Fubini's theorem to pass from line~\eqref{eq:FourierTransformConvolution:1} to line~\eqref{eq:FourierTransformConvolution:2}.

It remains to prove the result for $p = 2$. Let $f \in L^2(\Rbb^n)$. We choose $f_n \in \S(\Rbb^n)$ such that $f_n \to f$ for $n \to \infty$ in $L^2(\Rbb^n)$. By Proposition~\ref{Prop:ConvolutionLp} we know that $\norm{\varphi * f}_2 \leqslant \norm{\varphi}_1 \norm{f}_2$. This means that the linear map $L^2(\Rbb^n) \ni f \mapsto \varphi * f \in L^2(\Rbb^n)$ is continuous with operator norm less or equal to $\norm{\varphi}_1$. It follows that $\varphi * f_n \to \varphi * f$ in $L^2(\Rbb^n)$ and by continuity of the Fourier transform, $\widehat{\varphi * f_n} \to \widehat{\varphi * f}$ in $L^2(\Rbb^n)$. Since $f_n \in L^1(\Rbb^n)$, we have $\widehat{\varphi * f_n} = (2\pi)^{n/2} \widehat{\varphi} \widehat{f}_n$ for all $n$. Furthermore, observe that $\lim_{n \to \infty}^{L^2} \widehat{\varphi} \widehat{f}_n = \widehat{\varphi} \lim_{n \to \infty}^{L^2} \widehat{f}_n$. This follows from the fact that $\widehat{\varphi}$ is a bounded function (see remark~(b) after Definition~\ref{def:FourierTransform}) and 
multiplication with a bounded function is a continuous operator on $L^2(\Rbb^n)$. Combining these observations, we obtain
\[
\widehat{\varphi * f}
= {\lim_{n\to\infty}}^{\!\!L^2} \widehat{\varphi * f_n}
= (2\pi)^{n/2} {\lim_{n\to\infty}}^{\!\!L^2} \widehat{\varphi} \widehat{f}_n
= (2\pi)^{n/2} \widehat{\varphi} \widehat{{\lim_{n\to\infty}}^{\!\!L^2} f_n}
= (2\pi)^{n/2} \widehat{\varphi} \widehat{f}.
\qedhere
\]
\end{proof}

\section{The classical differential equations}

\subsection{The Laplace equation}

\begin{dfn}
(a) The Laplace operator on $\Rbb^n$ is defined as
\[
\Delta = \sum_{i=1}^n \frac{\partial^2}{\partial x_i^2}.
\]

(b) Let $U \subset \Rbb^n$ be an open subset and let $f \colon U \to \Com$ be a function of class $C^2$. The function $f$ is called harmonic if
\[
\Delta f = \sum_{i=1}^n \frac{\partial^2 f}{\partial x_i^2} = 0.
\]
\end{dfn}

\noindent\emph{Examples of harmonic functions.}

(a) Let $f$ be a polynomial on $\Rbb^n$ of degree at most~1 (i.e.\ a function of the form $f(x) = \sum_{i=1}^n a_i x_i + b$). Then $f$ is harmonic.

(b) Let $U \subset \Com \equiv \Rbb^2$ be an open subset and let $f \colon U \to \Com$ be a holomorphic function. Then $f$, $\RePart f$ and $\ImPart f$ are harmonic.

(c) Let $U \subset \Rbb^n$ be an open subset and let $f \colon U \to \Com$ be harmonic. Then

\indent \indent (i)
$\frac{\partial f}{\partial x_i}$ is harmonic (provided $f \in C^3(U)$, which is always fulfilled since any harmonic function is smooth, see Proposition~\ref{Prop:HarmFctsAreSmooth}),

\indent \indent (ii)
$\tau_y f$ is harmonic,

\indent \indent (iii)
$\varphi * f$ is harmonic (when defined, for instance for $\varphi \in C_c(\Rbb^n)$).

\begin{proof}
(b) Recall that the complex partial derivatives are defined as
\[
\frac{\partial}{\partial z} = \frac{1}{2} \left( \frac{\partial}{\partial x} -i \frac{\partial}{\partial y} \right), \quad
\frac{\partial}{\partial \bar{z}} = \frac{1}{2} \left( \frac{\partial}{\partial x} +i \frac{\partial}{\partial y} \right).
\]
By Cauchy-Riemann equations, $f$ is holomorphic if, and only if, 
\[
\frac{\partial}{\partial \bar{z}}f = 0.
\]
Let us compute $\frac{\partial}{\partial z} \circ \frac{\partial}{\partial \bar{z}}$:
\[
\frac{\partial}{\partial z} \circ \frac{\partial}{\partial \bar{z}}
= \frac{\partial^2}{\partial z \partial \bar{z}}
= \frac{1}{4} \left( \frac{\partial}{\partial x} -i \frac{\partial}{\partial y} \right) \left( \frac{\partial}{\partial x} +i \frac{\partial}{\partial y} \right)
= \frac{1}{4} \left( \frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} \right)
= \frac{1}{4} \Delta.
\]
Now if $f$ is harmonic, then
\[
0
= \frac{\partial}{\partial z} \circ \frac{\partial}{\partial \bar{z}} f
= \frac{1}{4} (\Delta f)
= \frac{1}{4} (\Delta \RePart f + i\Delta \ImPart f).
\]
This shows that $\Delta f = 0$. Since $\Delta \RePart f \in \Rbb$ and $i\Delta \ImPart f \in i\Rbb$, we have necessarily also $\Delta \RePart f = 0$ and $\Delta \ImPart f = 0$.
\end{proof}

There are a lot of harmonic functions on $U \subset \Rbb^n$ (provided $n \geqslant 2$). But there are very few of them depending only on the radius (norm).

\begin{lem}
We use the notation $r = r(x) = \sqrt{x^2_1 + x^2_2 + \dots + x^2_n}$. Let $\varphi \colon (0,\infty) \to \Com$ be a $C^2$-function. Then $f(x) = \varphi(r(x)) = \varphi(\norm{x})$ is harmonic on $\Rbb^n \smallsetminus \{0\}$ if and only if
\begin{equation}\label{Eq:RadialHarmonic}
\varphi''(r) + \frac{n-1}{r}\varphi'(r) = 0.
\end{equation}
\end{lem}

\begin{proof}
We consider $f(x) = \varphi(r(x))$. Then
\[
\frac{\partial r}{\partial x_i}
= \frac{1}{2} \frac{1}{r(x)} 2x_i
= \frac{x_i}{r},
\]
so by the chain rule,
\[
\frac{\partial f}{\partial x_i}
= \varphi'(r) \frac{\partial r}{\partial x_i}
= \varphi'(r) \frac{x_i}{r}
\]
and
\[
\frac{\partial^2 f}{\partial x_i^2}
= \varphi''(r) \frac{x^2_i}{r^2} + \varphi'(r) \frac{r - \frac{x^2_i}{r}}{r^2}
= \varphi''(r) \frac{x^2_i}{r^2} + \varphi'(r) \frac{r^2 - x^2_i}{r^3}.
\]
Taking the sum over $i \in \{1,\dots,n\}$, we obtain
\[
\Delta f = \varphi''(r) + \varphi'(r) \frac{nr^2 - r^2}{r^3}
= \varphi''(r) + \frac{n - 1}{r} \varphi'(r).
\qedhere
\]
\end{proof}

The ODE~\eqref{Eq:RadialHarmonic} can be solved explicitely by separation of variables. On an interval where $\varphi'(r) \neq 0$, we have $
\frac{\varphi''(r)}{\varphi'(r)} = - \frac{n-1}{r},
$
and therefore
$
\log\abs{\varphi'(r)} = (1-n) \log r + c_1
$.
It follows that
$
\abs{\varphi'(r)} = \frac{c_2}{r^{n-1}}
$
for some constant $c_2$, and since $\varphi'$ has constant sign on the considered interval, we have
$
\varphi'(r) = \frac{c_3}{r^{n-1}}
$
where either $c_3 = c_2$ or $c_3 = - c_2$.
For $n=2$, the solution is therefore
\[
\varphi(r) = C \log r + D
\]
and for $n \geqslant 3$,
\[
\varphi(r) = \frac{C}{r^{n-2}} + D.
\]

On the other hand, if $\varphi'(r_0) = 0$ and $\varphi(r_0) = D$, then $\varphi(r) = D$ for all $r$.

We have just shown

\begin{cor}\label{Cor:HarmonicRadialFcts}
The following functions exhaust all harmonic functions on $\Rbb^n \smallsetminus \{0\}$ that depend only on the radius:
\begin{align*}
	n = 2\colon \quad & f(x) = C \log \norm{x} + D, \\
	n \geqslant 3\colon \quad & f(x) = \frac{C}{\norm{x}^{n-2}} + D,
\end{align*}
where $C$ and $D$ are arbitrary complex constants.
In particular, the only such radial harmonic functions defined in the whole $\Rbb^n$ are constant.
\end{cor}

\begin{rem}
All these solutions are integrable over $B(0;R) \subset \Rbb^n$.
\end{rem}

\subsection{Typical problems involving the Laplace operator}

\subsubsection{(a) The inhomogeneous Laplace equation, also Poisson equation}

Let $U \subset \Rbb^n$ be an open subset and let $\varphi \in C(U)$ be a given continuous function on $U$. We look for a twice continuously differentiable function $f \in C^2(U)$ (maybe sometimes with additional properties) such that
\begin{equation}\label{eq:PoissonEquation}
\Delta f = \varphi.
\end{equation}

\begin{rem}
(a) For $\varphi = 0$ we look for harmonic functions.

(b) If $\varphi$ is general, $f$ is a solution of~\eqref{eq:PoissonEquation} and $f_0$ is harmonic, then $f + f_0$ is a solution of~\eqref{eq:PoissonEquation}.

(c) If $f_1$ and $f_2$ are solutions of~\eqref{eq:PoissonEquation}, then $f_1 - f_2$ is harmonic.
\end{rem}

\subsubsection{(b) Boundary value problems}

Let $U \subset \Rbb^n$ be an open, bounded and connected\footnote{If $U$ is not connected one can consider its connected components separately.} subset such that its boundary $\partial U := \overline{U} \smallsetminus U$ is a smooth submanifold of $\Rbb^n$ of codimension 1.

\vspace{6pt}
\noindent (b1) \emph{Dirichlet problem.} Given a function $\varphi \in C(\partial U)$, we look for $f \in C(\overline{U})$ such that

%(i) $f|_U$ is harmonic, i.e.\ $f|_U \in C^2(U)$ and $\Delta f|_U = 0$,
(i) the restriction of $f$ to $U$ is harmonic, i.e.\ $f|_U \in C^2(U)$ and $\Delta f|_U = 0$,

(ii) $f$ coincides with $\varphi$ on $\partial U$, i.e.\ $f|_{\partial U} = \varphi$.
\vspace{6pt}

A physical interpretation: We interprete $\varphi$ as the distribution of temperature on $\partial U$ which is independent of time (kept constant with respect to time). One expects that after some time the distribution of temperature in the interior $U$ will also be constant with respect to time. The process with respect to time of the distribution of heat (or temperature) is described by the heat equation
\[
\frac{\partial f}{\partial t} = \Delta f.
\]
If $\frac{\partial f}{\partial t}$ is zero after some time, then also $\Delta f = 0$ after some time.

\vspace{6pt}
\noindent (b2) \emph{Neumann problem.}
Let $N \colon \partial U \to \Rbb^n$ be the outer vector field along $\partial U$.\footnote{We say that $N$ is the outer normal vector field along $\partial U$ if $N$ is the unique vector field that satisfies the following properties:

(i) For all $y \in \partial U$, $N(y)$ is perpendicular to $\partial U$, that is, for any tangent vector $X \in T_y \partial U$ we have $\scalprod{X}{N(y)} = 0$.

(ii) $\norm{N(y)} = 1$ for all $y \in \partial U$.

(iii) $N(y)$ points outside $U$.}
%end of footnote
Given $\varphi \in C(\partial U)$ we look for $f \in C^1(\overline{U})$ such that

(i) $f|_U$ is harmonic,

(ii) $\varphi = Nf|_{\partial U}$, where we define $Nf|_{\partial U} := \d{}f|_{\partial U}(N)$.

\begin{rem}
The second condition can be also written in the form $\varphi(y) = Nf(y)$ for all $y \in \partial U$, where $Nf(y) := \d{}f_y(N(y))$. Note that $\d{}f_y(N(y)) = \scalprod{\grad f(y)}{N(y)}$.
\end{rem}

\noindent (b3) \emph{Dirichlet eigenvalues.} We look for complex numbers $\lambda_n$ and functions $f_n \in C(\overline{U})$ such that

(i) $f_n|_U \in C^2(U)$,

(ii) $f_n|_{\partial U} = 0$,

(iii) $\Delta f_n + \lambda_n f_n = 0$.

\begin{rem} All those $\lambda_n$ are real and positive. The number $-\lambda_n$ is an eigenvalue of $\Delta$ acting on some space of functions.
\end{rem}

\noindent (b4) \emph{Poisson equation with boundary conditions.}
Given a function $\varphi \in C^1(\overline{U})$, we look for $f \in C^1(\overline{U})$ such that

(i) $f|_U \in C^2(U)$,

(ii) $\Delta f|_U = \varphi|_U$,

(iii) $f|_{\partial U} = 0$.

\vspace{6pt}
\noindent \emph{Relation between \emph{(b3)} and \emph{(b4)}.}
If one knows the complete set of solutions of (b3), then one can construct (at least formally) a solution of (b4).

Let $\{ (\lambda_n, f_n) \mid n \in \Nbb \}$ be the complete set of solutions of (b3). Then for $\lambda_n \neq \lambda_m$ we have $\scalprod{f_n}{f_m}_{L^2(U)} = 0$. By normalization we can achieve $\scalprod{f_n}{f_m}_{L^2(U)} = \delta_{nm}$ so that we obtain an ONS in $L^2(U)$. ``Spectral theory of elliptic operators'' implies that this ONS is complete. We can therefore develop
\[
\varphi = \sum_{n=1}^\infty \scalprod{\varphi}{f_n}_{L^2(U)} f_n
\]
and define
\[
f := \sum_{n=1}^\infty -\frac{1}{\lambda_n}\scalprod{\varphi}{f_n}_{L^2(U)} f_n.
\]
One has to check that this series converges to something in $C^2(U)$ with $f|_{\partial U} = 0$ and $\Delta f = \varphi$. Formally, the last equation holds:
\[
\Delta f
\text{ ``$=$'' } \sum_{n=1}^\infty -\frac{1}{\lambda_n}\scalprod{\varphi}{f_n}_{L^2(U)} \Delta f_n
= \sum_{n=1}^\infty \scalprod{\varphi}{f_n}_{L^2(U)} f_n
= \varphi.
\]

\subsection{Gradient, divergence and integral formulas}

Let $X = (X_1, \dots, X_n) \colon U \to \Rbb^n$ or $\Com^n$ be a vector field of class $C^1$. Then the divergence of $X$ is the function $\divergence X \colon U \to \Rbb$ or $\Com$ defined by
\[
\divergence X(x) = \sum_{i=1}^n \frac{\partial X_i}{\partial x_i} (x).
\]
If $f \in C^2(U)$, then the gradient of $f$ is a $C^1$-vector field on $U$ and
\[
\Delta f = \divergence(\grad f).
\]

Let $U$, $\partial U$ be as above and let $\omega \in \Omega^{n-1}(\overline{U})$ be a differential $(n-1)$-form on $\overline{U}$ of class $C^1$ up to the boundary. Then the \textcolor{blue}{Stokes' theorem} states
\begin{equation}\label{eq:Stokes}
\int_{\partial U} \omega = \int_U \d{}\omega.
\end{equation}

Recall that the volume form of $\Rbb^n$ is $\dx_1\dx_2\dots\dx_n = \dx_1 \wedge \dx_2 \wedge \dots \wedge \dx_n$. The volume form of $\partial U$ can be defined as
\[
\d(\partial U) = \d{}y = \mathcal{i}_{N} (\dx_1 \wedge \dx_2 \wedge \dots \wedge \dx_n)
= \sum_{i=1}^n (-1)^{i-1} N_i(x) \dx_1 \wedge \dots \wedge \widehat{\dx_i} \wedge \dots \wedge \dx_n,
\]
where $N(x) = \big( N_1(x), N_2(x), \dots, N_n(x) \big)$ is the outer normal vector field and $\widehat{\dx_i}$ denotes a term that is omitted.

Alternatively, one can describe $\d(\partial U)$ using local parametrizations of the boundary $\partial U$: if $\partial U$ is parametrized by
\[
\varphi \colon \Rbb^{n-1} \supset V \to \partial U,
\]
then we set
\[
\d(\partial U) = f(y) \d{}y_1 \dots \d{}y_{n-1}
\]
where
\[
f(y) = \sqrt{\det \left( \scalprod{\frac{\partial \varphi}{\partial y_i}}{\frac{\partial \varphi}{\partial y_j}} \right) }.
\]

Then the Ostrogradski formula for the divergence states
\begin{equation}\label{eq:Ostrogradski}
\int_U \div X \dx = \int_{\partial U} \scalprod{X}{N} \d(\partial U).
\end{equation}
The formula~\eqref{eq:Ostrogradski} can be seen as a consequence of Stokes' theorem applied to the $(n-1)$-form\footnote{Recall that for a vector field $X$ and a differential $p$-form $\eta$ we define the differential $(p-1)$-form $\mathcal{i}_{X} \eta$ by setting $\mathcal{i}_{X} \eta(X_1, \dots, X_{p-1}) = \eta(X, X_1, \dots, X_{p-1})$.}
\[
\omega = \mathcal{i}_{X} (\dx_1 \wedge \dots \wedge \dx_n)
\]
the exterior differential of which is given by
\[
\d\omega = \divergence (X) \dx_1 \wedge \dots \wedge \dx_n.
\]

If $f \colon U \to \Com$ is an additional function (of class $C^1$), then we can consider the vector field $fX$. By the Leibniz rule, the divergence of $fX$ is
\[
\divergence(fX) = \scalprod{\grad f}{X} + f\divergence X.
\]
Inserting into~\eqref{eq:Ostrogradski} we obtain Gauss' formula
\begin{equation}\label{eq:Gauss}
\int_U (f \divergence X + \scalprod{\grad f}{X}) \dx
= \int_{\partial U} f \scalprod{X}{N} \d(\partial U).
\end{equation}

\begin{prop}[Green's formulas]\label{Prop:GreensFormulas}
Let $f, g \colon \overline{U} \to \Com$ be two functions of class $C^2$ (up to the boundary). Then
\begin{equation}\label{eq:GreenI}
\int_U f(\Delta g) \dx
= - \int_U \scalprod{\grad f}{\grad g} \dx + \int_{\partial U} f (Ng) \d(\partial U)
\end{equation}
and
\begin{equation}\label{eq:GreenII}
\int_U f(\Delta g) - g(\Delta f) \dx
= \int_{\partial U} f (Ng) - g(Nf) \d(\partial U).
\end{equation}
\end{prop}

\begin{proof}
Take $X = \grad g$ in~\eqref{eq:Gauss}. Then $\divergence X = \Delta g$ and $\scalprod{\grad g}{N} = Ng$. We obtain~\eqref{eq:GreenI}.
The second formula follows from~\eqref{eq:GreenI} by changing the roles of $f$ and $g$ and taking the difference.
\end{proof}

\begin{prop}[Uniqueness of the solutions of (b1) and (b2)]\label{Prop:UniquenessB1B2}~

(a) Let $\varphi \in C(\partial U)$ and let $f_1, f_2 \in C(\overline{U})$ be solutions of \emph{(b1)} such that $\grad (f_1 - f_2)$ is bounded.\footnote{The boundedness of $\grad (f_1 - f_2)$ is a technical assumption, satisfied e.g.\ if $f_1$ and $f_2 \in C^1(\overline{U})$.} Then $f_1 = f_2$.

(b) Let $\varphi \in C(\partial U)$. Assume that (b2) has a solution. Then
\[
\int _{\partial U} \varphi \d(\partial U) = 0.
\]

(c) Let $f_1, f_2 \in C^1(\overline{U})$ be two solutions of (b2). Then $f_1 - f_2$ is a constant function.
\end{prop}

\begin{proof}
(a) Consider $f:= f_1 - f_2$: $f$ is a solution of (b1) with $\varphi = 0$. Let $\{U_t\}_{t \in (0,\varepsilon)}$ be a family of open subsets with smooth boundary such that $U = \bigcup_{t \in (0,\varepsilon)} U_t$ and $U_{t_1} \supset U_{t_2}$ whenever $t_1 < t_2$ (one can also consider $\{U_t\}$ as a sequence).\footnote{One could construct such a thing explicitly using e.g.\ the distance to the boundary $\partial U$.} We have
\begin{align*}
	0
	&= \int_U f(\Delta f) \dx
	= \lim_{t \to 0} \int_{U_t} f(\Delta f) \dx \\
	&= \lim_{t \to 0} \left( -\int_{U_t} \norm{\grad f}^2 \dx + \int_{\partial U_t} f(N_t f) \d(\partial U_t) \right) \\
	&= \lim_{t \to 0} \left( -\int_{U_t} \norm{\grad f}^2 \dx + \int_{\partial U_t} f \scalprod{N_t}{\grad f} \d(\partial U_t) \right)
\end{align*}
where the passage to the second line follows from Green's formula~I. For $t \to 0$, we have $N_t \to N$, $\d(\partial U_t) \to \d(\partial U)$ and $f \to 0$. Since in addition $\grad f$ is bounded, the limit as $t \to 0$ of the last integral is $0$, and therefore
\[
0 = -\int_U \norm{\grad f}^2 \dx.
\]
Hence $\grad f = 0$ on $U$ and therefore $f$ is constant on $U$. Since in addition $f$ is continuous on $\overline{U}$ with $f|_{\partial U} = 0$, it follows that $f = 0$.

(b) Let $f$ be a solution of (b2). Then for $\{U_t\}_{t\in (0,\varepsilon)}$ as above, we obtain
\begin{align*}
	0 &= \lim_{t \to 0} \int_{U_t} 1 (\Delta f) \dx
	= \lim_{t \to 0} \left( -\int_{U_t} \scalprod{\grad 1}{\grad f} \dx + \int_{\partial U_t} 1N_t f \d(\partial U_t) \right) \\
	&= \lim_{t \to 0} \int_{\partial U_t} N_t f \d(\partial U_t)
	= \int_{\partial U} N f \d(\partial U) 
	= \int_{\partial U} \varphi \d(\partial U).
\end{align*}
The second equality in the computation above follows again from Green's formula~I.

(c) Let $f_1, f_2$ be two solutions of (b2). We consider $f:= f_1 - f_2$. Then $f$ solves (b2) with $\varphi = 0$. In particular, $f \varphi = f \, Nf = 0$ on $\partial U$. As in the proof of (a) we obtain using Green's formula~I
\[
\int_U \norm{\grad f}^2 \dx = 0.
\]
Hence $f$ is constant.
\end{proof}

\begin{recall}
The volume of the sphere $S^{n-1} := \{ x \in \Rbb^n \mid \norm{x} = 1 \}$ will be denoted by
\[
\omega_n := \vol_{n-1}(S^{n-1}) := \int_{S^{n-1}} 1 \d(S^{n-1}).
\]
There are several ways to compute $\omega_n$ explicitly. By Cavalieri's principle, we have
\[
c_n := \vol_n B(0,1)
= \int_0^1 \vol_{n-1} \big( \{x \mid \norm{x} = r\} \big) \d{}r
= \int_0^1 \omega_n r^{n-1} \d{}r
= \frac{\omega_n}{n}.
\]
One knows that
\[
c_n = \frac{\pi^{n/2}}{\Gamma(\frac{n}{2} + 1)},
\]
where $\Gamma$ is the Gamma function, defined by
\[
\Gamma(s) = \int_0^\infty e^{-t} t^{s-1} \d{}t \quad(\forall s > 0).
\]
We have $\Gamma(n+1) = n!$ for all $n \in \Nbb$ and $x \Gamma(x) = \Gamma(x+1)$ for all $x > 0$. It follows that for all $n \in \Nbb$,
\[
\omega_n = n c_n = \frac{\pi^{n/2}n}{\Gamma(\frac{n}{2}+1)}
= \frac{\pi^{n/2}n}{\frac{n}{2}\Gamma(\frac{n}{2})}
= \frac{2\pi^{n/2}}{\Gamma(\frac{n}{2})}.
\]
For instance, $\omega_2 = 2\pi$ and
$\displaystyle
\omega_3 = \frac{2\pi^{3/2}}{\Gamma(\frac{3}{2})}
= \frac{2\pi^{3/2}}{\frac{1}{2}\Gamma(\frac{1}{2})}
= \frac{2\pi^{3/2}}{\frac{1}{2}\sqrt{\pi}}
= 4 \pi
$.
\end{recall}

\begin{dfn}
We call ``fundamental solutions of $-\Delta$'' the functions $\gamma_n \colon \Rbb^n \smallsetminus \{0\} \to (0,\infty) \subset \Rbb$ defined as
\begin{align*}
	n = 2\colon \quad & \gamma_n(x) = -\frac{1}{\omega_2} \log \norm{x}, \\
	n \geqslant 3\colon \quad & \gamma_n(x) = \frac{1}{(n-2)\omega_n} \norm{x}^{2-n}.
\end{align*}
\end{dfn}

Recall that $\gamma_n$ is harmonic on $\Rbb^n \smallsetminus \{0\}$ (see Corollary~\ref{Cor:HarmonicRadialFcts}) and $\gamma_n|_{B(0;R)} \in L^1(B(0;R))$.

\begin{prop}\label{Prop:SolutionsOfDelta}
Let $U \subset \Rbb^n$ be an open, connected and bounded subset such that $\partial U$ is smooth. Let $f \in C^2(\overline{U})$ and $x \in U$. Then
\begin{equation}\label{Eq:Prop:SolutionsOfDelta}
f(x) =
- \int_U \gamma_n(x-y) \Delta f(y) \d{}y
+ \int_{\partial U} \gamma_n(x-y) Nf(y) - f(y)N_y \gamma_n(x-y) \d(\partial U(y)).
\end{equation}
\end{prop}

\begin{proof}
For $\varepsilon > 0$ such that $B(x;\varepsilon) \subset U$, we consider the open subset $U_\varepsilon := U \smallsetminus B(x;\varepsilon)$. We compute
\begin{align*}
	-\int_{U_\varepsilon} \gamma_n(x-y) \Delta f(y) \d{}y
	&= \int_{U_\varepsilon} f(y) \Delta_y \gamma_n(x-y) - \gamma_n(x-y) \Delta f(y) \d{}y \\
	&= \int_{\partial U} f(y) N\gamma_n(x-y) - \gamma_n(x-y) Nf(y) \d{}y \\
	&\qquad - \int_{S^{n-1}(x;\varepsilon)} f(y) N\gamma_n(x-y) - \gamma_n(x-y) Nf(y) \d{}(S^{n-1}(x;\varepsilon)(y)),
\end{align*}
where the first equality follows from the fact that $\Delta \gamma_n = 0$ on $\Rbb^n \smallsetminus \{0\}$ and the second equality is due to Green's formula~II. Note that in the last integral, $N$ denotes the outer normal field of the sphere $S^{n-1}(x;\varepsilon)$, which points inside $U_\varepsilon$. For this reason, the minus sign before the last integral appears.

%We investigate the last integral for $n \geqslant 3$ (for $n = 2$, the computation is analogous).
We set
\[
%I_1(\varepsilon) := \int_{S^{n-1}(x;\varepsilon)} f(y)  N\gamma_n(x-y)\d{}(S^{n-1}(x;\varepsilon)(y))
I_1(\varepsilon) := \int_{S^{n-1}(x;\varepsilon)} f(y)  N\gamma_n(x-y)\d{}y
\]
and
\[
%I_2(\varepsilon) := \int_{S^{n-1}(x;\varepsilon)} \gamma_n(x-y) Nf(y) \d{}(S^{n-1}(x;\varepsilon)(y)).
I_2(\varepsilon) := \int_{S^{n-1}(x;\varepsilon)} \gamma_n(x-y) Nf(y) \d{}y.
\]
By taking $\varepsilon$ to $0$, we find that the RHS of~\eqref{Eq:Prop:SolutionsOfDelta} is equal to
\[
- \lim_{\varepsilon \to 0} I_1(\varepsilon) - \lim_{\varepsilon \to 0} I_2(\varepsilon).
\]
We investigate the integrals $I_1(\varepsilon)$ and $I_2(\varepsilon)$ for $n \geqslant 3$ (for $n = 2$, the computation is analogous).

As for $I_2(\varepsilon)$, observe that
\[
\gamma_n(x-y) = \frac{1}{(n-2) \omega_n} \varepsilon^{2-n}
\]
on $S^{n-1}(x;\varepsilon)$ and
\[
\abs{N f(y)} \leqslant C
\]
for all $y \in S^{n-1}(x;\varepsilon)$, where $C$ is a constant (independent of $\varepsilon$ near $0$). It follows that
\[
\abs{I_2(\varepsilon)} \leqslant C' \vol S^{n-1}(x;\varepsilon) \varepsilon^{2-n} = C'' \varepsilon^{n-1} \varepsilon^{2-n} = C'' \varepsilon.
\]
Therefore $\lim_{\varepsilon \to 0} I_2(\varepsilon) = 0$.

It remains to show that $\lim_{\varepsilon \to 0} I_1(\varepsilon) = -f(x)$. In polar coordinates around $x \in U$, we have
\[
N = \frac{\partial}{\partial r}
\quad
\text{and}
\quad
\gamma_n (x-y) = \frac{1}{(n-2) \omega_n} r^{2-n}.
\]
Therefore
\[
N \gamma_n(r) = - \frac{1}{\omega_n} r^{1-n}
\]
and on $S^{n-1}(x;\varepsilon)$,
\[
N \gamma_n(r) = - \frac{1}{\omega_n} \varepsilon^{1-n}.
\]
It follows that
\begin{align*}
	I_1(\varepsilon)
	= \int_{S^{n-1}(x;\varepsilon)} f(y) N\gamma_n(x-y) \d{}y
	= - \frac{1}{\omega_n} \varepsilon^{1-n} \int_{S^{n-1}(x;\varepsilon)} f(y) \d{}y \\
	= - \frac{1}{\omega_n} \varepsilon^{1-n} \left( \int_{S^{n-1}(x;\varepsilon)} f(x) \d{}y - \int_{S^{n-1}(x;\varepsilon)} f(y) - f(x) \d{}y \right).
\end{align*}
Since $f$ is continuous, we have $\abs{f(y) - f(x)} < C(\varepsilon)$ with $\lim_{\varepsilon \to 0} C(\varepsilon) = 0$ and therefore the last integral goes to $0$ for $\varepsilon \to 0$. We obtain finally $\lim_{\varepsilon \to 0} I_1(\varepsilon) = -f(x)$. The proposition follows.
\end{proof}

\begin{cor}\label{Cor:SolutionsOfDeltaForCompaclySuppFcts}
Let $f \in C^2_c(\Rbb^n)$ be a compactly supported $C^2$-function. Then
\begin{equation}\label{Eq:Prop:SolutionsOfDeltaForCopmSuppFcts}
f(x) = - \int_{\Rbb^n} \gamma_n(x-y) \Delta f(y) \d{}y,
\end{equation}
i.e.\ $f(x) = -(\gamma_n * \Delta f)(x)$.
\end{cor}

\begin{proof}
We choose $U$ open, bounded and connected with smooth boundary (e.g.\ $U = B(0;R)$ with $R$ sufficiently large) such that $\supp f \subset U$. Then $f|_{\partial U} = 0 = Nf|_{\partial U}$. We apply Proposition~\ref{Prop:SolutionsOfDelta}. The boundary integral gives $0$.
\end{proof}

It follows from Corollary~\ref{Cor:SolutionsOfDeltaForCompaclySuppFcts} that there are no harmonic functions with compact support other than $0$.

For $f \in C^2_c(\Rbb^n)$ we can recover $f$ from $\Delta f$ by~\eqref{Eq:Prop:SolutionsOfDeltaForCopmSuppFcts}. Thus one could try to use~\eqref{Eq:Prop:SolutionsOfDeltaForCopmSuppFcts} in order to solve the Poisson equation $\Delta f = \varphi$ for $\varphi \in C^2_c(\Rbb^n)$.

\begin{prop}[Special solution for the Poisson equation $\Delta f = \varphi$]\label{Prop:SolPoissonEq}
Let $\varphi \in C^1_c(\Rbb^n)$. Then
\[
f(x) := -\int_{\Rbb^n} \gamma_n(x-y) \varphi(y) \d{}y
\]
defines a $C^2$-function on $\Rbb^n$ that satisfies $\Delta f = \varphi$.
\end{prop}

\begin{rem}
(a) If $\varphi \in C_c(\Rbb^n) \smallsetminus C^1_c(\Rbb^n)$ then $f$ defined as above is not necessarily a $C^2$-function. The equation $\Delta f = \varphi$ does not make sense (in the strong sense). But it still holds in a weaker sense. In this case, $f$ is called a ``weak solution'' of $\Delta f = \varphi$. These notions will be explained in the next semester in the framework of distributions.

(b) The function $f$ defined above does not have necessarily compact support.
\end{rem}

\begin{proof}[Proof of Proposition~\ref{Prop:SolPoissonEq}]
See handwritten notes (Proposition~4). %nedodelek
\end{proof}

If we want to apply a similar method in order to solve boundary value problems (e.g.\ b1, b2 or b4), one has to modify the fundamental solutions $\gamma_n$ (depending on $U$). Before we do this we want to exploit Proposition~\ref{Prop:SolutionsOfDelta} further in order to understand harmonic functions.

The following result is known as the mean value property of harmonic functions.

\begin{prop}\label{Prop:MeanValueProperty}
Let $U \subset \Rbb^n$ be an open subset and let $f \colon U \to \Com$ be a harmonic function. Let $x \in U$ and $R > 0$ be such that $B(x;R) \subset U$. Then
\[
f(x) = \frac{1}{\omega_n R^{n-1}} \int_{S^{n-1}(x;R)} f(y) \d S^{n-1}(x;R)(y).
\]
\end{prop}

\begin{proof}
See handwritten notes (Proposition~5). %nedodelek
\end{proof}

The following proposition claims that harmonic functions satisfy the maximum principle:

\begin{prop}\label{Prop:MaximumPrinciple}
Let $U \subset \Rbb^n$ be an open, bounded and connected subset, and let $f \in C(\overline{U})$ be a real-valued function such that $f|_U$ is harmonic. If $f$ assumes its maximum or minimum in $U$, then $f$ is constant.
\end{prop}

\begin{proof}
Let $M:= \max_{x \in \overline{U}} f(x)$ and $A:= \{ x \in U \mid f(x) = M\}$. Since $f$ is continuous, $A$ is a closed subset of $U$. We will show that $A$ is also open. Let $x \in A$. Choose $R > 0$ such that $B(x;R) \subset U$. Let $r \leqslant R$. Then
\[
M = f(x) = \frac{1}{\omega_n r^{n-1}} \int_{S^{n-1}(x;r)} f(y) \d{}y
\]
by the mean value property. We have $f(y) \leqslant M$ for all $y \in U$. Since $f$ is continuous, the above equality implies $f(y) = M$ for all $y \in S^{n-1}(x;r)$. It follows that $f(y) = M$ for all $y \in B(x;R)$ and hence $B(x;R) \subset A$. Therefore $A$ is open.

Since $U$ is connected, the fact that $A$ is closed and open in $U$ implies that $A = \varnothing$ or $A = U$. If $f$ assumes its maximum in $U$, then $A$ is non-empty and therefore $A = U$. Then $f(x) = M$ for all $x \in U$, so $f$ is constant.

For minimum one argues analogously.
\end{proof}

\begin{rem}
Compare analogous properties of holomorphic functions from complex analysis.
\end{rem}

We return to the discussion of boundary value problems and fundamental solutions.

\begin{dfn}[Green's functions for a domain $U$]
Let $U \subset \Rbb^n$ be an open, bounded and connected subset with smooth boundary $\partial U$. For $x \in U$, let $\phi_x \in C^2(\overline{U})$ be such that

(i) $\phi_x|_U$ is harmonic,

(ii) $\phi_x(y) = -\gamma_n(x-y)$ for all $y \in \partial U$.

\noindent (In other words, $\phi_x$ is solution of the Dirichlet problem (b1) with $\varphi = - \gamma_n(x-.)$.)

Then the function
\[
G(x,y) = \gamma_n(x-y) + \phi_x(y) \quad(x \in U, \, y \in \overline{U})
\]
is called a Green's function for $U$.
\end{dfn}

\begin{rem}
(a) $G(x,.)|_{U \smallsetminus \{ x \}}$ is harmonic and $G(x,.)|_{\partial U} = 0$.

(b) By Proposition~\ref{Prop:UniquenessB1B2}, $\phi_x$ is uniquely determined by the above conditions. Therefore $G$ is also uniquely determined.

(c) Existence of $G$ can be shown by using much more theory. We will only show the existence (and explicit formulas) for the case $U = B(x;R)$.

(d) One can show that $G(x,y) = G(y,x)$ for all $x,y \in U$.
\end{rem}

\begin{prop}
Let $U$ be as in Definition~3 with a Green's function $G$. Let $f \in C^2(\overline{U})$ and $x \in U$. Then
\[
f(x)
= - \int_U G(x,y) \Delta f(y) \d{}y
- \int_{\partial U} f(y) N_y G(x,y) \d{}(\partial U)(y).
\]
\end{prop}

\begin{proof}
Consequence of (b2) and Proposition~\ref{Prop:SolutionsOfDelta}. See handwritten notes (Proposition~7). %nedodelek
\end{proof}

\begin{cor}
Let $f \in C^2(\overline{U})$ be a function with $\Delta f = \varphi$, $f|_{\partial U} = 0$ (i.e.\ $f$ is a solution of (b4)). Then
\[
f(x)
= - \int_U G(x,y) \varphi(y) \d{}y.
\]
\end{cor}

%\begin{proof}
%Obvious.
%\end{proof}

\begin{rem}
One can also show that the above formula always produces a solution (compare Proposition~\ref{Prop:SolPoissonEq}). If $\varphi \in C^1(\overline{U})$, then
\begin{equation}\label{Eq:SolB4}
f(x) := - \int_U G(x,y) \varphi(y) \d{}y
\end{equation}
is $C^2$, satisfies $f|_{\partial U} = 0$ and $\Delta f = \varphi$. Thus~\eqref{Eq:SolB4} gives the unique solution of the problem~(b4).
\end{rem}

We now consider (b1).

\begin{cor}\label{Cor:FormOfSolutionsOfB1}
Let $f \in C^2(\overline{U})$ be such that $f|_U$ is harmonic and $f|_{\partial U} = \varphi$. Then
\begin{equation}\label{Eq:Cor:SolB1}
f(x) = - \int_{\partial U} (N_y G(x,y)) \varphi(y) \d{}y.
\end{equation}
\end{cor}

Thus solutions of the Dirichlet problem (b1) with $f \in C^2(\overline{U})$ have necessarily the form~\eqref{Eq:Cor:SolB1}. In many cases one can also prove the ``contrary'': \eqref{Eq:Cor:SolB1} always gives solutions of (b1). We want to do this for $U = B(0;R)$.

\begin{ex}[Green's functiond for balls]
Let $U = B(0;R) \subset \Rbb^n$. Then
\[
G(x,y) = \gamma_n(x-y) - \gamma_n \left( \frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y \right),
\]
i.e.\
\[
\phi_x(y) = - \gamma_n \left( \frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y \right).
\]

In order to check that $G$ is really the Green's function, we have to check the following properties:

\indent \indent (i) $\phi_x \in C^2(\overline{U})$,

\indent \indent (ii) $\phi_x|_U$ is harmonic,

\indent \indent (iii) $\phi_x(y) = - \gamma_n(x-y)$ for all $y \in \partial U$.

It is clear that condition (iii) holds, since on $\partial U$, we have $\abs{y} = R$.

We know that $\gamma_n$ only depends on the norm of the argument. We compute
\begin{equation}\label{Eq:SymmetryPhiX}
\Abs{ \frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y }^2
= \scalprod{ \frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y }{ \frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y }
= \frac{\abs{y^2}\abs{x^2}}{R} - 2 \scalprod{x}{y} + R^2.
\end{equation}
This is symmetric in $x$ and $y$ and therefore also $\phi_x(y)$ is symmetric in $x$ and $y$.

We also have
\[
\frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y \neq 0
\]
for all $(x,y) \in U \times \overline{U}$, since
\[
\Abs{\frac{\abs{y}}{R}x} \leqslant \abs{x} < R
\quad \text{and} \quad
\Abs{\frac{R}{\abs{y}}y} = R.
\]
It follows that $\phi_x$ is of class $C^\infty$.

Furthermore, we know that $\gamma_n$ is harmonic on $\Rbb^n \smallsetminus \{0\}$. Therefore
\[
x \mapsto \phi_x(y) = -\gamma_n\left( \frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y \right) = - \gamma_n(ax + b)
\]
(where $a:= \abs{y}/R$ and $b := -Ry/\abs{y}$) is also harmonic on $\{x \in \Rbb^n \mid ax + b \neq 0\}$. Now using the symmetry~\eqref{Eq:SymmetryPhiX} we find that $y \mapsto \phi_x(y) = -\gamma_n\left( \frac{\abs{y}}{R} x - \frac{R}{\abs{y}} y \right)$ is harmonic on $U = B(0;R)$.
\end{ex}

\begin{lem}\label{Lemma:NyOfGreenFForBalls}
Let $G \colon B(0;R) \times \overline{B}(0;R) \to \Rbb$ be the Green's function as in the above example. Then for $n \geqslant 2$ and $y \in S^{n-1}(0;R) = \partial B(0;R)$, we have
\[
N_y G(x,y) = \frac{\abs{x}^2 - R^2}{R \omega_n \abs{x-y}^n}.
\]
\end{lem}

\begin{proof}
See handwritten notes (Lemma~2).
\end{proof}

\begin{rem}
For any fixed $y \in \partial U$, the function $x \mapsto N_y G(x,y)$ is harmonic in $x \in U$. (This is true for general $U$.)

Indeed, $\Delta_x N_y G(x,y) = N_y \Delta_x G(x,y) = N_y 0 = 0$. The equality $\Delta_x G(x,y) = 0$ follows from the fact that $G(x,.)|_{U \smallsetminus \{ x \}}$ is harmonic and $x \neq y$ (since $x \in U$ and $y \in \partial U$).
\end{rem}

The following theorem gives the solution of the Dirichlet problem for $U = B(0;R)$.

\begin{thm}[Solution of the Dirichlet problem for the ball]\label{Theo:SolDirichletOverBall}
Let $\varphi \in C(S^{n-1}(0;R))$. We define for $x \in B(0;R)$
\begin{equation}\label{PoissonsFormula}
f(x) = \frac{R^2 - \abs{x}^2}{R \omega_n}
\int_{S^{n-1}(0;R)} \frac{\varphi(y)}{\abs{x-y}^n} \d{}S^{n-1}(y).
\end{equation}
Then:

(a) $f$ is harmonic on $B(0;R)$,

%(b) $f$ extends continuously to $\overline{B}(0;R)$ and for any sequence $\{x_n\}_{n \in \Nbb} \in B(0;R)^\Nbb$ with $\lim_{n \to \infty} x_n = y \in S^{n-1}(0;R)$, we have $\lim_{n \to \infty} f(x_n) = \varphi(y)$.
(b) $f$ extends continuously to $\overline{B}(0;R)$ and for any sequence $\{x_n\}_{n \in \Nbb} \in B(0;R)^\Nbb$ converging to $y_0 \in S^{n-1}(0;R)$, we have $\lim_{n \to \infty} f(x_n) = \varphi(y_0)$.
\end{thm}

Shortly, $f$ solves the Dirichlet problem (b1) for $U = B(0;R)$ (and is the unique solution by Proposition~\ref{Prop:UniquenessB1B2}).

Formula \eqref{PoissonsFormula} is known as \textcolor{blue}{Poisson's formula}.

\begin{proof}
(a) By the above remark, $\frac{R^2 - \abs{x}^2}{\abs{x-y}^n}$ is harmonic in $x \in B(0;R)$ for any fixed $y \in S^{n-1}(0;R)$. We apply just differentiation of parameter-dependent integrals.

(b) See handwritten notes (Theorem~1). %nedodelek
\end{proof}

Using Poisson's formula we want to establish further properties of harmonic functions.

Let $U \subset \Rbb^n$ be an open subset, $f \colon U \to \Com$ a harmonic function and $x_0 \in U$. Then Corollary~\ref{Cor:FormOfSolutionsOfB1} combined with Lemma~\ref{Lemma:NyOfGreenFForBalls} gives
\begin{equation}\label{FormulaB}
f(x) = \frac{r^2 - \abs{x-x_0}^2}{r \omega_n}
\int_{S^{n-1}(x_0;r)} \frac{f(y)}{\abs{x-y}^n} \d{}y %zkontrolovat R / r
\end{equation}
for all $x \in B(x_0;r)$.

\begin{prop}\label{Prop:HarmFctsAreSmooth}
Let $U \subset \Rbb^n$ be an open subset and let $f \colon U \to \Com$ be harmonic. Then $f \in C^\infty(U)$, i.e.\ $f$ is smooth.
\end{prop}

\begin{proof}
The theorem on the differentiation of parameter-dependent integrals applied to~\eqref{FormulaB} shows that $D^\alpha f(x)$ exists for all $\alpha \in \Nbb^n_0$, $x \in B(x_0;r)$, and is given by a similar integral formula. Hence $f|_{B(x_0;r)}$ is smooth. Since $x_0 \in U$ is arbitrary, $f$ is smooth on $U$.
\end{proof}

\begin{rem}
There is a class of differential operators, called elliptic operators. $\Delta$ is just a prototype of an elliptic operator. Elliptic operators $D$ have the so-called regularity property: if $Df = g$ and $g$ is smooth, then $f$ is smooth. Proposition~\ref{Prop:HarmFctsAreSmooth} is a special case with $g = 0$.
\end{rem}

\begin{prop}[Liouville]
Let $f \colon \Rbb^n \to \Rbb$ be a harmonic function. If $f$ is bounded from above or below, then $f$ is constant. If $f \colon \Rbb^n \to \Com$ is harmonic and bounded, i.e.\ $\abs{f(x)} \leqslant C$ for all $x \in \Rbb^n$, then $f$ is constant.
\end{prop}

\begin{proof}
Assume that $f \colon \Rbb^n \to \Rbb$ is harmonic and bounded from below. Then $f + C \geqslant 0$ for some constant $C$ and $f + C$ is harmonic. If $f$ is harmonic and bounded from above, then $-f$ is bounded from below and harmonic. If $f \colon \Rbb^n \to \Com$ is harmonic and bounded, then $\RePart f$ and $\ImPart f \colon \Rbb^n \to \Rbb$ are harmonic and bounded (from above and below). This discussion shows that it suffices to prove the following: if $f \colon \Rbb^n \to \Rbb$ is harmonic with $f(x) \geqslant 0$ for all $x \in \Rbb^n$, then $f$ is constant.

Let $x \in \Rbb^n$. Choose $R > \abs{x}$. Then \eqref{FormulaB} (for $r = R$, $x_0 = 0$) implies
\begin{align*}
	f(x)
	&= \frac{R^2 - \abs{x}^2}{R \omega_n} \int_{S^{n-1}(0;R)} \frac{f(y)}{\abs{x-y}^n} \d{}y
	\leqslant \frac{R^2 - \abs{x}^2}{R \omega_n (R - \abs{x})^n} \, \int_{S^{n-1}(0;R)} f(y) \d{}y \\
	&= \frac{R^2 - \abs{x}^2}{R \omega_n (R - \abs{x})^n} \, R^{n-1} \omega_n f(0)
	= \frac{(R^2 - \abs{x}^2) R^{n-2}}{(R - \abs{x})^n} \, f(0).
\end{align*}
The inequality in the first line results from the fact that $\abs{x-y} \geqslant \abs{y} - \abs{x} = R - \abs{x}$, and the passage to the second line follows from the mean value property (Proposition~\ref{Prop:MeanValueProperty}). By taking $R$ to infinity, we obtain $f(x) \leqslant f(0)$. Since $x \in \Rbb^n$ was chosen arbitrarily, this implies that $f$ has a maximum at $x = 0$. It follows from the maximum primciple (Proposition~\ref{Prop:MaximumPrinciple}) that $f|_{B(0;R)}$ is constant. This is true for all $R > 0$, so $f$ is constant on the whole $\Rbb^n$.
\end{proof}

\subsection{Dirichlet eigenvalues (b3) for the unit disc in $\Rbb^2$}

The polar coordinates in $\Rbb^2$ are defined by the relations $x = r \cos \varphi$ and $y = r \sin \varphi$. In these coordinates, the Laplace operator has the following form:
\[
\Delta = \frac{\partial^2}{\partial r^2} + \frac{1}{r} \frac{\partial}{\partial r} + \frac{1}{r^2} \frac{\partial^2}{\partial \varphi^2}.
\]

%We want to find functions $f \colon \Rbb^2 \supset B(0;1) \to \Com$ and constants $\lambda \in (0,\infty)$ such that

%\indent \indent (a) $\Delta f + \lambda f = 0$ and

%\indent \indent (b) $f|_{S^1(0;1)} = 0$.

%\noindent If we write $f$ in local coordinates, the last condition is equivalent to

%\indent \indent (b) $f(1,\varphi) = 0$.

We want to find functions $f \colon \Rbb^2 \supset B(0;1) \to \Com$ and constants $\lambda \in (0,\infty)$ such that (a) $\Delta f + \lambda f = 0$ and (b) $f|_{S^1(0;1)} = 0$. If we write $f$ in polar coordinates, the last condition can be equivalently stated as (b) $f(1,\varphi) = 0$. Note that $f$ is $2\pi$-periodic in $\varphi$.

We make the ansatz
\[
f(r,\varphi) = h(\sqrt{\lambda}r) e^{in\varphi}
\]
for some $n \in \Zbb$. We have
\[
\Delta f(r,\varphi) = \left( \lambda h''(\sqrt{\lambda}r) + \frac{\sqrt{\lambda}}{r} h'(\sqrt{\lambda}r) - \frac{n^2}{r^2} h(\sqrt{\lambda}r) \right) e^{in\varphi},
\]
so condition (a) takes the form
\[
\lambda h''(\sqrt{\lambda}r) + \frac{\sqrt{\lambda}}{r} h'(\sqrt{\lambda}r) + \left(\lambda - \frac{n^2}{r^2} \right) h(\sqrt{\lambda}r) = 0.
\]
This can be written equivalently using the change of variables $x = \sqrt{\lambda} r$, $\lambda = \frac{x^2}{r^2}$ as
\[
\frac{x^2}{r^2} h''(x) + \frac{x}{r^2} h'(x) + \left( \frac{x^2}{r^2} - \frac{n^2}{r^2} \right) h(x) = 0,
\]
which is equivalent to say that
\[
x^2 h''(x) + xh'(x) + (x^2 - n^2)h(x) = 0.
\]
The last equation is known as ``Bessel's differential equation'' and its solutions are called ``Bessel's functions''. The space of solutions is 2-dimensional. One special solution is the ``Bessel function of first kind''
\[
J_n(z) = \left( \frac{z}{2} \right)^n \sum_{k=0}^\infty \frac{(-1)^k}{k! (n+k)!} \left( \frac{z}{2} \right)^{2k}
\]
for $n \in \Nbb_0$. We have
\[
J_n(0) = \begin{cases} 1 & \text{if $n=0,$} \\ 0 & \text{if $n>0.$} \end{cases}
\]
A second solution, often denoted by $N_n(z)$, has the property
\[
\lim_{z \to 0} \abs{N_n(z)} = \infty.
\]
In particular, multiples of $J_n$ are the only solutions that are defined at $x = 0$. We therefore define
\[
f_{\lambda,n}(r \varphi) = J_n(\sqrt{\lambda}r) e^{\pm in \varphi}
\]
if $J_n(\sqrt{\lambda}) = 0$.

In other words, let $\mu_{n,k}$, $n = 0,1,2, \dots$, $k = 1,2,3, \dots$, be the zeroes of $J_n$, then the solutions of our problem are given by
\[
\lambda_{n,k} = \mu^2_{n,k}
\]
and
\[
f^{\pm}_{n,k}(r,\varphi) = J_n(\mu_{n,k} r) e^{\pm in \varphi}.
\]

For zeroes of Bessel's functions see e.g.\\ \url{http://mathworld.wolfram.com/BesselFunctionZeros.html}.

\begin{rem}
That our ansatz gives all solutions is a consequence of the theory of Fourier series (in the variable $\varphi$).
\end{rem}

\section{The heat equation}

Let $U \subset \Rbb^n$ be an open subset and let $I \subset \Rbb$ be an open interval. Recall that a function $f \colon I \times U \to \Com$ of class $C^2$ satisfies the heat equation if
\[
\frac{\partial f}{\partial t} (t,x) = \Delta_x f(t,x)
\]
for all $(t,x) \in I \times U$.

Let $h \colon (0,\infty) \times \Rbb^n \to \Com$ be defined by
\[
h(t,x) = \frac{1}{(4\pi t)^{n/2}} \, e^{-\frac{\abs{x}^2}{4t}}.
\]
The function $h$ satisfies the heat equation and is called ``fundamental solution of the heat equation'' (see Section~\ref{Subsection:PropertiesFT}.a).

\begin{lem}\label{Lemma:IntOfHIsOne}
Let $h$ be defined as above. We have
\[
\int_{\Rbb^n} h(t,x) \dx = 1.
\]
\end{lem}

\begin{proof}
We have
\[
\int_{\Rbb^n} h(t,x) \dx = (2\pi)^{n/2} \, \widehat{h}(t,0) = 1,
\]
where $\widehat{h}$ denotes the Fourier transform of $h$ with respect to the variable $x$. The last equality follows from the fact that
\[
\widehat{h}(t,\xi) = \frac{1}{(2\pi)^{n/2}} \, e^{-t\abs{\xi}^2}
\]
(see Section~\ref{Subsection:PropertiesFT}).
\end{proof}

\subsection{Cauchy problem for the heat equation on $\Rbb^n$}%(or initial value problem)

Given a continuous function $\varphi \colon \Rbb^n \to \Com$, we are looking for $f \colon [0,\infty) \times \Rbb^n \to \Com$ such that $f|_{(0,\infty) \times \Rbb^n}$ is $C^2$, satisfies the heat equation and $f(0,x) = \varphi(x)$.

For bounded $\varphi$, a solution of this problem is given by the following theorem:

\begin{thm}\label{Theo:SolHomCauchyForHeatEq}
Let $\varphi \colon \Rbb^n \to \Com$ be continuous and bounded. Let $h$ be the fundamental solution of the heat equation as above. We define for $t \in (0,\infty)$
\[
f(t,x) = \int_{\Rbb^n} h(t,x-y) \varphi(y) \d{}y.
\]
Then $f$ extends to a continuous function on $[0,\infty) \times \Rbb^n$ and solves the Cauchy problem above. Moreover, $f$ is bounded.
\end{thm}

\begin{proof}
Since $h(t,.)$ is a Schwartz function and since $\varphi$ is bounded, there are no problems with the existence of the integral defining $f$. Moreover, differentiation of parameter-dependent intagrals shows that $f \in C^2((0,\infty)\times \Rbb^n)$ (in fact $C^\infty$) and $\Delta_x f = \frac{\partial f}{\partial t}$ (since $\Delta_x h = \frac{\partial h}{\partial t}$).

Next, we show that $f$ is bounded. Since $\varphi$ is bounded, there exists a constant $C > 0$ such that $\abs{\varphi(x)} < C$ for all $x$. We have
\[
\abs{f(t,x)}
\leqslant
\int_{\Rbb^n} h(t, x-y) \abs{\varphi(y)} \d{}y
\leqslant
C \int_{\Rbb^n} h(t, x-y) \d{}y
=
C \int_{\Rbb^n} h(t, z) \d{}z
= C.
\]
The last equality in the preceding line follows from Lemma~\ref{Lemma:IntOfHIsOne}.

It remains to show that
\begin{equation}\label{Eq1:Theo:CauchyHeatEq}
\lim_{(t,x) \to (0,x_0)} f(t,x) = \varphi(x_0).
\end{equation}
We have shown in Section~\ref{Subsection:PropertiesFT} that
\[
\lim_{t \to 0} \int_{\Rbb^n} h(t,y) \psi(y) \d{}y = \psi(0)
\]
for $\psi \in \S(\Rbb^n)$. This gives~\eqref{Eq1:Theo:CauchyHeatEq} for Schwartz functions. We want to have~\eqref{Eq1:Theo:CauchyHeatEq} for arbitrary bounded continuous functions. So we have to use some other argument. By Lemma~\ref{Lemma:IntOfHIsOne}, we have
\[
f(t,x) - \varphi(x_0)
= \int_{\Rbb^n} h(t,x-y) \big( \varphi(y) - \varphi(x_0) \big) \d{}z
= \int_{\Rbb^n} h(t,z) \big( \varphi(x-z) - \varphi(x_0) \big) \d{}z.
\]
As in the proof of Theorem~\ref{Theo:SolDirichletOverBall}, we split the last integral into two pieces, one over $\Rbb^n \smallsetminus B(0;r)$ and the other over $B(0;r)$.

As for the integral over $\Rbb^n \smallsetminus B(0;r)$, we have
\[
\Abs{\int_{\Rbb^n \smallsetminus B(0;r)} h(t,y) \big( \varphi(x-y) - \varphi(x_0) \big) \d{}y}
\leqslant
2 \sup_{x \in \Rbb^n} \abs{\varphi(x)} \int_{\Rbb^n \smallsetminus B(0;r)} h(t,y) \d{}y
\]
and
\[
\int_{\Rbb^n \smallsetminus B(0;r)} h(t,y) \d{}y
= \int_{\Rbb^n \smallsetminus B(0;r)} \frac{1}{(4\pi t)^{n/2}} e^{-\frac{\abs{y}^2}{4t}} \d{}y
= \frac{1}{\pi^{n/2}} \int_{\Rbb^n \smallsetminus B(0; \frac{r}{2\sqrt{t}})} e^{-\abs{x}^2} \dx
\xrightarrow{t \to 0} 0,
\]
where the change of variables $x = \frac{y}{2\sqrt{t}}$, $\d{}y = (4t)^{n/2} \dx$ is used.

Now consider the integral over $B(0;r)$. Let $\varepsilon > 0$ be given. Since $\varphi$ is continuous, we can choose $r > 0$ such that
\[
\absbig{\varphi(x) - \varphi(x_0)} \leqslant \frac{\varepsilon}{2} \quad \forall x \in B(x_0,2r).
\]
Let $x \in B(x_0,r)$. Then
\[
\Abs{\int_{B(0;r)} h(t,y) \big( \varphi(x-y) - \varphi(x_0) \big) \d{}y }
\leqslant \frac{\varepsilon}{2} \int_{B(0;r)} h(t,y) \d{}y
\leqslant \frac{\varepsilon}{2} \int_{\Rbb^n} h(t,y) \d{}y
= \frac{\varepsilon}{2}.
\]

Choose $\delta > 0$ such that for all $t < \delta$,
\[
2 \sup_{x \in \Rbb^n} \abs{\varphi(x)} \int_{\Rbb^n \smallsetminus B(0;r)} h(t,y) \d{}y
\leqslant \frac{\varepsilon}{2}.
\]
% (this is possible since we have shown above that the integral over $\Rbb^n \smallsetminus B(0;r)$ goes to $0$ as $t \to 0$).
We obtain: for all $\varepsilon > 0$ there exist $r > 0$ and $\delta > 0$ such that for $x \in B(x_0,r)$ and $0 < t < \delta$,
\[
\absbig{f(t,x) - \varphi(x_0)}
\leqslant \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon.
\]
In other words, $\lim_{(t,x) \to (0,x_0)} f(t,x) = \varphi(x_0)$.
\end{proof}

\subsection{Inhomogeneous Cauchy problem for the heat equation}

Given a function $g \colon (0,T) \times \Rbb^n \to \Com$ (with $T = \infty$ allowed) and a continuous function $\varphi \colon \Rbb^n \to \Com$, we are looking for a continuous function $f \colon [0,T) \times \Rbb^n \to \Com$ such that $f|_{(0,T) \times \Rbb^n}$ is $C^2$ and
\begin{equation*}
\begin{array}{r@{{}={}}l}
\frac{\partial f}{\partial t} (t,x) & \Delta_x f(t,x) + g(t,x) \\[3pt]
f(0,x) & \varphi(x)	
\end{array}
\tag{ICP}
\end{equation*}
for all $(t,x) \in (0,T) \times \Rbb^n$.

\begin{thm}\label{Theo:SolInhomCauchyForHeatEq}
If $\varphi$ is bounded, $g \in C^1((0,T) \times \Rbb^n)$ and for all $t \in (0,T)$ the functions $g|_{(0,t] \times \Rbb^n}$ and $\left.\frac{\partial g}{\partial x_i}\right|_{[0,t) \times \Rbb^n}$ are bounded, then
\[
f(t,x) :=
\int_{\Rbb^n} h(t,x-y) \varphi(y) \d{}y + \int_0^t \int_{\Rbb^n} h(t-s,x-y) g(s,y) \d{}y \d{}s
\]
is a solution of ICP.
\end{thm}

We don't give a detailed proof (similar to the proof of Theorem~\ref{Theo:SolHomCauchyForHeatEq}). We just check formally that $f$ satisfies the inhomogeneous heat equation:
\begin{align*}
	\frac{\partial f}{\partial t}(t,x)
	&= \int_{\Rbb^n} \Delta_x h(t,x) \varphi(y) \d{}y \\
	& \qquad + \lim_{s \to t} \int_{\Rbb^n} h(t-s,x-y) g(s,y) \d{}y
	+ \int^t_0 \int_{\Rbb^n} \Delta_x h(t-s,x-y) g(s,y) \d{}y \d{}s \\
	&= \Delta_x f(t,x) + \lim_{s \to t} \int_{\Rbb^n} h(t-s,x-y) g(s,y)\d{}y.
\end{align*}
As in the proof of Theorem~\ref{Theo:SolHomCauchyForHeatEq} we obtain
\[
\lim_{s \to t} \int_{\Rbb^n} h(t-s,x-y) = g(t,x).
\]
Therefore $\frac{\partial f}{\partial t} = \Delta_x f + g$.

\begin{prop}[Maximum principle for the heat equation --- bounded domains]%~\\
Let $U \subset \Rbb^n$ be a bounded, open and connected subset, $T \leqslant \infty$ and $f \in C([0,T]\times \overline{U})$ a real-valued function such that $f|_{(0,T] \times U}$ is $C^2$ and satisfies the heat equation. Then $f$ assumes its maximum on $\{0\} \times U \cup [0,T] \times \partial U$. A similar statement holds true for minimum.
\end{prop}

\begin{proof}
See handwritten notes (Proposition~10).
\end{proof}

\begin{prop}[Maximum principle for bounded functions]\label{Prop:HE:MaximalPrincipleBndFcts}
Let $U = \Rbb^n$, $T \leqslant \infty$ and let $f \in C([0,T] \times \Rbb^n)$ be a real-valued function such that $f|_{(0,T] \times \Rbb^n}$ is $C^2$ and satisfies the (homogeneuous) heat equation. We assume in addition that $f|_{[0,t_0] \times \Rbb^n}$ is bounded for all $0 < t_0 < T$. Then
\[
\sup \big\{ f(t,x) \;\big|\; (t,x) \in [0,T] \times \Rbb^n \big \}
= \sup \big\{ f(0,x) \;\big|\; x \in \Rbb^n \big \}.
\]
\end{prop}

\begin{proof}
See handwritten notes (Proposition~11).
\end{proof}

\begin{prop}[Uniqueness of bounded solutions of the Cauchy problem]
Let $f_1$ and $f_2$ be two bounded solutions of ICP (for the same $g$ and $\varphi$). Then $f_1 = f_2$.
\end{prop}

\begin{proof}
We consider $f = f_1 - f_2$. Then $f$ is a solution of the HCP (homogeneous Cauchy problem) with $\widetilde{\varphi}(x) = f(0,x) = 0$. By going to real or imaginary parts of $f$ we can assume that $f$ is real-valued. Moreover, $f$ is bounded. By Proposition~\ref{Prop:HE:MaximalPrincipleBndFcts}, we get $f(t,x) \leqslant \sup_{x \in \Rbb^n} f(0,x) = 0$. Similarly, since $-f$ is a solution of the same HCP, we get $-f \leqslant 0$. Therefore $f = 0$.
\end{proof}

\begin{rem}
The solutions given in Theorems~\ref{Theo:SolHomCauchyForHeatEq} and~\ref{Theo:SolInhomCauchyForHeatEq} are unique among the bounded solutions of corresponding Cauchy problem. Among not necessarily bounded solutions uniqueness can fail.
\end{rem}

\section{The wave equation}

Let $I \times U \subset \Rbb^1 \times \Rbb^n$ be open. Then $f \in C^2(I \times U)$ is said to satisfy the wave equation if
\begin{equation}\label{Eq:WE}
\frac{\partial^2 f}{\partial t^2} = \Delta_x f
\tag{W}
\end{equation}
as function on $I \times U$.

In physics, the wave equation has the form
\[
\frac{1}{c^2} \frac{\partial^2 f}{\partial t^2} = \Delta_x f
\]
where $c$ is the material constant or ``speed of the light''. Here we just normalize $c = 1$. Solutions of~\eqref{Eq:WE} describe (mechanical or electromagnetic) waves.

Sometimes we will abbreviate~\eqref{Eq:WE} just to
\[
\Box f = 0,
\]
where
\[
\Box := \frac{\partial^2}{\partial t^2} - \Delta_x.
\]

For a continuous function $g$, one can consider the inhomogeneous wave equation:
\[
\Box f = g.
\]

\subsection{Homogeneous/inhomogeneous Cauchy problem}

Given $f_0$, $f_1 \in C(\Rbb^n)$ and $g \in C((0,\infty)\times \Rbb^n)$, we are looking for $f \in C([0,\infty) \times \Rbb^n)$ such that

(i) $f|_{(0,\infty) \times \Rbb^n} \in C^2$ and $\Box f = g$ on $(0,\infty) \times \Rbb^n$,

(ii) $f(0,x) = f_0(x)$ for all $x \in \Rbb^n$,

(iii) $\frac{\partial f}{\partial t}$ extends continuously to $t = 0$ and $\frac{\partial f}{\partial t} (0,x) = f_1(x)$.

\vspace{6pt}

The homogeneous Cauchy problem (HCP) is just the case $g = 0$. We will sometimes add additional differentiability conditions for $f$, $g$, $f_0$ or $f_1$. Here we have just required the minimal ones such that the problem makes sense.

%In dimension $n = 1$, we have the following characterization of the solutions of the wave equation:
We start by dealing with the case of dimension $n = 1$.

\begin{prop}
A function $f \in C^2(\Rbb^1 \times \Rbb^1)$ satisfies the wave equation $\Box f = 0$ if and only if there exists functions $f_+$, $f_- \in C^2(\Rbb^1)$ such that
\begin{equation}\label{Eq:SolWE:Dim1}
f(t,x) = f_+(x+t) + f_-(x-t).
\end{equation}
\end{prop}

\begin{proof}
See handwritten notes (Proposition~13).
\end{proof}

\begin{prop}[Solutions of HCP for $n = 1$]
Let $f_0 \in C^2(\Rbb^1)$ and $f_1 \in C^1(\Rbb^n)$. Then there is a unique solution $f$ of HCP such that $f \in C^2([0,\infty) \times \Rbb^n)$. It is given by~\eqref{Eq:SolWE:Dim1} with
\[
f_+(y) = \frac{1}{2} \big( f_0(y) + F_1(y) \big),
\qquad f_-(y) = \frac{1}{2} \big( f_0(y) - F_1(y) \big),
\]
where $F_1 \colon \Rbb \to \Com$ is a primitive of $f_1$. In other words,
\begin{equation}\label{Eq:SolWE:HCP:Dim1}
f(t,x)
= \frac{1}{2} \big( f_0(x+t) + f(x-t) \big)
+ \frac{1}{2} \int^{x+t}_{x-t} f_1(\tau) \d\tau.
\end{equation}
Function $f$ extends to solution of~\eqref{Eq:WE} on $\Rbb^1 \times \Rbb^1$ by~\eqref{Eq:SolWE:HCP:Dim1}.
\end{prop}

\begin{proof}
See handwritten notes (Proposition~14).
\end{proof}

\begin{prop}[Oscilating string with fixed endpoints]
Let $U = (0,\ell) \subset \Rbb^1$ be an open interval, and let $f_0 \in C^2(\overline{U})$, $f_1 \in C^1(\overline{U})$ be such that $f_0(0) = f_0(\ell) = f_1(0) = f_1(\ell) = 0$. We assume in addition that $f_0''(0) = f_0''(\ell) = 0$. Then there exists a unique function $f \in C^2([0,\infty) \times \overline{U})$ with

(a) $\Box f = 0$,

(b) $f(t,0) = f(t,\ell) = 0$,

(c) $f(0,x) = f_0(x)$ and $\frac{\partial f}{\partial t} (0,x) = f_1(x)$.

\noindent This solution is given by~\eqref{Eq:SolWE:HCP:Dim1} if $f_0$ is replaced by $\widetilde{f}_0$ and $f_1$ is replaced by $\widetilde{f}_1$ where $\widetilde{f}_i \colon \Rbb \to \Com$ are $2\ell$-periodic extensions of $f_i$, i.e.\ are characterized by

$\bullet$ $\widetilde{f}_i(y) = f_i(y)$, $y \in [0,\ell]$,

$\bullet$ $\widetilde{f}_i(y) = -\widetilde{f}_i(-y)$, $y \in [-\ell,0]$,

$\bullet$ $\widetilde{f}_i(y + 2\ell) = \widetilde{f}_i(y)$, $y \in \Rbb$.
\end{prop}

\begin{proof}
See handwritten notes (Proposition~15).
\end{proof}

Now $n$ is again an arbitrary positive dimension.

\begin{dfn}
Let $I \subset \Rbb$ be an interval and let $U \subset \Rbb^n$ be an open subset. Let $f \colon I \times U \to \Com$ be a solution of the wave equation~\eqref{Eq:WE}. We define the energy density of $f$
\[
E = E_f \colon I \times U \to [0,\infty)
\]
by
\[
E(t,x) = \frac{1}{2} \left( \Abs{\frac{\partial f}{\partial t}(t,x)}^2 + \Abs{\grad_x f(t,x)}^2 \right),
\]
i.e.\
\[
E(t,x) = \frac{1}{2} \left( \Abs{\frac{\partial f}{\partial t}(t,x)}^2 + \sum_{i=1}^n \Abs{\frac{\partial f}{\partial x_i} (t,x)}^2 \right).
\]
For an open subset $V$ of $U$, we define the energy of $f$ on $V$ by
\[
E(t,V) = \int_V E(t,x) \dx \in [0,\infty].
\]
\end{dfn}

We have the following version of ``conservation of energy'':

\begin{lem}
Let $f \colon I \times U \to \Rbb$ (for convenience) be a solution of~\eqref{Eq:WE}, and let $V \subset U$ be open, bounded subset with smooth boundary such that $\overline{V} \subset U$. Then
\[
\frac{\d{}}{\d{}t} E(t,V) = \int_{\partial V} \frac{\partial f}{\partial t} (t,x) N_x f(t,x) \d{}(\partial V)(x).
\]
\end{lem}

\begin{rem}
If $f(t,x) = 0$ (or another constant) for $t \in I_0 \subset I$, $x \in \partial V$, then $\frac{\partial}{\partial t} E(t,V) = 0$ for $t \in I_0$. In this sense we have conservation of energy.
\end{rem}

\begin{proof}
See handwritten notes (Lemma~4).
\end{proof}

\begin{prop}\label{Prop:WE:EnergyNonIncreasing}
Let $f \colon I \times U \to \Com$ be a solution of~\eqref{Eq:WE}. Fix $x_0 \in U$ and $R \in \Rbb$. Then for all $t \in I$ such that $R-t > 0$ we have
\[
\frac{\d{}}{\d{}t} E \big(t, B(x_0,R-t) \big) \leqslant 0.
\]
\end{prop}

\begin{proof}
See handwritten notes (Proposition~16).
\end{proof}

The following result can be interperted by the fact that waves have ``finite propagation speed'' (in our normalization the speed is 1).

\begin{thm}\label{Theo:FinitePropagationSpeed}
Let $f \colon I \times U \to \Com$ be a solution of~\eqref{Eq:WE} such that for some $(t_0,x_0) \in I \times U$,
\[
f(t_0,x) = 0 = \frac{\partial f}{\partial t}(t_0,x) \quad \forall x \in B(x_0;R).
\]
Then for all $t \in I$ with $t_0 \leqslant t < R + t_0$ we have
\[
f(t,x) = 0 \quad \forall x \in B \big(x_0, R - (t-t_0) \big).
\]
\end{thm}
%nedodelek: obrazek

\begin{proof}
By Proposition~\ref{Prop:WE:EnergyNonIncreasing}, we have
\[
\frac{\d{}}{\d{}t} E\big( t, B(x_0, R + t_0 - t) \big) \leqslant 0
\]
and by assumption,
\[
E\big(t_0, B(x_0,R)\big) = 0.
\]
Since energy is always non-negative, it follows that
\[
E \big( t, B(x_0, R + t_0 - t) \big) = 0
\]
for all $t$ with $t_0 \leqslant t < R$. Hence
\[
\frac{\partial f}{\partial t}(t,x) = 0 = \frac{\partial f}{\partial x_i}(t,x)
\]
for all $x \in B(x_0; R + t_0 - t)$. Therefore $f(t,x) = C$ (constant) for all $t_0 \leqslant t < R$ and $x \in B(x_0, R + t_0 - t)$. But $f(t_0,x) = 0$ for $x \in B(x_0;R)$, so $C = 0$.
\end{proof}

The next proposition gives uniqueness of solutions of Cauchy problems, at least among $f \in C^1([0,\infty) \times \Rbb^n)$:

\begin{prop}
Let $f, \widetilde{f} \in C^1([0,\infty) \times \Rbb^n)$ be two solutions of the homogeneous or inhomogeneous Cauchy problem for the wave equation. Then $f = \widetilde{f}$.
\end{prop}

\begin{proof}
We consider $F:= f - \widetilde{f}$. Then $F$ satisfies~\eqref{Eq:WE} on $(0,\infty) \times \Rbb^n$, and $F(0,x) = 0 = \frac{\partial F}{\partial t}(0,x)$ for all $x \in \Rbb^n$. By Proposition~\ref{Prop:WE:EnergyNonIncreasing}, we have for $x \in \Rbb^n$, $\rho > 0$ and $t \geqslant t_0$
\begin{equation}\label{Eq:Proof:WE:UniquenessCauchy}
E(t, B\big(x;\rho)\big) \leqslant E \big(t_0, B(x; \rho + t - t_0) \big).
\end{equation}
Here $E$ is the energy of $F$. Since $F \in C^1([0,\infty) \times \Rbb^n)$, the limit
\[
\lim_{t_0 \to 0} E \big( t_0, B(x; \rho + t - t_0) \big)
\]
exists and is equal to
\[
\frac{1}{2} \int_{B(x; \rho + t)} \Abs{ \frac{\partial F}{\partial t}(0,x) }^2 + \Abs{\grad F(0,x)}^2 \dx
= 0.
\]
The last equality holds by initial conditions. By taking $t_0$ to $0$ in~\eqref{Eq:Proof:WE:UniquenessCauchy}, we therefore obtain $E \big( t, B(x;\rho) \big) \leqslant 0$, whence
\[
E \big( t, B(x;\rho) \big) = 0.
\]
Using the same argument as in the proof of Theorem~\ref{Theo:FinitePropagationSpeed}, this shows that $F$ is constant. By initial conditions, it follows that $F = 0$, i.e.\ $f = \widetilde{f}$.
\end{proof}

Our next goal is to find explicit solution formulas for $n \geqslant 2$ (under slightly stronger assumptions on $f_0$, $f_1$, $g$).

\begin{dfn}\label{Def:SphericalMean}
Let $\varphi \in C(\Rbb^n)$. For $x \in \Rbb^n$ and $t \geqslant 0$, we define the sperical mean
\[
M\varphi(t,x) := \frac{1}{\omega_n} \int_{S^{n-1}} \varphi(x + ty) \d{}y.
\]
\end{dfn}

$M \varphi(t,x)$ gives the ``average'' of $\varphi$ over the sphere of radius $t$ and centre $x$. We can also write
\[
M\varphi(t,x) = \frac{1}{\vol(S^{n-1}(x;t))} \int_{S^{n-1}(x;t)} \varphi(y) \d{}y.
\]

\begin{rem}
(a) If $\varphi \in C^k(\Rbb^n)$, then $M\varphi \in C^k([0,\infty) \times \Rbb^n)$. This can be shown using the theorem on differentiation of parameter-dependent integrals.

(b) If $\varphi$ is harmonic (i.e.\ $\Delta \varphi = 0$), then $M\varphi(t,x) = \varphi(x)$ for all $t \geqslant 0$. This is the mean value property of harmonic functions (see Proposition~\ref{Prop:MeanValueProperty}).
\end{rem}

\begin{lem}\label{Lemma:DiffSphericalMean}
Let $\varphi \in C^2(\Rbb^n)$. Then for $t > 0$,
\[
\frac{\partial M\varphi}{\partial t}(t,x)
= \frac{1}{t^{n-1}} \int^t_0 \tau^{n-1} M(\Delta \varphi) (\tau,x) \d\tau.
\]
\end{lem}

\begin{proof}
Using the theorem on differentiation of parameter-dependent integrals and the chain rule, we obtain
\begin{align*}
\frac{\partial M\varphi}{\partial t}(t,x)
&= \frac{1}{\omega_n} \int_{S^{n-1}} \scalprod{\grad \varphi(x + ty)}{y} \d{}y.
\intertext{The change of variables $z = x + ty$ yields}
%\begin{align*}
	\frac{\partial M\varphi}{\partial t}(t,x)
	&= \frac{1}{\omega_n t^{n-1}} \int_{S^{n-1}(x;t)} \scalprod{\grad \varphi(z)}{N_z} \d{}z \\
	&= \frac{1}{\omega_n t^{n-1}} \int_{\partial B^{n-1}(x;t)} N_z \varphi(z) \d{}z.
%\end{align*}
\intertext{Green's formula~II applied to the last integral gives}
%\[
\frac{\partial M\varphi}{\partial t}(t,x)
&= \frac{1}{\omega_n t^{n-1}} \int_{B^{n-1}(x;t)} \Delta \varphi(z) \d{}z
%\]
\intertext{and by passing to polar coordinates, we obtain}
%\begin{align*}
	\frac{\partial M\varphi}{\partial t}(t,x)
	&= \frac{1}{\omega_n t^{n-1}} \int^t_0 \tau^{n-1} \int_{S^{n-1}(0;1)} \Delta \varphi(x + \tau y) \d{}y \d\tau \\
	&= \frac{1}{\omega_n t^{n-1}} \int^t_0 \tau^{n-1} M(\Delta \varphi) (\tau,x) \d\tau.
	\qedhere
\end{align*}
\end{proof}

\begin{cor}
Let $\varphi \in C^2(\Rbb^n)$ as above. Then
\[
\frac{\partial^2 M\varphi}{\partial t^2}
= - \frac{n-1}{t^n} \int^t_0 \tau^{n-1} M(\Delta \varphi) (\tau,x) \d\tau
+ \frac{1}{t^{n-1}} M(\Delta \varphi) (t,x).
\]
\end{cor}

\begin{proof}
Direct differentiation of the formula in Lemma~\ref{Lemma:DiffSphericalMean}.
\end{proof}

The following lemma gives the solution of the Cauchy problem for $g = f_0 = 0$ and odd dimensions.

\begin{lem}
Let $n \geqslant 3$ be odd. Let $\varphi \in C^{n-1}(\Rbb^n)$ and set%
\footnote{Notation: $\Box^0 = id$ and $\Box^k = \Box \circ \overset{(k)}{{}\dots{}} \circ \Box$.}
\[
\Mtil \varphi (t,x)
:= \frac{1}{(n-2)!} \; \Box^{\frac{n-3}{2}} (t^{n-2} M\varphi) (t,x).
\]
Then $f := \Mtil \varphi$ has the following properties:
%\begin{itemize}
%	\item $f \in C^2([0,\infty) \times \Rbb^n)$, 
%	\item $\Box f = 0$ (on $[0,\infty) \times \Rbb^n$),
%	\item $f(0,x) = 0$,
%	\item $\frac{\partial f}{\partial t} (0,x) = \varphi$,
%	\item $\frac{\partial^2 f}{\partial t^2} (0,x) = 0$.
%\end{itemize}
	
	(i) $f \in C^2([0,\infty) \times \Rbb^n)$, 
	
	(ii) $\Box f = 0$ (on $[0,\infty) \times \Rbb^n$),
	
	(iii) $f(0,x) = 0$,
	
	(iv) $\frac{\partial f}{\partial t} (0,x) = \varphi$,
	
	(v) $\frac{\partial^2 f}{\partial t^2} (0,x) = 0$.
\end{lem}

\begin{rem}
In the case of dimension $n = 3$, we have $\Mtil\varphi(x,t) = t M\varphi(t,x)$.
\end{rem}

\begin{proof}
(i) We have $t^{n-2} M\varphi \in C^{n-1}([0,\infty)\times \Rbb^n)$ by the remark after the introduction of $M\varphi$ (Definition~\ref{Def:SphericalMean}). The operator $\Box^{\frac{n-3}{2}}$ acts by differentiation of order $n - 3$. Hence $\Box^{\frac{n-3}{2}} (t^{n-2} M\varphi) \in C^{2}([0,\infty)\times \Rbb^n)$.

(iii) By Schwartz lemma, $\frac{\partial}{\partial x_i}$ and $\frac{\partial}{\partial t}$ commute as operators on $C^k([0,\infty)\times \Rbb^n)$ (for $k \geqslant 2$). By iteration, $\Delta$ and $\frac{\partial}{\partial t}$ commute for $k \geqslant 3$. We can therefore apply the binomial formula to compute
\[
\Box^{\frac{n-3}{2}}
= \left( \frac{\partial^2}{\partial t^2} - \Delta \right)^{\frac{n-3}{2}}
= \sum_{k=0}^{(n-3)/2} (-1)^k \binom{\frac{n-3}{2}}{k} \left( \frac{\partial}{\partial t} \right)^{n - 3 - 2k} \Delta^k.
\]
In particular, the highest $t$-derivative is $\frac{\partial^{n-3}}{\partial t}$ and therefore $f$ is of the form
$
f(t,x) = t g(t,x)
$
where $g$ is a sum of derivatives of $t^k M\varphi$ (and is continuous). Hence $f(0,x) = 0$.

(iv) We have
\[
\frac{\partial f}{\partial t}
= \frac{1}{(n-2)!} \; \Box^{\frac{n-3}{2}}
\left( (n-2) t^{n-3} M\varphi + t^{n-2} \frac{\partial M\varphi}{\partial t} \right)
\]
and therefore
\[
\frac{\partial f}{\partial t}(0,x)
= \frac{1}{(n-3)!} \left( \frac{\partial}{\partial t} \right)^{n-3} (t^{n-3})|_{t=0} M\varphi(0,x) = \varphi(x).
\]

(ii) We will prove that $\Box f = 0$ for $n = 3$ only. For $t > 0$, we have
\begin{align*}
	\Box(tM\varphi)
	&= \frac{\partial}{\partial t} \left( M\varphi + t \frac{\partial M\varphi}{\partial t} \right) - t \Delta M(\varphi)
	= 2 \frac{\partial M \varphi}{\partial t} + t \frac{\partial^2 M \varphi}{\partial t^2} - t M(\Delta \varphi) \\
	&= \frac{2}{t^2} \int^t_0 \tau^2 M(\Delta\varphi) (\tau,x) \d\tau
		- \frac{2}{t^2} \int^t_0 \tau^2 M(\Delta\varphi) (\tau,x) \d\tau
		+ t M(\Delta \varphi) - t M(\Delta \varphi) = 0.
\end{align*}
\end{proof}
For the inhomogeneous Cauchy problem we need an additional construction. Let $n\;\geq\;3$ be odd.
\begin{dfn}
Let $g\;\in\;C^{n-1}([0,\infty)\times \Rbb^n)$
We define the \textbf{retarded potential} for g 
\end{dfn}
 
\section{PDE Exercises}
\begin{equation*}
 f: \Rbb^n \To \Com
\end{equation*}
given
$\tilde{M}f$ is a solution of the homogeneous Cauchy problem, with $\tilde{M}f(0,x) = 0$,
$\frac{\partial \tilde{M}f}{\partial t}(0,x) = f(x)$
Let $g:[0,\infty) \times \Rbb^n \To \Com$ be sufficiently often continuously differentiable. Show without using any
explicit formular for $\tilde{M}f$ that the function Qg defined by 
\begin{equation*}
 Qg(t,x):= \int^{t}_{0} \tilde{M}g_s(t-s,x)ds, 
\end{equation*}
where $g_s(x):= g(s,x),$ is the solution of the Cauchy problem for the inhomogeneous wave equation with right hand
side g and zero initial conditions. 
We want to show that this implies $\Box Qg = g$
$Qg(0,x)= \frac{\partial Qg}{\partial t}(0,x) = 0$
\newline
\begin{rem}
 For n = 1 this gives an alternative solution of Example 1.
\begin{equation*}
 \tilde{M}f(0,x) = \frac{1}{2c} \int^{x+t}_{x-t}f(\tau)d\tau
\end{equation*}
This implies 
\begin{equation}
 Qg(t,x) = \frac{1}{2c} \int^{t}_{0} \int^{x+c(t-s)}_{x-c(t-s)}g(s,\tau)d\tau ds
\end{equation}

\end{rem}
We can then write Qg(0,x) = $\int_0^0 \cdots ds = 0$
$\frac{\partial Q}{\partial t}(t,x) = \tilde{M} g_s(t-s,x)$ 
We let s = t 
$+\int^t_0 \frac{\partial}{\partial t} \tilde{M}g_s(t-s,x)ds$
We know $\tilde{M}g_t(0,x) =0$
SO: \begin{equation}\label{8}
     \frac{\partial Qg}{\partial t}(t,x) = \int^{t}_0 \frac{\partial}{\partial t} \tilde{M}g_s(t-s,x)ds 
    \end{equation}
In particular if t=0 
We get $\frac{\partial Qg}{\partial t} (0,x) = \int^0_0 \cdots = 0$
We also have to look at the box operator 
$\Box = \frac{\partial^2}{\partial t^2} - \triangle_x$
We obtain by $\frac{\partial}{\partial t}\ref{8}$
By parameter dependent integrals;
\begin{equation*}
 \frac{\partial^2 Qg}{\partial t^2}(t,x) = \int^{t}_0 \frac{\partial^2}{\partial t^2} \tilde{M}g_s(t-s,x) + 
\frac{\partial}{\partial t} \tilde{M}g_s (t-s,x)|_{s=t} 
\end{equation*}
\begin{equation*}
 \frac{\partial^2 Qg(t,x)}{\partial t^2} = g(t,x) + \int^t_0 \cdots ds
\end{equation*}
By parameter dependent integrals;
\begin{equation*}
 \triangle_x Qg(t,x) =\int^t_0 \triangle_x \tilde{M}g_s(t-s,x) ds
\end{equation*}
\begin{equation*}
 \Box Qg(t,x) = g(t,x) + \int^t_0 \Box Mg(t-s,x)ds
\end{equation*}
The integral above goes to zero by the homogeneous Cauchy problem solution. 
Therefore we can write 
\begin{equation}
 \Box Qg(t,x) = g(t,x)
\end{equation}
\begin{rem}
 We only need the properties of $\tilde{M}g_s$. This should be seen as an exercise in parameter dependent integrals. 
\end{rem}
\section{Examples of distributions and their order}
Let us recall the criterion:
T:$C^{\infty}_{c}(U) \To \Com$ linear 
T is a distribution $\iff$ $\forall K \subset U$ compact 
$\exists p(K) \in \mathbb{N}_0$, $C(K) \in [0,\infty)$ such that for 
$\phi \in C^{\infty}_{c}(U)$ with supp$\phi \subset K$
\begin{equation*}
 |T(\phi)| \leq C(K) \sum_{|\alpha|\leq p(K)}\|D^{\alpha}\phi\|_{\infty}
\end{equation*}
Where the last norm is the suprenum norm. 
\begin{ex}
 \begin{equation*}
  \delta_{x_{0}} 
 \end{equation*}
\begin{equation*}
 |\delta_{x_{0}}| = |\phi(x_{0})| \leq \|\phi \|_{\infty}
\end{equation*}
(c=1, p = 0, indepedent of K.
\end{ex}
\begin{ex}
 \begin{equation*}
  f \in L^1_{loc}(U) 
 \end{equation*}
$T_f(\phi) = \int_U f(x) \phi (x) ds$
$|T_f(\phi)| = |\int_U f(x) \phi(x) dx| \leq \int_U|f(x)||\phi(x)|dx$ 
Assume $K \subset U$ compact 
$supp \phi \subset K$ $=\int_K|f(x)||\phi(x)|dx$
$\leq \|\phi\|_\infty \int_K |f(x)|dx$
the integral above can be considered as C(K) and it is less than infinity (p=0, independent of K).
\end{ex}
\begin{ex}
 $T(\phi) = \int_M \phi|_M . \omega$
M $\subset U$ k-dim oriented subset and we can consider $\omega$ a k(top) form
There is a \textbf{trick}: In local coordinates $Y_1,\cdots Y_k$ $V\subset M$ open $y_1: V 
\To \Rbb$
$\omega = g(y_1,\cdots, y_k)dY_1\wedge \cdots \wedge dY_k$
We use the pullback in fact, but we can sloppy write 
\begin{equation*}
 \int_V \phi|_M \omega = \int_V \phi(Y_1 \cdots Y_k)g(Y_1,\cdots,Y_k)dy_1,\cdots, dy_k
\end{equation*}
$\int_M \phi_M \omega =$ sum over open sets, where we have coordinates using partition of unity. We need a volume form or 
take the modulus of $|g(y_1,...,y_k)|$
\begin{rem}
 If we define, in local coordinates of the correct orientation 
$|\omega(x)|=|g(y_1,\cdots,y_k)|dy_1 \wedge \cdots \wedge dy_k$
then $|\omega|$ is well-defined independent of co-ordinates.
\end{rem}
We can then write the following 
\begin{equation*}
 |\int_M \phi|_M . \omega| \leq \int_M|\phi|_M . |\omega| = \int_{K \cap M} |\phi|_{|M}.|\omega| 
\leq \|\phi\|_\infty . \int_{K \cap M} |\omega|
\end{equation*}
Because $supp \phi \subset K$ we can do this trick.
The integral above becomes C(K) and is finite, since $\omega$ has a finite number.
This is indeed a distribution and clearly of order 0.
\end{ex}
\begin{ex}
\begin{rem}
Show that the sequence $(T_n)$, where
 $T_n$ is given by the locally integrable function $ne^{-\frac{n^{2}x^{2}}{2}}$,
 converges in $C^{-\infty}(\mathbb{R})$ and compute its limit. 
\end{rem}
\begin{proof}
 Let $\phi\in\mathcal{D}(\mathbb{R})$ (i.e., $\phi$ is a $C^\infty$ function with compact suport). Then
$$
\langle T_n,\phi\rangle=\int_\mathbb{R}n\,e^{-n^2x^2}\phi(x)\,dx=\int_\mathbb{R}\,e^{-x^2}\phi\bigl(\frac xn\bigr)\,dx.
$$
We have 
$$
\lim_{n\To\infty}e^{-x^2}\phi\bigl(\frac xn\bigr)=e^{-x^2}\phi(0)\quad\forall x\in\mathbb{R}
$$
and
$$
\Bigl|e^{-x^2}\phi\bigl(\frac xn\bigr)\Bigr|\le \|\phi\|_\infty e^{-x^2}.
$$
The dominated convergence theorem implies that
$$
\lim_{n\To\infty}\langle T_n,\phi\rangle=\phi(0),
$$
that is, $T_n$ converges in the distribution sense to Dirac's $\delta_0$.
\end{proof}
\end{ex}
\begin{ex}
 Formulate the homogeneous Cauchy problem for the heat equation on $\Rbb^{n}$, and give uniqueness and existence 
results, including a solution formula, under a boundedness condition.
\paragraph{} Assume now that the initial condition $\phi$ is real valued, nonnegative, compactly supported and not 
identically zero. Show that the solution $f(t,x)$ satisfies
\begin{itemize}
 \item f(t,x) $\gt$ 0 for all $(t,x) \in (0, \infty) \times \Rbb^n$,\
\item $lim_{|x| \To \infty}f(t,x) = 0$ for any fixed t $\gt$ 0,
\item $lim_{t \To \infty} f(t,x)$ = 0 for any fixed $x \in \Rbb^n$
\end{itemize}
\end{ex}
\begin{ex}
 Let us consider what happens to a linear constant coefficient partial differential operator, P(D).
\textit{the fundamental solution of P can never be a distribution with compact support}.
\begin{proof}
In fact, assume we have P(D)u = f, where u is a distribution, then u has compact support 
$\iff \dfrac{f}{P(\xi)}$ is analytic. (This result can be found in Chapter 7 of Volume 1 of Hormanders
treatise). 
Now, if we have 
\begin{equation}
 P(D)u = \delta
\end{equation}
obviously $\dfrac{\delta}{P(\xi)}$ is never an analytic function for a polynomial P. So the fundamental solution
of P can not be compactly supported. 
\end{proof}
\end{ex}
\begin{ex} I have a sequence $(T_n)$, where $T_n$ is given by the locally integrable function $ne^{-\dfrac{n^{2}x^{2}}{2}}$, converges in $C^{-\infty}(\mathbb{R})$ and compute its limit. 
I suspect that the limit tends towards zero since the exponential tending towards infinity will become zero. Is this enough to prove this, in conjunction with the definition? I've already written the definition of a locally integrable function and I already understand the definition (sometimes called the 'weak-dual convergence') of the convergence of a sequence of distributions. 
   I've not considered any topologies in these cases, as I don't understand Frechet spaces and the like. 
\end{ex}
\begin{proof}
Let $\phi\in\mathcal{D}(\mathbb{R})$ (i.e., $\phi$ is a $C^\infty$ function with compact suport). Then
$$
\langle T_n,\phi\rangle=\int_\mathbb{R}n\,e^{-n^2x^2}\phi(x)\,dx=\int_\mathbb{R}\,e^{-x^2}\phi\bigl(\frac xn\bigr)\,dx.
$$
We have 
$$
\lim_{n\To\infty}e^{-x^2}\phi\bigl(\frac xn\bigr)=e^{-x^2}\phi(0)\quad\forall x\in\mathbb{R}
$$
and
$$
\Bigl|e^{-x^2}\phi\bigl(\frac xn\bigr)\Bigr|\le \|\phi\|_\infty e^{-x^2}.
$$
The dominated convergence theorem implies that
$$
\lim_{n\To\infty}\langle T_n,\phi\rangle=\phi(0)\int_\mathbb{R}\,e^{-x^2}dx=\sqrt\pi\,\phi(0),
$$
that is, $T_n$ converges in the distribution sense to Dirac's $\sqrt\pi\,\delta_0$.
\end{proof}
\begin{ex}
 Show that he distribution given by the locally integrable function $\dfrac{1}{2} e^{|x|}$ is a fundamental solution of the differential operator 
$
-\dfrac{\partial^{2}}{\partial x^{2}} + id
$ on $\mathbb{R}^{1}$
\end{ex}

\begin{proof}
 You can check directly by noting the fact that 
$$
\frac{d}{dx}e^{|x|}=(H(x)+H(-x))e^{|x|}
$$
where H is the Heaviside function.
On the other hand,you can use fourier transform to get the desired result,in fact,let u satisfies
$$
(1-\frac{d}{dx^2})u=\delta
$$
Take fourier transform on both sides,then get 
$$
\widehat{u}=\frac{1}{1+x^2}
$$
then the result follows easily.
\end{proof}
\begin{ex}
 Let us consider 
$ \lim_{\epsilon \To 0} \dfrac{\epsilon}{x^{2} + \epsilon^{2}} $ in $C^{-\infty}(\Rbb)$
\end{ex}
\begin{proof}
 Firstly let us use $y = \dfrac{x}{\epsilon}$\newline
So we have $\lim_{\epsilon \To 0} \dfrac{\epsilon}{\epsilon^{2} y^{2} + \epsilon^{2}}$\newline
We know that $\int_\Rbb g(x)dx$ is Continuous and bounded.\newline
$y_{\epsilon}(x) = 1/\epsilon(g(\dfrac{x}{\epsilon})dy$ \newline
Let us now form a distribution \newline
$T_{y_{\epsilon}}(\phi) = \int_{\Rbb} \epsilon^{-1} y(\dfrac{x}{\epsilon}) \phi(x)$\newline
$= \int_\Rbb g(y) \phi(\epsilon y) dy$
$\lim_{\epsilon \To 0} T_{y_{\epsilon}}(\phi) = \lim_{\epsilon \To 0}$\newline
$= \int_\Rbb g(y) \lim_{\epsilon \To 0} \phi(\epsilon y) dy$ \newline
$= \int_\Rbb g(y) \phi(0) dy$ \newline
$\phi(0) \int_\Rbb g(y) dy$ by the assumption that this integral is x. \newline
= $x\cdot \phi(0)$
\end{proof}
\begin{ex}
 Question 4 on June 20th 2011
Suppose there exists a non-zero solution $f \in C^{\infty}(\Rbb^{n})$ of th equation 
$D' f = 0$ 
\end{ex}
\begin{proof}
 DT = S, where $S \in C^{-\infty}_{c}(U)$
By the a proposition $\exists$! $\tilde{S}:C^{\infty}(U) \To \Com$
such that 
$\tilde{S}(f) = S(f)$ for all $f \in C^{\infty}_{c}(U)$
but $f \in C^{\infty}$ therefore by a Proposition \begin{equation}\tilde{S}(f) = 0 \end{equation}
\end{proof}
\subsection{Fourier Transform Examples}
It is worth first considering a few examples in a table form

\begin{ex}
\newcolumntype{M}{>{$}c<{$}}
\begin{tabular}{MM}
f(x)             &                \widehat{f}(\xi)\\ \hline
\chi_{[a,b]} & \dfrac{1}{\sqrt{2 \pi}} \cdot \dfrac{1}{\xi}(e^{-i\xi b} -e^{-i\xi a}), \xi \neq 0 \\ 
e^{-t|x|} & \dfrac{1}{\sqrt{2 \pi}} \cdot \dfrac{2t}{t^2 + \xi^2} = \sqrt{\dfrac{2}{\pi}\dfrac{t}{t^2 + \xi^2}} \\ 
\dfrac{1}{1 + x^{2}} & \sqrt{\dfrac{\pi}{2}} e^{-|\xi|}\\ 
\chi_{[0, \infty]} e^{-x} & \dfrac{1}{\sqrt{2\pi}} \dfrac{1}{1+i \xi}\\ 
\chi_{[0,1] \times [0,1]} & \widehat{\chi}_{[0,1]}(\xi_{1})\cdot\widehat{\chi}_{[0,1]}(\xi_{2})\\
\hline
\end{tabular}
\end{ex}
\begin{ex}
 \begin{equation}
  \chi_{[0,1] \times [0,1]} 
 \end{equation}
The trick is to use Fubini's theorem, so let us write out this in terms of Fourier transform
\begin{align}
 \widehat{\chi_{\infty}}(\xi_1, \xi_2) = \dfrac{1}{2\pi} \int_{\Rbb^{2}}\chi_{\infty} (x_1, x_2)
e^{-i(\xi_1 x_1+ \xi_2 +2)} dx_1 dx_2 \\
= \dfrac{1}{2\pi} \int_{\Rbb^{2}} \chi_{[0,1]}(x_1)\cdot 
\chi_{[0,1]}(x_2)e^{-i \xi_1 x_1} e^{-i \xi_2 x_2}dx_1 dx_2 \\
(Fubini) = \dfrac{1}{2 \pi} \int_{\Rbb} \chi_{[0,1]} (x_1) e^{-i \xi_1 x_1} dx_{1} 
\int_{\Rbb} \chi_{[0,1]} (x_2) e^{-i \xi_2 x_2} dx_{2} \\
=  \widehat{\chi}_{[0,1]}(\xi_{1})\cdot\widehat{\chi}_{[0,1]}(\xi_{2})
\end{align}

\end{ex}
\begin{dfn}\label{def:FourierTransform}
For a function $f \in L^1(\Rbb^n)$ and $\xi \in  \Rbb^n$ we define
\begin{displaymath}
\widehat{f} (\xi) = \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} f(x) e^{-i \scalprod{\xi}{x}} \dx \in \Com.
\end{displaymath}
The function $\widehat{f} \colon \Rbb^n \to \Com$ is called the \textcolor{blue}{Fourier transform of $f$}.
\end{dfn}
\begin{thm}[Riemann-Lebesgue]
 If f $\in L^{1}(\Rbb)$,then $\widehat{f}$ satisfies the following conditions:
\begin{enumerate}
 \item $\widehat{f}$ is continuous and bounded on \Rbb as a linear map. 
\item $\mathcal{F}$ is a continuous linear operator from $L^1(\Rbb)$ to $L^\infty(\Rbb)$, and
\begin{equation}
 \|\widehat{f}\|_\infty \leq \|f\|_{1}
\end{equation}
\item $\lim_{|\xi| \rightarrow + \infty} |\widehat{f}(\xi)| = 0$
\end{enumerate}

\end{thm}

\begin{proof}
\begin{flushleft}
 \begin{align*}
(1) \text{The continuity of} \widehat{f}\text{ follows directly from the continuity of the integral}
 \ref{def:FourierTransform} \\
\text{Fourier transform with respect to the parameter $\xi$.}\\
 \text{The function} \xi \mapsto e^{i <x, \chi>}f(x) 
\text{is continuous on} \Rbb \text{and is dominated by} |f(x)|, 
\\ \text{which is in} L^1(\Rbb). \text{Therefore the assertion holds}
\end{align*}
\begin{align*}
(2)\text{For all $\chi \in \Rbb$ we have} |\widehat{f}(\chi)| \leq \int|f(x)|dx = \|f\|_{1}. \text{Thus} \\
\widehat{f} \text{is bounded and $\mathcal{F}$ is continuous from $L^{1}(\Rbb)$ to $L^{\infty}(\Rbb)$.} 
\end{align*} 
\end{flushleft} 

\begin{eqnarray*}
 f \in L^1(\Rbb^{n}) \\
\text{f} \in \mathcal{S}(\Rbb^n) \Rightarrow \widehat{f} \in \mathcal{S}(\Rbb^n) \\
|\widehat{f}(\xi)| \leq \dfrac{C}{1 + |\xi|^{2}} \text{By definition of $\mathcal{S}(\Rbb^{2})$}\\
\rightarrow \lim_{|\xi| \rightarrow \infty} \widehat{f} (\xi) = 0 \\
\S(\Rbb^n) \subset L^1(\Rbb^{n}) \exists f_n \in \S(\Rbb^{n}) \text{with} \| f - f_{n}\| \stackrel{n \rightarrow 
\infty}{\rightarrow} 0 \\
Using (2) : f \in L^1(\Rbb^n), \|\widehat{f}\|_{\infty} = \sup_{\xi \in \Rbb^{n}}\|\widehat{f}(\xi)\| \leq \frac{1}{(2\pi)^{n/2}}\|
f\| \\
|\widehat{f}(\xi)| \leq \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n} f(x) e^{-i \scalprod{\xi}{x}} \dx \\
= \frac{1}{(2\pi)^{n/2}} \int_{\Rbb^n}\| f(x) \|\dx  = \dfrac{\|f\|_{1}}{(2\pi)^{n/2}}
\\
f_n, f \text{as above} \| \widehat{f} - \widehat{f}_{n}\|_{\infty} \leq \epsilon \text{i.e} \\
 | \widehat{f}(\xi) - \widehat{f}_{n}(\xi)| \leq \epsilon \; \forall \xi  \Rightarrow \exists R \text{so that for} \\
|\xi| \geq R \text{(for fixed n)} |\widehat{f}_{n}(\xi)| \leq \epsilon \\
\Rightarrow \text{For} |\xi| \geq R \;   |\widehat{f}(\xi) - \widehat{f}_{n}(\xi)| + |\widehat{f}_{n}(\xi)| \\
                                      \leq \epsilon + \epsilon = 2 \epsilon
\end{eqnarray*}
\begin{flushleft}
Summarizing: $\forall \epsilon > 0$, $\exists R \forall \xi$, $|\xi| \geq R \colon |\widehat{f}(\xi) \leq 2 \xi$,\\
this means $\lim_{|\xi| \rightarrow \infty}|\widehat{f}(\xi)| = 0$
\end{flushleft} \qed
\end{proof}

\end{document}
